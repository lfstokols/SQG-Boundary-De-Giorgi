\documentclass[11pt]{amsart}
\usepackage{amssymb,amsbsy,upref,epsf,MnSymbol}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,mathtools,mathrsfs,wrapfig}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}



%-------------------------------------------<commands>--------------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Prj}{\mathbb{P}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\Four}{\mathcal{F}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\eps}{\varepsilon}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\chevron}[1]{\langle #1 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\convex}{conv}
\DeclareMathOperator{\image}{Im}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\lspan}{span}
\DeclareMathOperator{\conv}{conv} % stands for conv, as in convex hull
\DeclareMathOperator{\Int}{int} % stands for int, as in interior of a set
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\rank}{rank}
%\DeclareMathOperator{\dim}{dim}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\cod}{\operatorname{cod}}
\newcommand{\Hom}{\operatorname{hom}}
\newcommand{\Ob}{\operatorname{Ob}}
\newcommand{\cl}{\operatorname{cl}}
\DeclareMathOperator{\BMO}{BMO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\del}{\partial}
\newcommand{\pvec}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\grad}{\nabla}
\newcommand{\ddt}{\frac{d}{dt}}
\renewcommand{\div}{\operatorname{div}}
\newcommand{\Laplace}{\Delta}
\newcommand{\kinet}{\bracket{\del_t + v\cdot \grad_x}}
\newcommand{\bessel}{\paren{1-\Laplace_v}}
\newcommand{\loc}{\text{loc}}
\newcommand{\ddz}{\frac{d}{dz}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\into}{\hookrightarrow}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\isom}{\cong}
\newcommand{\rest}{{\upharpoonright}}
\newcommand{\weakly}{\rightharpoonup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ith}{^\mathrm{th}}
\newcommand{\n}{^{-1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\indic}[1]{\chi_{\{#1\}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\eigen}[1]{\eta_{#1}} %my eigenfunctions
\newcommand{\Ctest}{C_c^\infty}
\newcommand{\test}{\mathcal{D}}

\newcounter{step_count}[section]
\newcommand{\step}[1]{\stepcounter{step_count} \smallskip \noindent{\textbf{Step \arabic{step_count}:} #1}}


%-------------------------------------------</commands>--------------------------------------------------------

%\newcommand{\draftnum}{1}%-----------------------------UPDATE DRAFT NUM----------------------------------------

\title{SQG Boundary, \today}

\author[Stokols]{Logan F. Stokols} 
\address[L. F. Stokols]{\newline Department of Mathematics, \newline The University of Texas at Austin, Austin, TX 78712, USA}
\email{lstokols@math.utexas.edu}

\date{\today}

%\subjclass[2010]{35H10,35B65,47G20,35Q84} % hypoellptic, regularity, integro-differential, fokker-planck
%\keywords{Fokker-Planck Equation, Fractional Laplacian, H\"older regularity,  De Giorgi method}

%\thanks{\textbf{Acknowledgment.} This work was partially supported by the NSF Grant DMS 1614918. }

\begin{document}




\maketitle \centerline{\date}

We're gonna consider the equation 
\begin{equation}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ u = \grad^\perp \Lambda\n \theta.
\end{equation}

Here the operator 
\[ \Lambda := \sqrt{-\Laplace_D} \]
where $\Laplace_D$ is the Laplacian with Dirichlet boundary condition.  

We're going to linearize the equation by fixing $u$ independent of $\theta$.  What property do we want $u$ to have?  For some constant $\kappa$, we'll want
\begin{align*} 
u &= \sum_{j \in \Z} u_j, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j. 
\end{align*}
The convergence of that sum is in, say, weak $L^2$.  


\section{Lemmas}

\begin{lemma}
If $f$ and $g$ are non-negative functions with disjoint support (i.e. $f(x)g(x) = 0$ for all $x$), then 
\[ \int \Lambda^s f \Lambda^s g \,dx \leq 0. \]
\end{lemma}

This proves, in particular, that $-\int \theta_+ \Lambda \theta_-$ is a positive term (hence dissipational and extraneous) and that $\int \Lambda^{1/2} (\theta-\psi) \Lambda^{1/2} (\theta-\psi)$ breaks down (bilinearly) into the doubly positive, the doubly negative, and the cross term, all of which are positive and hence each of which is positive.  

\begin{proof}
Use the characterization from Caffarelli-Stinga.  There exist non-negative functions $K(x,y)$ and $B(x)$, depending on the parameter $s$, such that
\[ \int \Lambda^s f \Lambda^s g \,dx = \iint [f(x)-f(y)][g(x)-g(y)] K(x,y) \,dxdy + \int f(x) g(x) B(x) \,dx. \]

Since $f$ and $g$ are non-negative and disjoint, the $B$ term vanishes.  Moreover, the product inside the $K$ term becomes
\[ [f(x)-f(y)][g(x)-g(y)] = -f(x)g(y)-f(y)g(x) \leq 0. \]
Since $K$ is non-negative, the result follows.  
\end{proof}

\begin{lemma}
For all functions $f$ in $H_D^1$,
\[ \int \abs{\grad f}^2 = \int \abs{\Lambda f}^2. \]

Moreover, if $f \in H_D^1$ then $\trace(f)=0$.  
\end{lemma}

\begin{proof}
Let $\eigen{i}$ and $\eigen{j}$ be two eigenfunctions of the Dirichlet Laplacian on $\Omega$.  Note that these functions are smooth in the interior of $\Omega$.  Because $\Omega$ has Lipschitz boundary, and because $\eigen{i} \grad \eigen{j}$ is smooth on $\Omega$ and countinuous and bounded on $\overline{\Omega}$ vanishing on the boundary, therefore 
\[ \int_\Omega \div(\eigen{i} \grad \eigen{j}) = \int_{\del \Omega} \eigen{i} \grad \eigen{j}. \]
But $\eigen{i} \grad \eigen{j}$ vanishes on the boundary, so the right hand side vanishes.  Moreover, $\div(\eigen{i} \grad \eigen{j}) = \grad \eigen{i} \cdot \grad \eigen{j} + \eigen{i} \Laplace \eigen{j}$.  Therefore
\[ \int \grad \eigen{i} \cdot \grad \eigen{j} = - \int \eigen{i} \Laplace \eigen{j} = \lambda_k \int \eigen{i} \eigen{j}. \]
Of course, the inner product of two eigenfunctions is 0 unless they are the same eigenfunction, in which case it is 1.  

Consider a function $f = \sum f_k \eigen{k}$ which is an element of $H_D^1$, by which we mean $\sum \lambda_k f_k^2 < \infty$.  Since $\norm{\grad \eigen{k}}_{L^2(\Omega)} = \sqrt{\lambda_k}$, the following sums all converge in $L^2(\Omega)$ and hence the calculation is justified:
\begin{align*}
\int \abs{\grad f}^2 &= \int \paren{\sum_i f_i \grad \eigen{i} } \paren{\sum_j f_j \grad \eigen{j}}
\\ &= \int \sum_{i,j} (f_i f_j) \grad \eigen{i} \cdot \grad \eigen{j}
\\ &= \sum_{i,j} (f_i f_j) \int \grad \eigen{i} \cdot \grad \eigen{j}.
\end{align*}
Since this double-sum vanishes except on the diagonal, we see from [citation] that in fact
\[ \norm{\grad f}_{L^2(\Omega)} = \norm{\Lambda f}_{L^2(\Omega)}. \]

To see that $\trace(f)$ vanishes, note that $f = \sum_{k=0}^\infty f_k \eigen{k}$ and that each finite partial sum for this series satisfies the Dirichlet boundary condition.  Since $\trace$ is a bounded operator on $H^1$, we need only show that this series is Cauchy in $H^1$, in which case its $H^1$ limit will exist and be equal to its $L^2$ limit which will be equal to $f$.  

For each $k$,
\[ \norm{ f_k \eigen{k} }_{H^1} \leq C_\textrm{Poincare} f_k \norm{\grad \eigen{k}}_2 = C f_k \sqrt{\lambda_k}. \]
This sequence is $\ell^2$ summable, since $f \in H_D^1$ by assumption.  Therefore $f$, being an $H^1$ limit of functions with vanishing trace, also has vanishing trace.  
\end{proof}

\begin{lemma}
For any function $f$, and any $0 < s < 1$,
\[ \int \abs{\Lambda^s f}^2 \simeq \int \abs{\paren{-\Laplace}^{s/2} \bar{f}}^2. \]
Here $\bar{f}$ is the extension of $f$ to $\R^2$ and $\paren{-\Laplace}^s$ is defined in the fourier sense.  
\end{lemma}

\begin{proof}
Let $g$ be any Schwarz function in $L^2(\R^2)$, and let $f$ be a function in $H^{s+1}_D$.  Let $E:H^1(\Omega) \to H^1(\R^2)$ be a bounded extension operator, where $H^1$ denotes the classical Sobolev space defined using the gradient.  Define the function
\[ \Phi(z) = \int_{\R^2} \paren{-\Laplace}^{z/2} g E \Lambda^{s-z} f. \]

When $\Re(z) = 0$, then $\norm{\paren{-\Laplace}^{z/2} g}_2 = \norm{g}_2$ and $\norm{\Lambda^{s-z} f}_2 = \norm{\Lambda^s f}_2$.  Hence
\[ \Phi(z) \leq \norm{g}_2 \norm{f}_{H^s_D}. \]

When $\Re(z)=1$, then $\norm{\paren{-\Laplace}^{(z-1)/2} g}_2 = \norm{g}_2$ and 
\[ \norm{\paren{-\Laplace}^{1/2} E\Lambda^{s-z} f}_{L^2(\R^2)} = \norm{\grad E \Lambda^{s-z} f}_{L^2(\R^2)} \leq \norm{E} \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)}. \]
It remains to ask whether $\Lambda^{s-z} f$ is in $H^1_D$ so that we can apply lemma [citation].  However, this is true based on our assumption $f \in H^{1+s}_D$, since the various powers of $\Lambda$ all commute and form a semigroup.  Ergo
\[ \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)} = \norm{\Lambda \Lambda^{s-z} f}_2 \leq \norm{\Lambda^s f}_2 \]
and we can bound
\[ \Phi(z) \leq \norm{E} \norm{g}_2 \norm{f}_{H^s_D}. \]

Now we will bound the derivative of $\Phi(z)$.  Specifically, compute the derivative in $z$ of the integrand, for $0<\Re(z)<1$, and hope that it is integrable.  To this end, we rewrite the integrand of $\Phi$ as
\[ \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k. \]
The derivative $\ddz$ commutes with linear operators like $\Four\n$ and $E$, so the derivative is
\[ \Four\n\paren{ \ln(|\xi|) |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k + \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \frac{-1}{2} \ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} f_k. \]

Since $0<\Re(z)<1$, $\ln(|\xi|)|\xi|$ is bounded as a multiplier operator from Schwarz functions to $L^2$.  Moreover, $\ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} \leq C \lambda_k^{\frac{s-z+\eps}{2}}$ for some $C$ independent of $k$ but dependent on $z$, $\eps$.  Since $f \in H^{1+s}_D$ this sum converges in $L^2$, in fact in $H_D^1$.  This makes our differentiated integrand a sum of two $H^1$ functions with compact support multiplied by two Schwarz functions.  In particular it is integrable, which means we can interchange the integral sign and the derivative $\ddz$ and prove that $\Phi'(z)$ is finite for all $0<\Re(z)<1$. 

This is sufficient now to apply the Hadamard three-lines lemma to our function $\Phi$.  

It follows that for any Schwarz function $g \in L^2(\R^n)$ and $H_D^{s+1}$ function $f$, 
\[ \int_{\R^2} \paren{-\Laplace}^{s/2} g E f = \Phi(s) \leq \norm{g}_{L^2(\R^2)} \norm{f}_{H_D^s}. \]

Since Schwarz functions are dense in $L^2(\R^2)$, this means by density that 
\[ \int \abs{ \paren{-\Laplace}^{s/2} E f }^2 \leq \int \abs{\Lambda^s f}^2 \]
or in other words it means that $E$ is a bounded operator from $H_D^s$ to $H^s$, at least on the subset $H_D^{s+1} \cap H_D^s$.  It remains to extend this bound to the whole space by density.  

We know from [citation] Caffarelli and Stinga that $\test(\Omega)$ is dense in $H_D^s$ for all $0 \leq s < 1$.  In fact, this takes a bit of interpretation, so I ought to illucidate that this is because $H_D^s = H_0^s$ (the latter in the Slobodekij sense) for most $s$ and at $s=1/2$ we get the Lions-Magenes spaces which still has $\test(\Omega)$ dense.  

Surely, right(?), test functions are all inside of $H_D^{1+s}$.  I should meditate on this, but it must be true.  
\end{proof}


\section{De Giorgi Estimates}

First let us derive an energy inequality.  

We know a priori that $\theta \in L^\infty(0,T; L^2(\Omega)) \cap L^2(0,T; H_D^{1/2}(\Omega))$.  Let $\psi: \Omega \to \R^+$ be a non-negative function in $H_D^{1/2}$ non-uniformly, and define $\theta = \theta_+ + \psi - \theta_-$.  Since $\theta - \psi$ is in $H_D^{1/2}$, by the lemma above, both $\theta_+$ and $\theta_-$ are in that space as well.  In particular, our weak solution can eat $\theta_+$.  

We end up with
\[ 0 = \int \theta_+ \bracket{ \ddt + u \cdot \grad + \Lambda } \paren{\theta_+ + \psi - \theta_-} \]
which decomposes into three terms, corresponding to $\theta_+$, $\psi$, and $\theta_-$.  We analyze them one at a time.  

Firstly,
\begin{align*} 
\int \theta_+ \bracket{ \ddt + u \cdot \grad + \Lambda } \theta_+ &= (1/2) \ddt \int \theta_+^2 + (1/2) \int \div u \, \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2
\\ &= (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2.
\end{align*}

The $\psi$ term produces important error terms:
\begin{align*} 
\int \theta_+ \bracket{ \ddt + u \cdot \grad + \Lambda } \psi &= \ddt \int \theta_+\psi + \int \theta_+ u \cdot \grad \psi + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi.
\end{align*}

Since $\theta_+ and \theta_-$ have disjoint support, the $\theta_-$ term is nonnegative by lemma [citation]:
\begin{align*} 
\int \theta_+ \bracket{ \ddt + u \cdot \grad + \Lambda } \theta_- &= (1/2) \int \theta_+ \del_t \theta_- + \int \theta_+ u \cdot \theta_- + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-
\\ &= \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_- \leq 0.
\end{align*}

Put together, we arrive at 
\[ (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq \abs{\iint \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi} + \abs{\int \theta_+ u \cdot \grad \psi}. \]

\hrule%----%--------%--------

\[ (1/2) \ddt \int \theta_+^2 + \int u \cdot \grad \frac{\theta_+^2}{2} + \int \theta_+ u \cdot \grad \psi - \int \theta_+ u \cdot \grad \theta_- + \int \theta_+ \Lambda \theta = 0. \]

We break up the $\theta_+ \Lambda \theta$ term into
\begin{align*} 
\int \theta_+ \Lambda \theta &= \int \abs{\Lambda^{1/2} \theta_+} + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi - \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-
\\ &= \int \abs{\Lambda^{1/2} \theta_+}^2 + \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) + \int \theta_+ \psi B - \int  \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-.
\end{align*}
The $\theta_-$ term is non-negative by lemma [citation], and the $B$ term is non-negative since $B \geq 0$, so we have the inequality
\[ (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq \abs{\iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y)} + \abs{\int \theta_+ u \cdot \grad \psi}. \]

This integral is symmetric in $x$ and $y$, and the integrand is only nonzero if one of $\theta_+(x)$ and $\theta_+(y)$ is nonzero.  Hence
\[ \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) \leq 2 \indic{\theta_+>0}(x) \abs{[\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)]} K(x,y). \]
Now we can break up this integral using the Peter-Paul variant of H\"{o}lder's inequality.  
\[ \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) \leq \eps \int \abs{\Lambda^{1/2}\theta_+}^2 + \frac{1}{\eps} \iint \indic{\theta_+>0}(x) [\psi(x)-\psi(y)]^2 K(x,y). \]

It remains to bound the quantity $[\psi(x)-\psi(y)]^2 K(x,y)$.  By Caffarelli-Stinga theorem 2.4 [citation], there is a universal constant $C$ such that
\[ K(x,y) \leq \frac{C}{|x-y|^{3}}. \]
The cutoff $\psi$ is Lipschitz, and it grows at a rate $|x|^\gamma$.  Therefore 
\[ [\psi(x)-\psi(y)]^2 K(x,y) \leq |x-y|^{-1} \wedge |x-y|^{2\gamma-3}. \]
If $3-2\gamma > 2$ then this quantity is integrable.  Thus
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \lesssim \int \theta_+ u \cdot \grad \psi + \int \indic{\theta_+>0}.\]

%\begin{align*}
%\iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) &\leq \eps \iint [\theta_+(x)-\theta_+(y)]^2 K(x,y) + \frac{1}{\eps} \iint_{\theta_+(x) > 0 \textrm{ or } \theta_+(y) > 0} [\psi(x)-\psi(y)]^2 K(x,y)
%\\ &\leq \eps \int \abs{\Lambda^{1/2} \theta_+}^2 + \frac{2}{\eps} \int \indic{\theta_+>0}(x)\int [\psi(x)-\psi(y)]^2 K(x,y)\,dy\,dx.
%\end{align*}

For the drift term, let's say that $u$ is broken down into $u_l$ and $u_h$ (standing for high-pass and low-pass) and that they have the desired properties.  

For the high-pass term, for each $i = 1,2$,
\[ \int (u_l)_i \theta_+ \del_i \psi = \int \Lambda^{-1/4} u_l \Lambda^{1/4} (\theta_+ \grad \psi) \leq \paren{\int \abs{\Lambda^{1/4} \theta_+ \grad \psi}^2}^{1/2} \leq \]

We're looking at $\int g \Lambda^{1/4} \theta_+$ where $\Lambda^{1/4} g = u_h$ and $g \in L^\infty$.  This breaks down as
\[ \iint [g-g^*][\theta_+-\theta_+^*] K_{1/4} + \int g \theta_+ B_{1/4}. \]

For a given parameter $\lambda$, break up into the region where $|x-y|$ is bigger and smaller than $\lambda$.  Considering the bigger part,
\[ \iint_{\geq \lambda} [g-g^*][\theta_+ - \theta_+^*] K_{1/4} \leq 2 (2 \norm{g}_\infty) \iint_{\geq \lambda} |\theta_+ - \theta_+^*| \frac{dxdx^*}{|x-y|^{2+1/4}} \leq 8 \lambda^{-2.25} \norm{g}_\infty \norm{\theta_+}_1. \]

The $B$ part may be a real problem.  The $g$ means it doesn't have a sign, so we actually have to bound it.  Consider this.  
\begin{align*}
\int g \theta_k B_{1/4} &\leq \norm{g}_\infty \int \theta_{k-1} \theta_k B_{1/4}
\\ &\leq \norm{g}_\infty \int \theta_{k-1}^2 B_{1/4}
\\ &\leq \norm{g}_\infty \int \abs{\Lambda^{1/8} \theta_{k-1}}^2.
\end{align*} 

Lastly, we have the near part.  
\begin{align*} 
\iint_{< \lambda} [g-g^*][\theta_+ - \theta_+^*] K_{1/4} &\leq 2\iint_{<\lambda} \chi_+ [g-g^*]^2 |x-y|^{3/4} K_{1/4} + \iint_{<\lambda} [\theta_+-\theta_+^*]^2 |x-y|^{-3/4} K_{1/4} 
\\ &\leq 4 \norm{g}_\infty^2 \int \chi_+ \int_{<\lambda} |x-y|^{-1.5} + \iint_{<\lambda} [\theta_+-\theta_+^*]^2 K_1
\\ &\leq \norm{g}_\infty^2 \lambda^{1/2} \abs{\chi_+} + \int \abs{\Lambda^{1/2} \theta_+}^2
\end{align*}

Taken together,
\[ \int \Lambda^{-1/4} \theta_+ u_h \cdot \grad \psi \leq \frac{1}{2} \int \abs{\Lambda^{1/2} \theta_+ \grad \psi} + \int \chi_+ + \int \theta_+ + \int \theta_+ \grad \psi B_{1/4}. \]


\section{Control on $u$}
Let's assume that our drift term is a sum of $u_j$ for $j \in \Z$ and a constant which is tbd.  Assume that each $u_j$ is an $L^\infty$ function, and that their sum converges to $u$ in $L^2(\Omega)$, and that each $u_j$ specfies the bounds as stated.  First we show that they sum up to $u_h$ and $u_l$ in the ways desired.  Then we show that the properties required are maintained as we zoom.  Then at last we argue that, before any zooming, $u$ really does have this property.  

Firstly, assume that 
\[ u = \lim_{L^2} \sum_{-N}^N u_j, \]
\begin{align*} 
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j. 
\end{align*}
We then define
\[ u_h = \sum_{j=0}^\infty u_j \]
and 
\[ u_\ell = \sum_{-\infty}^{j=-1} u_j. \]

Since $u_j \in L^\infty$ in particular they are $L^2$ functions which sum in $L^2$.  Remember that only finitely many negative $j$ have $u_j \neq 0$.  The sequence $u_j$ is thus singly infinite and in particular is a Cauchy sequence, so $u_h$ also converges in $L^2$.  Since $\Lambda^{-1/4}$ is a continuous linear operator, it passes to the partial sums and so
\[ \Lambda^{-1/4} u = \lim_{L^2} \sum_{j=0}^\infty \Lambda^{-1/4} u_j. \]
In particular, the sum converges in the sense of distributions, i.e. in $\test(\Omega)'$.  Since test functions are dense in $L^1(\Omega)$, and the partial sums are uniformly bounded in the dual of $L^1(\Omega)$ (namely $L^\infty(\Omega)$), therefore the limit $\Lambda^{-1/4} u_h$ is also bounded in the dual of $L^1(\Omega)$.  
\[ \norm{\Lambda^{-1/4} u_h}_\infty \leq \sum_{j=0}^\infty \norm{\Lambda^{-1/4} u_j}_\infty \leq \kappa \frac{1}{1-2^{-1/4}}. \]

As for $u_\ell$, we have that $\sum_{j < 0} u_j$ converges in $L^2$, and hence also in the sense of distributions $\test(\Omega)'$.  Since $\grad$ is continuous on distributions, also $\sum_{j<0} \grad u_j$ converges to $\grad u_\ell$.  But each partial sum is uniformly bounded in the dual of $L^1(\Omega)$, meaning that the limit $\grad u_\ell$ is also bounded in the dual, $L^\infty(\Omega)$.  
\[ \norm{\grad u_\ell}_\infty \leq \sum_{j < 0} \norm{\grad u_j}_\infty \leq \kappa \frac{1/2}{1 - 2^{-1}} = \kappa. \]

\begin{lemma}{Scaling}
Suppose that $\theta$ solves the PDE
\[ \bracket{\del_t + u\cdot\grad + \Lambda} \theta = 0\]
where the velocity $u$ satisfies
\[ u = \upsilon(t) + \sum_{j=-\infty}^\infty u_j \]
with that sum converging in $L^2(\Omega)$ and with $\upsilon$ being constant in space and $u$ divergence free.  Suppose that the domain of definition is $(-T,0) \times \Omega$, and $0 \in \del \Omega$.  Suppose that
\begin{align*}
\upsilon(t) &= \sum_{j<0} u_j(t,0), \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j.
\end{align*}

Let $\eps$ be a small constant which is a power of 2, $\eps = 2^{-N}$. Then there exists some $\gamma: [-T/\eps ,0] \to \R^2$ such that
\[ \bar{\theta}(t,x) = \theta(\eps t, \eps x + \gamma(\eps t)) \]
satisfies all of the same constraints for $(t,x) \in [-T/\eps, 0]\times \Omega_\eps$.  
\end{lemma}

\begin{proof}
Denote $p = (t,x)$ and $\bar{p} = (\eps t, \eps x + \gamma(\eps t))$.  

We calculate
\[ \del_t \bar{\theta}(p) = \eps \del_t \theta(\bar{p}) + \eps \dot{\gamma}(\bar{p}) \cdot \grad \theta (\bar{p}) \]
and 
\[ \grad \bar{\theta}(p) = \eps \grad \theta(\bar{p}) \]
and
\[ \Lambda \bar{\theta}(p) = \eps \Lambda \theta(\bar{p}). \]

Thus, if we define
\[ \bar{u}(p) = u(\bar{p}) - \dot{\gamma}(\bar{p}) \]
then it will be the case that, for $p \in [-T/\eps,0]\times \Omega_\eps$, 
\[ \bracket{\del_t + \bar{u}\cdot\grad + \Lambda} \bar{\theta}(p) = \eps \bracket{\del_t + u\cdot\grad + \Lambda} \theta(\bar{p}). \]

It remains to demonstrate the decomposition of $\bar{u}$ and that $\bar{\gamma}$ still makes $\bar{u}_\ell(0)=0$, let alone that $0$ is still on the boundary of $\Omega_\eps$.  

Recall that for a positive integer $N$, $2^N \eps = 1$.  We define 
\[ \bar{u}_j(p) := u_{j+N}(\bar{p}), \]
that is each $u_j$ is scaled appropriately and then the labels are shifted by $N$.  Our new decomposition of $\bar{u}$ is
\begin{align*} 
\bar{u}(p) &= u(\bar{p}) - \dot{\gamma}(\bar{p})
\\ &= \upsilon(\bar{p}) + \sum u_j(\bar{p}) + \dot{\gamma}(\bar{p})
\\ &= \bracket{\upsilon(\bar{p}) + \dot{\gamma}(\bar{p})} + \sum \bar{u}_j (p)
\end{align*}
which means
\[ \bar{\upsilon}(p) = \upsilon(\bar{p}) + \dot{\gamma}(\bar{p}). \]

We easily bound the $\bar{u}_j$:
\begin{align*}
\norm{\Lambda^{-1/4} \bar{u}_j}_\infty &= \eps^{-1/4}\norm{\Lambda^{-1/4} u_{j+N}}_\infty 
\\ &\leq \eps^{-1/4} \kappa 2^{-(j+N)/4}
\\ &= (\eps 2^N)^{-1/4} \kappa 2^{-j/4} = \kappa 2^{-j/4}.
\end{align*}
Also,
\begin{align*}
\norm{\grad \bar{u}_j}_\infty &= \eps \norm{\grad u_{j+N}}_\infty
\\ &\leq \eps \kappa 2^{j+N} = \kappa 2^j.
\end{align*}

To confirm the desired properties of $\bar{\upsilon}$, we want to say that
\[ \bar{\upsilon}(t) = \sum_{j<0} \bar{u}_j(t,0) \]
or equivalently
\[ \dot{\gamma}(\eps t) = -\upsilon(\eps t) +  \sum_{j<0} u_{j+N}(\eps t, \gamma(\eps t)). \]
By the Caratheodory Existence theorem, there exists a function $\gamma$ which satisfies this relationship for a.e. $t \in [-T/\eps, 0]$.  I can choose the initial condition, and I don't know what I want, so how about $\gamma(0)=0$.  

In fact, since $-\upsilon(t) + \sum_{j<-N} u_{j+N}(t,0)$ vanishes by assumption, we can say in fact that 
\[ -\upsilon(t) +  \sum_{j<0} u_{j+N}(t, 0) = \sum_{j=0}^{N-1} u_j(t,0) \leq N \norm{u_j}_\infty. \]
Here it's relevant that $\norm{u_j}_\infty$ is independent of $j$, which I know but have not proven or even stated before.  Since $\sum_{j<N} u_j$ is a Lipschitz function, with Lipschitz constant $\kappa 2^N$, we can bound $\gamma$
\[ \dot{\gamma}(t) \leq N \norm{u_j}_\infty + \kappa 2^N |\gamma(t)|. \]
That's a Lipschitz bound on $\gamma$.  It becomes a real bound
\[ \gamma(t) \leq N 2^{-N} (\exp(\kappa 2^N t)-1). \]

All that remains is the most important part.  Showing that our $\gamma$ is small enough and of the correct nature such that the information we get about $\bar{\theta}$ will be useful.  

For example, we probably want that $\gamma(t) \in \del \Omega$ for all $t$.  Why would that be true?  It's actually not.  No matter what $\gamma$ is, the $u_j$ terms point along the boundary and hence they can never turn $\dot{\gamma}$ in a direction so as to go ``off the rails'' so to speak.  On the other hand, $\upsilon$ is only tangential at the origin.  Elsewhere, $\upsilon$ might as well have a tangential component.  

Wait, I'm adding $\dot{\gamma}$ to $\upsilon$.  But $\upsilon$ is a scalar, it's the value of $u_\ell$ at 0, while $\dot{\gamma}$ is a vector, it's the time derivative of a moving point in $\R^2$.  That seems off.  No way man, $u$ is vector valued, so $\upsilon$ is too.  All good.  

Let's get to it.  Define
\[ f(t,x) = -\upsilon(t) + \sum_{j < N} u_j(t,x). \]
This function is Lipschitz in $x$, with constant $\kappa 2^N$.  Morever, $f(t,0) \leq \kappa N$.  

It's important that $(t,0) \mapsto (\eps t, \gamma(\eps t))$ is on the boundary of $\Omega$.  So we want that $\dot{\gamma}(t)$ is pointing along the boundary of $\Omega$ at $\gamma(t)$.  


\end{proof}

New idea is to drop all the $\gamma$ nonsense.  Instead, we argue that even though $u_\ell(t,0)$ is large in the $L^\infty(L^\infty)$ sense, it is small in the $L^1(L^\infty)$ sense (that's integration in time).  This makes sense, because every time we zoom in by $\eps = 2^N$, we increse the $L^\infty(\Omega)$ norm by $\kappa N$ but we also shrink the time interval by $2^N$.  I believe that this is essentially the property that we exploit in the drift formulation, namely that the correction term $\gamma$ may be large in principle but $\dot{\gamma}$ is small so over small enough time intervals, $\gamma$ is small.  It's important that the $L^1(L^\infty)$ norm not only grow slowly but actually grow in a summable manner, so that after 1 million zooms still the error introduced is bounded.  

Even if we can do all that, how do we formulate that error term and how do we deal with it in the energy inequality?  Well, let's say that
\[ u_\ell = \tau + \sigma \]
where $\tau$ is a function of time alone and $\sigma$ is both Lipschitz in space and $\sigma(t,0) = 0$.  The Lipschitz constant of $\sigma$ grows with each zoom, in such a way as to effectively cancel out the gains we get from zooming so the effective $L^\infty$ norm remains constant.  Similarly, the quantitative bound on $\tau$ grows with each zoom in such a way as to cancel out the gains of zooming so that its integral remains constant.  

Now in the energy inequality, we have three terms $u = \tau + \sigma + u_h$.  Remember that the energy inequality contains
\[ \iint \theta_+ u \cdot \grad \psi. \]
We bound this integral using the duality pairing, $L^1(L^\infty)$ vs $L^\infty(L^2)$ and absorb the $\theta_+$ into the $\sup \int \theta_+^2$ term on the left hand side.  We do some pro forma nonsense to keep a factor of $\int \chi_+$ involved on the remainder and zoop zop wop we're done.  I'm a genius.  









\end{document}