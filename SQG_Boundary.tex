\documentclass[11pt]{amsart}
\usepackage{amssymb,amsbsy,upref,epsf,MnSymbol}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,mathtools,mathrsfs,wrapfig}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}



%-------------------------------------------<commands>--------------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Prj}{\mathbb{P}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\Four}{\mathcal{F}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\eps}{\varepsilon}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\chevron}[1]{\langle #1 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\convex}{conv}
\DeclareMathOperator{\image}{Im}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\lspan}{span}
\DeclareMathOperator{\conv}{conv} % stands for conv, as in convex hull
\DeclareMathOperator{\Int}{int} % stands for int, as in interior of a set
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\rank}{rank}
%\DeclareMathOperator{\dim}{dim}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\cod}{\operatorname{cod}}
\newcommand{\Hom}{\operatorname{hom}}
\newcommand{\Ob}{\operatorname{Ob}}
\newcommand{\cl}{\operatorname{cl}}
\DeclareMathOperator{\BMO}{BMO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\del}{\partial}
\newcommand{\pvec}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\grad}{\nabla}
\newcommand{\ddt}{\frac{d}{dt}}
\renewcommand{\div}{\operatorname{div}}
\newcommand{\Laplace}{\Delta}
\newcommand{\kinet}{\bracket{\del_t + v\cdot \grad_x}}
\newcommand{\bessel}{\paren{1-\Laplace_v}}
\newcommand{\loc}{\text{loc}}
\newcommand{\ddz}{\frac{d}{dz}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\into}{\hookrightarrow}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\isom}{\cong}
\newcommand{\rest}{{\upharpoonright}}
\newcommand{\weakly}{\rightharpoonup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ith}{^\mathrm{th}}
\newcommand{\n}{^{-1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\indic}[1]{\chi_{\{#1\}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\eigen}[1]{\eta_{#1}} %my eigenfunctions
\newcommand{\Ctest}{C_c^\infty}
\newcommand{\test}{\mathcal{D}}

\newcounter{step_count}[section]
\newcommand{\step}[1]{\stepcounter{step_count} \smallskip \noindent{\textbf{Step \arabic{step_count}:} #1}}


%-------------------------------------------</commands>--------------------------------------------------------

%\newcommand{\draftnum}{1}%-----------------------------UPDATE DRAFT NUM----------------------------------------

\title{SQG Boundary, \today}

\author[Stokols]{Logan F. Stokols} 
\address[L. F. Stokols]{\newline Department of Mathematics, \newline The University of Texas at Austin, Austin, TX 78712, USA}
\email{lstokols@math.utexas.edu}

\date{\today}

%\subjclass[2010]{35H10,35B65,47G20,35Q84} % hypoellptic, regularity, integro-differential, fokker-planck
%\keywords{Fokker-Planck Equation, Fractional Laplacian, H\"older regularity,  De Giorgi method}

%\thanks{\textbf{Acknowledgment.} This work was partially supported by the NSF Grant DMS 1614918. }

\begin{document}




\maketitle \centerline{\date}

We're gonna consider the equation 
\begin{equation}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ u = \grad^\perp \Lambda\n \theta.
\end{equation}

Here the operator 
\[ \Lambda := \sqrt{-\Laplace_D} \]
where $\Laplace_D$ is the Laplacian with Dirichlet boundary condition.  

We're going to linearize the equation by fixing $u$ independent of $\theta$.  What property do we want $u$ to have?  For some constant $\kappa$, we'll want
\begin{align*} 
u &= \sum_{j \in \Z} u_j, \\
\norm{u_j}_\infty \leq \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j. 
\end{align*}
The convergence of that sum is in, say, weak $L^2$.  

Recall the notation
\[ \bracket{f}_\alpha := \sup_{x,y \in \Omega, x \neq y} \frac{|f(x)-f(y)|}{|x-y|^\alpha}. \]


\section{Lemmas}

\begin{lemma}
If $f$ and $g$ are non-negative functions with disjoint support (i.e. $f(x)g(x) = 0$ for all $x$), then 
\[ \int \Lambda^s f \Lambda^s g \,dx \leq 0. \]
\end{lemma}

This proves, in particular, that $-\int \theta_+ \Lambda \theta_-$ is a positive term (hence dissipational and extraneous) and that $\int \Lambda^{1/2} (\theta-\psi) \Lambda^{1/2} (\theta-\psi)$ breaks down (bilinearly) into the doubly positive, the doubly negative, and the cross term, all of which are positive and hence each of which is positive.  

\begin{proof}
Use the characterization from Caffarelli-Stinga.  There exist non-negative functions $K(x,y)$ and $B(x)$, depending on the parameter $s$, such that
\[ \int \Lambda^s f \Lambda^s g \,dx = \iint [f(x)-f(y)][g(x)-g(y)] K(x,y) \,dxdy + \int f(x) g(x) B(x) \,dx. \]

Since $f$ and $g$ are non-negative and disjoint, the $B$ term vanishes.  Moreover, the product inside the $K$ term becomes
\[ [f(x)-f(y)][g(x)-g(y)] = -f(x)g(y)-f(y)g(x) \leq 0. \]
Since $K$ is non-negative, the result follows.  
\end{proof}

\begin{lemma}
For all functions $f$ in $H_D^1$,
\[ \int \abs{\grad f}^2 = \int \abs{\Lambda f}^2. \]

Moreover, if $f \in H_D^1$ then $\trace(f)=0$.  
\end{lemma}

\begin{proof}
Let $\eigen{i}$ and $\eigen{j}$ be two eigenfunctions of the Dirichlet Laplacian on $\Omega$.  Note that these functions are smooth in the interior of $\Omega$.  Because $\Omega$ has Lipschitz boundary, and because $\eigen{i} \grad \eigen{j}$ is smooth on $\Omega$ and countinuous and bounded on $\overline{\Omega}$ vanishing on the boundary, therefore 
\[ \int_\Omega \div(\eigen{i} \grad \eigen{j}) = \int_{\del \Omega} \eigen{i} \grad \eigen{j}. \]
But $\eigen{i} \grad \eigen{j}$ vanishes on the boundary, so the right hand side vanishes.  Moreover, $\div(\eigen{i} \grad \eigen{j}) = \grad \eigen{i} \cdot \grad \eigen{j} + \eigen{i} \Laplace \eigen{j}$.  Therefore
\[ \int \grad \eigen{i} \cdot \grad \eigen{j} = - \int \eigen{i} \Laplace \eigen{j} = \lambda_k \int \eigen{i} \eigen{j}. \]
Of course, the inner product of two eigenfunctions is 0 unless they are the same eigenfunction, in which case it is 1.  

Consider a function $f = \sum f_k \eigen{k}$ which is an element of $H_D^1$, by which we mean $\sum \lambda_k f_k^2 < \infty$.  Since $\norm{\grad \eigen{k}}_{L^2(\Omega)} = \sqrt{\lambda_k}$, the following sums all converge in $L^2(\Omega)$ and hence the calculation is justified:
\begin{align*}
\int \abs{\grad f}^2 &= \int \paren{\sum_i f_i \grad \eigen{i} } \paren{\sum_j f_j \grad \eigen{j}}
\\ &= \int \sum_{i,j} (f_i f_j) \grad \eigen{i} \cdot \grad \eigen{j}
\\ &= \sum_{i,j} (f_i f_j) \int \grad \eigen{i} \cdot \grad \eigen{j}.
\end{align*}
Since this double-sum vanishes except on the diagonal, we see from [citation] that in fact
\[ \norm{\grad f}_{L^2(\Omega)} = \norm{\Lambda f}_{L^2(\Omega)}. \]

To see that $\trace(f)$ vanishes, note that $f = \sum_{k=0}^\infty f_k \eigen{k}$ and that each finite partial sum for this series satisfies the Dirichlet boundary condition.  Since $\trace$ is a bounded operator on $H^1$, we need only show that this series is Cauchy in $H^1$, in which case its $H^1$ limit will exist and be equal to its $L^2$ limit which will be equal to $f$.  

For each $k$,
\[ \norm{ f_k \eigen{k} }_{H^1} \leq C_\textrm{Poincare} f_k \norm{\grad \eigen{k}}_2 = C f_k \sqrt{\lambda_k}. \]
This sequence is $\ell^2$ summable, since $f \in H_D^1$ by assumption.  Therefore $f$, being an $H^1$ limit of functions with vanishing trace, also has vanishing trace.  
\end{proof}

\begin{lemma}
For any function $f$, and any $0 < s < 1$,
\[ \int \abs{\Lambda^s f}^2 \simeq \int \abs{\paren{-\Laplace}^{s/2} \bar{f}}^2. \]
Here $\bar{f}$ is the extension of $f$ to $\R^2$ and $\paren{-\Laplace}^s$ is defined in the fourier sense.  
\end{lemma}

\begin{proof}
Let $g$ be any Schwarz function in $L^2(\R^2)$, and let $f$ be a function in $H^{s+1}_D$.  Let $E:H^1(\Omega) \to H^1(\R^2)$ be a bounded extension operator, where $H^1$ denotes the classical Sobolev space defined using the gradient.  Define the function
\[ \Phi(z) = \int_{\R^2} \paren{-\Laplace}^{z/2} g E \Lambda^{s-z} f. \]

When $\Re(z) = 0$, then $\norm{\paren{-\Laplace}^{z/2} g}_2 = \norm{g}_2$ and $\norm{\Lambda^{s-z} f}_2 = \norm{\Lambda^s f}_2$.  Hence
\[ \Phi(z) \leq \norm{g}_2 \norm{f}_{H^s_D}. \]

When $\Re(z)=1$, then $\norm{\paren{-\Laplace}^{(z-1)/2} g}_2 = \norm{g}_2$ and 
\[ \norm{\paren{-\Laplace}^{1/2} E\Lambda^{s-z} f}_{L^2(\R^2)} = \norm{\grad E \Lambda^{s-z} f}_{L^2(\R^2)} \leq \norm{E} \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)}. \]
It remains to ask whether $\Lambda^{s-z} f$ is in $H^1_D$ so that we can apply lemma [citation].  However, this is true based on our assumption $f \in H^{1+s}_D$, since the various powers of $\Lambda$ all commute and form a semigroup.  Ergo
\[ \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)} = \norm{\Lambda \Lambda^{s-z} f}_2 \leq \norm{\Lambda^s f}_2 \]
and we can bound
\[ \Phi(z) \leq \norm{E} \norm{g}_2 \norm{f}_{H^s_D}. \]

Now we will bound the derivative of $\Phi(z)$.  Specifically, compute the derivative in $z$ of the integrand, for $0<\Re(z)<1$, and hope that it is integrable.  To this end, we rewrite the integrand of $\Phi$ as
\[ \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k. \]
The derivative $\ddz$ commutes with linear operators like $\Four\n$ and $E$, so the derivative is
\[ \Four\n\paren{ \ln(|\xi|) |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k + \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \frac{-1}{2} \ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} f_k. \]

Since $0<\Re(z)<1$, $\ln(|\xi|)|\xi|$ is bounded as a multiplier operator from Schwarz functions to $L^2$.  Moreover, $\ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} \leq C \lambda_k^{\frac{s-z+\eps}{2}}$ for some $C$ independent of $k$ but dependent on $z$, $\eps$.  Since $f \in H^{1+s}_D$ this sum converges in $L^2$, in fact in $H_D^1$.  This makes our differentiated integrand a sum of two $H^1$ functions with compact support multiplied by two Schwarz functions.  In particular it is integrable, which means we can interchange the integral sign and the derivative $\ddz$ and prove that $\Phi'(z)$ is finite for all $0<\Re(z)<1$. 

This is sufficient now to apply the Hadamard three-lines lemma to our function $\Phi$.  

It follows that for any Schwarz function $g \in L^2(\R^n)$ and $H_D^{s+1}$ function $f$, 
\[ \int_{\R^2} \paren{-\Laplace}^{s/2} g E f = \Phi(s) \leq \norm{g}_{L^2(\R^2)} \norm{f}_{H_D^s}. \]

Since Schwarz functions are dense in $L^2(\R^2)$, this means by density that 
\[ \int \abs{ \paren{-\Laplace}^{s/2} E f }^2 \leq \int \abs{\Lambda^s f}^2 \]
or in other words it means that $E$ is a bounded operator from $H_D^s$ to $H^s$, at least on the subset $H_D^{s+1} \cap H_D^s$.  It remains to extend this bound to the whole space by density.  

We know from [citation] Caffarelli and Stinga that $\test(\Omega)$ is dense in $H_D^s$ for all $0 \leq s < 1$.  In fact, this takes a bit of interpretation, so I ought to illucidate that this is because $H_D^s = H_0^s$ (the latter in the Slobodekij sense) for most $s$ and at $s=1/2$ we get the Lions-Magenes spaces which still has $\test(\Omega)$ dense.  

Surely, right(?), test functions are all inside of $H_D^{1+s}$.  I should meditate on this, but it must be true.  
\end{proof}


\section{De Giorgi Estimates}

First let us derive an energy inequality.  

We know a priori that $\theta \in L^\infty(0,T; L^2(\Omega)) \cap L^2(0,T; H_D^{1/2}(\Omega))$.  Let $\psi: \Omega \to \R^+$ be a non-negative function in $H_D^{1/2}$ non-uniformly, and define $\theta = \theta_+ + \psi - \theta_-$.  Since $\theta - \psi$ is in $H_D^{1/2}$, by the lemma above, both $\theta_+$ and $\theta_-$ are in that space as well.  In particular, our weak solution can eat $\theta_+$.  

\begin{lemma}[Caccioppoli Estimate]
Let $\theta \in L^2(0,T; H_D^{1/2}(\Omega))$ and $u \in L^\infty(0,T; L^2(\Omega))$ solve
\begin{align*}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ \div u = 0
\end{align*}
in the sense of distributions.  Let $\psi \in L^\infty(0,T; H_D^{1/2}(\Omega))$ be non-negative, Lipschitz-in-space, and H\"{o}lder continuous-in-space with exponent $\gamma < 1/2$.  Then the decomposition
\[ \theta = \theta_+ + \psi - \theta_- \]
satisfies the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (\del_t \psi + u\cdot\grad\psi) } \]
with the constant $C$ depending on $\norm{\grad \psi}_\infty$ and $\sup_t \bracket{\psi(t,\cdot)}_\gamma$.  

\end{lemma}

\begin{proof}
We decompose $\theta-\psi = \theta_+ - \theta_-$ with both $\theta_+$ and $\theta_-$ non-negative and having disjoint support.  Since at a.e. time $t$ $\theta$ and $\psi$ are both in $H_D^{1/2}$, we can write
\[ \infty > \int \abs{\Lambda^{1/2}(\theta_+-\theta_-)}^2 = \int \abs{\Lambda^{1/2}\theta_+}^2 + \int \abs{\Lambda^{1/2} \theta_-}^2 - \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-. \]
By a lemma proved above, the final term (by disjoint support) is non-positive, hence all three terms are finite and in particular $\theta_+$ and $\theta_-$ are in $H_D^{1/2}$ at a.e. time.  

We can therefore multiply our equation [cite] by $\theta_+$ and integrate in space to obtain
\[ 0 = \int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \paren{\theta_+ + \psi - \theta_-} \]
which decomposes into three terms, corresponding to $\theta_+$, $\psi$, and $\theta_-$.  We analyze them one at a time.  

Firstly,
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_+ &= (1/2) \ddt \int \theta_+^2 + (1/2) \int \div u \, \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2
\\ &= (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2.
\end{align*}

The $\psi$ term produces important error terms:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \psi &= \int \theta_+ \del_t \psi + \int \theta_+ u \cdot \grad \psi + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\\ &= \int \theta_+ (\del_t \psi + u \cdot \grad \psi) + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\end{align*}

Since $\theta_+$ and $\theta_-$ have disjoint support, the $\theta_-$ term is nonnegative by lemma [citation]:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_- &= (1/2) \int \theta_+ \del_t \theta_- + \int \theta_+ u \cdot \grad \theta_- + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-
\\ &= \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_- \leq 0.
\end{align*}

Put together, we arrive at 
\[ (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 + \iint \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \leq \abs{\int \theta_+ (\del_t \psi + u \cdot \grad \psi) \cdot \grad \psi}. \]

At this point we break down the $\Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi$ term using the formula from [citation] Caffarelli-Stinga.  
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi = \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) + \int \theta_+ \psi B. \]
Since $B \geq 0$ (see Caff-Stinga [citation]) and $\psi$ is non-negative by assumption, the $B$ term is non-negative and so
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \geq \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y). \]
The remaining integral is symmetric in $x$ and $y$, and the integrand is only nonzero if at least one of $\theta_+(x)$ and $\theta_+(y)$ is nonzero.  Hence
\[ \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) \leq 2 \iint \indic{\theta_+>0}(x) \abs{[\theta_+(x)-\theta_+(y)][\psi_t(x)-\psi_t(y)]} K(x,y). \]
Now we can break up this integral using the Peter-Paul variant of H\"{o}lder's inequality.  
\[ \abs{\iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y)} \leq \eps \int \abs{\Lambda^{1/2}\theta_+}^2 + \frac{1}{\eps} \iint \indic{\theta_+>0}(x) [\psi(x)-\psi(y)]^2 K(x,y). \]

It remains to bound the quantity $[\psi(x)-\psi(y)]^2 K(x,y)$.  By Caffarelli-Stinga theorem 2.4 [citation], there is a universal constant $C$ such that
\[ K(x,y) \leq \frac{C}{|x-y|^{3}}. \]
The cutoff $\psi$ is Lipschitz, and H\"{o}lder continuous with exponent $\gamma < 1/2$ by assumption.  Therefore 
\[ [\psi(x)-\psi(y)]^2 K(x,y) \leq |x-y|^{-1} \wedge |x-y|^{2\gamma-3}. \]
Since $3-2\gamma > 2$, this quantity is integrable.  Thus
\[ \int \indic{\theta_+>0}(x) \int [\psi(x)-\psi(y)]^2 K(x,y) \,dxdy \leq C(\norm{\psi}_\textrm{Lip}, \bracket{\psi}_\gamma) \int \indic{\theta_+>0} \,dx. \]
Combining [citation, like 4 different things are combined] we arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \lesssim \int \theta_+ (\del_t\psi+u\cdot\grad\psi) + \int \indic{\theta_+>0}.\]
\end{proof}

We've completed the essential version of the Caccioppoli inequality.  However, much more can be said about the drift-term $u$.  In particular, we can design a cutoff $\psi$ in order to minimize the expression $\del_t \psi + u\cdot\grad\psi$.  

For the drift term, let's say that $u$ is broken down into $u_l$ and $u_h$ (standing for high-pass and low-pass) and that they have the desired properties.  

For the high-pass term, for each $i = 1,2$,
\[ \int (u_l)_i \theta_+ \del_i \psi = \int \Lambda^{-1/4} u_l \Lambda^{1/4} (\theta_+ \grad \psi) \leq \paren{\int \abs{\Lambda^{1/4} \theta_+ \grad \psi}^2}^{1/2} \leq \]

We're looking at $\int g \Lambda^{1/4} \theta_+$ where $\Lambda^{1/4} g = u_h$ and $g \in L^\infty$.  This breaks down as
\[ \iint [g-g^*][\theta_+-\theta_+^*] K_{1/4} + \int g \theta_+ B_{1/4}. \]

For a given parameter $\lambda$, break up into the region where $|x-y|$ is bigger and smaller than $\lambda$.  Considering the bigger part,
\[ \iint_{\geq \lambda} [g-g^*][\theta_+ - \theta_+^*] K_{1/4} \leq 2 (2 \norm{g}_\infty) \iint_{\geq \lambda} |\theta_+ - \theta_+^*| \frac{dxdx^*}{|x-y|^{2+1/4}} \leq 8 \lambda^{-2.25} \norm{g}_\infty \norm{\theta_+}_1. \]

The $B$ part may be a real problem.  The $g$ means it doesn't have a sign, so we actually have to bound it.  Consider this.  
\begin{align*}
\int g \theta_k B_{1/4} &\leq \norm{g}_\infty \int \theta_{k-1} \theta_k B_{1/4}
\\ &\leq \norm{g}_\infty \int \theta_{k-1}^2 B_{1/4}
\\ &\leq \norm{g}_\infty \int \abs{\Lambda^{1/8} \theta_{k-1}}^2.
\end{align*} 

Lastly, we have the near part.  
\begin{align*} 
\iint_{< \lambda} [g-g^*][\theta_+ - \theta_+^*] K_{1/4} &\leq 2\iint_{<\lambda} \chi_+ [g-g^*]^2 |x-y|^{3/4} K_{1/4} + \iint_{<\lambda} [\theta_+-\theta_+^*]^2 |x-y|^{-3/4} K_{1/4} 
\\ &\leq 4 \norm{g}_\infty^2 \int \chi_+ \int_{<\lambda} |x-y|^{-1.5} + \iint_{<\lambda} [\theta_+-\theta_+^*]^2 K_1
\\ &\leq \norm{g}_\infty^2 \lambda^{1/2} \abs{\chi_+} + \int \abs{\Lambda^{1/2} \theta_+}^2
\end{align*}

Taken together,
\[ \int \Lambda^{-1/4} \theta_+ u_h \cdot \grad \psi \leq \frac{1}{2} \int \abs{\Lambda^{1/2} \theta_+ \grad \psi} + \int \chi_+ + \int \theta_+ + \int \theta_+ \grad \psi B_{1/4}. \]


\section{Control on $u$}
Let's assume that our drift term is a sum of $u_j$ for $j \in \Z$ and a constant which is tbd.  Assume that each $u_j$ is an $L^\infty$ function, and that their sum converges to $u$ in $L^2(\Omega)$, and that each $u_j$ specfies the bounds as stated.  First we show that they sum up to $u_h$ and $u_l$ in the ways desired.  Then we show that the properties required are maintained as we zoom.  Then at last we argue that, before any zooming, $u$ really does have this property.  

Firstly, assume that 
\[ u = \lim_{L^2} \sum_{-N}^N u_j, \]
\begin{align*} 
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j. 
\end{align*}
We then define
\[ u_h = \sum_{j=0}^\infty u_j \]
and 
\[ u_\ell = \sum_{-\infty}^{j=-1} u_j. \]

Since $u_j \in L^\infty$ in particular they are $L^2$ functions which sum in $L^2$.  Remember that only finitely many negative $j$ have $u_j \neq 0$.  The sequence $u_j$ is thus singly infinite and in particular is a Cauchy sequence, so $u_h$ also converges in $L^2$.  Since $\Lambda^{-1/4}$ is a continuous linear operator, it passes to the partial sums and so
\[ \Lambda^{-1/4} u = \lim_{L^2} \sum_{j=0}^\infty \Lambda^{-1/4} u_j. \]
In particular, the sum converges in the sense of distributions, i.e. in $\test(\Omega)'$.  Since test functions are dense in $L^1(\Omega)$, and the partial sums are uniformly bounded in the dual of $L^1(\Omega)$ (namely $L^\infty(\Omega)$), therefore the limit $\Lambda^{-1/4} u_h$ is also bounded in the dual of $L^1(\Omega)$.  
\[ \norm{\Lambda^{-1/4} u_h}_\infty \leq \sum_{j=0}^\infty \norm{\Lambda^{-1/4} u_j}_\infty \leq \kappa \frac{1}{1-2^{-1/4}}. \]

As for $u_\ell$, we have that $\sum_{j < 0} u_j$ converges in $L^2$, and hence also in the sense of distributions $\test(\Omega)'$.  Since $\grad$ is continuous on distributions, also $\sum_{j<0} \grad u_j$ converges to $\grad u_\ell$.  But each partial sum is uniformly bounded in the dual of $L^1(\Omega)$, meaning that the limit $\grad u_\ell$ is also bounded in the dual, $L^\infty(\Omega)$.  
\[ \norm{\grad u_\ell}_\infty \leq \sum_{j < 0} \norm{\grad u_j}_\infty \leq \kappa \frac{1/2}{1 - 2^{-1}} = \kappa. \]

\begin{lemma}{Scaling}
Suppose that $\theta$ solves the PDE
\[ \bracket{\del_t + u\cdot\grad + \Lambda} \theta = 0\]
where the velocity $u$ satisfies
\[ u = \sum_{j=-\infty}^\infty u_j \]
with that sum converging in $L^2(\Omega)$.  Suppose that the domain of definition is $(-T,0) \times \Omega$, and $0 \in \del \Omega$.  Suppose that
\begin{align*}
\norm{u_j}_\infty &\leq \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j.
\end{align*}

Let $\eps$ be a small constant which is a power of 2, $\eps = 2^{-N}$. Then
\[ \bar{\theta}(t,x) = \theta(\eps t, \eps x) \]
satisfies all of the same constraints for $(t,x) \in [-T/\eps, 0]\times \Omega_\eps$.  

Moreover, 
\[ \norm{\sum_{j=-\infty}^0 \bar{u}_j(t,0) - \sum_{j=-\infty}^0 u_j(\eps t, 0)}_\infty \leq \kappa N. \]
\end{lemma}

\begin{proof}
Denote $p = (t,x)$ and $\bar{p} = (\eps t, \eps x + \gamma(\eps t))$.  

We calculate
\[ \del_t \bar{\theta}(p) = \eps \del_t \theta(\bar{p}) + \eps \dot{\gamma}(\bar{p}) \cdot \grad \theta (\bar{p}) \]
and 
\[ \grad \bar{\theta}(p) = \eps \grad \theta(\bar{p}) \]
and
\[ \Lambda \bar{\theta}(p) = \eps \Lambda \theta(\bar{p}). \]

Thus, if we define
\[ \bar{u}(p) = u(\bar{p}) - \dot{\gamma}(\bar{p}) \]
then it will be the case that, for $p \in [-T/\eps,0]\times \Omega_\eps$, 
\[ \bracket{\del_t + \bar{u}\cdot\grad + \Lambda} \bar{\theta}(p) = \eps \bracket{\del_t + u\cdot\grad + \Lambda} \theta(\bar{p}). \]

It remains to demonstrate the decomposition of $\bar{u}$ and that $\bar{\gamma}$ still makes $\bar{u}_\ell(0)=0$, let alone that $0$ is still on the boundary of $\Omega_\eps$.  

Recall that for a positive integer $N$, $2^N \eps = 1$.  We define 
\[ \bar{u}_j(p) := u_{j+N}(\bar{p}), \]
that is each $u_j$ is scaled appropriately and then the labels are shifted by $N$.  Our new decomposition of $\bar{u}$ is
\begin{align*} 
\bar{u}(p) &= u(\bar{p}) - \dot{\gamma}(\bar{p})
\\ &= \upsilon(\bar{p}) + \sum u_j(\bar{p}) + \dot{\gamma}(\bar{p})
\\ &= \bracket{\upsilon(\bar{p}) + \dot{\gamma}(\bar{p})} + \sum \bar{u}_j (p)
\end{align*}
which means
\[ \bar{\upsilon}(p) = \upsilon(\bar{p}) + \dot{\gamma}(\bar{p}). \]

We easily bound the $\bar{u}_j$:
\begin{align*}
\norm{\Lambda^{-1/4} \bar{u}_j}_\infty &= \eps^{-1/4}\norm{\Lambda^{-1/4} u_{j+N}}_\infty 
\\ &\leq \eps^{-1/4} \kappa 2^{-(j+N)/4}
\\ &= (\eps 2^N)^{-1/4} \kappa 2^{-j/4} = \kappa 2^{-j/4}.
\end{align*}
Also,
\begin{align*}
\norm{\grad \bar{u}_j}_\infty &= \eps \norm{\grad u_{j+N}}_\infty
\\ &\leq \eps \kappa 2^{j+N} = \kappa 2^j.
\end{align*}

To confirm the desired properties of $\bar{\upsilon}$, we want to say that
\[ \bar{\upsilon}(t) = \sum_{j<0} \bar{u}_j(t,0) \]
or equivalently
\[ \dot{\gamma}(\eps t) = -\upsilon(\eps t) +  \sum_{j<0} u_{j+N}(\eps t, \gamma(\eps t)). \]
By the Caratheodory Existence theorem, there exists a function $\gamma$ which satisfies this relationship for a.e. $t \in [-T/\eps, 0]$.  I can choose the initial condition, and I don't know what I want, so how about $\gamma(0)=0$.  

In fact, since $-\upsilon(t) + \sum_{j<-N} u_{j+N}(t,0)$ vanishes by assumption, we can say in fact that 
\[ -\upsilon(t) +  \sum_{j<0} u_{j+N}(t, 0) = \sum_{j=0}^{N-1} u_j(t,0) \leq N \norm{u_j}_\infty. \]
Here it's relevant that $\norm{u_j}_\infty$ is independent of $j$, which I know but have not proven or even stated before.  Since $\sum_{j<N} u_j$ is a Lipschitz function, with Lipschitz constant $\kappa 2^N$, we can bound $\gamma$
\[ \dot{\gamma}(t) \leq N \norm{u_j}_\infty + \kappa 2^N |\gamma(t)|. \]
That's a Lipschitz bound on $\gamma$.  It becomes a real bound
\[ \gamma(t) \leq N 2^{-N} (\exp(\kappa 2^N t)-1). \]

All that remains is the most important part.  Showing that our $\gamma$ is small enough and of the correct nature such that the information we get about $\bar{\theta}$ will be useful.  

For example, we probably want that $\gamma(t) \in \del \Omega$ for all $t$.  Why would that be true?  It's actually not.  No matter what $\gamma$ is, the $u_j$ terms point along the boundary and hence they can never turn $\dot{\gamma}$ in a direction so as to go ``off the rails'' so to speak.  On the other hand, $\upsilon$ is only tangential at the origin.  Elsewhere, $\upsilon$ might as well have a tangential component.  

Wait, I'm adding $\dot{\gamma}$ to $\upsilon$.  But $\upsilon$ is a scalar, it's the value of $u_\ell$ at 0, while $\dot{\gamma}$ is a vector, it's the time derivative of a moving point in $\R^2$.  That seems off.  No way man, $u$ is vector valued, so $\upsilon$ is too.  All good.  

Let's get to it.  Define
\[ f(t,x) = -\upsilon(t) + \sum_{j < N} u_j(t,x). \]
This function is Lipschitz in $x$, with constant $\kappa 2^N$.  Morever, $f(t,0) \leq \kappa N$.  

It's important that $(t,0) \mapsto (\eps t, \gamma(\eps t))$ is on the boundary of $\Omega$.  So we want that $\dot{\gamma}(t)$ is pointing along the boundary of $\Omega$ at $\gamma(t)$.  


\end{proof}

New idea is to drop all the $\gamma$ nonsense.  Instead, we argue that even though $u_\ell(t,0)$ is large in the $L^\infty(L^\infty)$ sense, it is small in the $L^1(L^\infty)$ sense (that's integration in time).  This makes sense, because every time we zoom in by $\eps = 2^N$, we increse the $L^\infty(\Omega)$ norm by $\kappa N$ but we also shrink the time interval by $2^N$.  I believe that this is essentially the property that we exploit in the drift formulation, namely that the correction term $\gamma$ may be large in principle but $\dot{\gamma}$ is small so over small enough time intervals, $\gamma$ is small.  It's important that the $L^1(L^\infty)$ norm not only grow slowly but actually grow in a summable manner, so that after 1 million zooms still the error introduced is bounded.  

Even if we can do all that, how do we formulate that error term and how do we deal with it in the energy inequality?  Well, let's say that
\[ u_\ell = \tau + \sigma \]
where $\tau$ is a function of time alone and $\sigma$ is both Lipschitz in space and $\sigma(t,0) = 0$.  The Lipschitz constant of $\sigma$ grows with each zoom, in such a way as to effectively cancel out the gains we get from zooming so the effective $L^\infty$ norm remains constant.  Similarly, the quantitative bound on $\tau$ grows with each zoom in such a way as to cancel out the gains of zooming so that its integral remains constant.  

Now in the energy inequality, we have three terms $u = \tau + \sigma + u_h$.  Remember that the energy inequality contains
\[ \iint \theta_+ u \cdot \grad \psi. \]
We bound this integral using the duality pairing, $L^1(L^\infty)$ vs $L^\infty(L^2)$ and absorb the $\theta_+$ into the $\sup \int \theta_+^2$ term on the left hand side.  We do some pro forma nonsense to keep a factor of $\int \chi_+$ involved on the remainder and zoop zop wop we're done.  I'm a genius.  

Okay, this has gotten ridiculous.  As of April 24th, the statement of the scaling theorem seems right but the proof is well out of date.  




\section{The Japanese Stuff}

Logan: The japanese paper's Lemma 3.6, used extensively here, only applies in the case $j \geq 0$. Obviously I need it and use it for $j > j_0$.  This is equivalent, I can see from the proof, but maybe mention the issue somewhere so it doesn't seem like I didn't notice.  

In this section we will prove that $u$ breaks up into pieces with various norms under control.  

We know that $\theta \in L^\infty$.  Let $\phi$ be a Schwartz function on $\R$ which is suited to Littlewood-Paley decomposition.  That is, for example, $\phi(2^j x) \phi(2^i x) = 0$ unless $|i-j|\leq 1$ and $\sum \phi(2^j) = 1$.  We have some projections 
\[ P_j f := \sum_k \phi(2^j f_k) \eigen{k}. \]
Is that the right formula?  Hmm.  Well, I'll use the functional calculas that I know and clean up the definitions later.  

Recall that $P_j = 0$ for $j$ sufficiently small, because $-\Laplace_D$ has a smallest eigenvalue.  

For each $j \in \Z$, I'll define
\[ u_j := \grad^\perp \Lambda^{-1} P_j \theta. \]
Qualitatively, we know that $\theta \in L^2$ and hence $u_j \in L^2$.  In fact, $u = \sum u_j$ in the $L^2$ sense.  

Firstly, we know by [citation] Fornare, Metafune and Priola that if $\Omega$ is $C^{2,\alpha}$ then
\[ \norm{\grad e^{-t\Laplace_D}}_{L^\infty \to L^\infty} \leq \frac{C}{\sqrt{t}} \qquad 0 < t \leq 1. \]
According to [citation] Iwabuchi, Matsuyama, and Tanaguchi's paper Bilinear Estimates, Lemma 3.6, this is enough to show that
\[ \norm{u_j}_\infty \leq C \norm{\theta}_\infty. \]

We'll need a lemma now,
\begin{lemma}
For any function $f$,
\[ \norm{P_i \grad P_j f}_\infty \leq C \min(2^j,2^i) \norm{f}_\infty. \]
\end{lemma}
\begin{proof}
Let $g$ be an $L^1$ function.  Then
\[ \int g P_i \grad P_j f = \int (P_i g) \grad P_j f \leq C 2^j \norm{g}_1 \norm{f}_\infty \]
from [citation] IMT-Bilinear, Lemma 3.6 and Proposition 3.3 (which is also IMT Boundedness of Spectral Multiplies for Schrodinger Operators on Open Sets, Theorem 1.1).  

Further integrating by parts,
\[ \int g P_i \grad P_j f = - \int (\grad P_i g) P_j f \leq C 2^i \norm{g}_1 \norm{f}_\infty. \]
This follows from the same theorems as above.  

The result follows.  
\end{proof}

Since $u_j \in L^2$, we know that
\[ \Lambda^{-1/4} u_j = \sum_{i \in \Z} P_i \Lambda^{-1/4} u_j. \]
Define $\bar{P}_j$ a projection which is 1 on the support of $P_j$ (functional calculus-wise).  Then $\bar{P}_j P_j = P_j$, and since both types of projections are spectral operators, they both commute with $\Lambda^s$.  We therefore rewrite
\[ \paren{P_i \Lambda^{-1/4} u_j}^\perp = \paren{\Lambda^{-1/4} \bar{P}_i} P_i \grad P_j \paren{\Lambda^{-1} \bar{P}_j} \theta. \]
We apply sequentially three bounded operators on $L^\infty$.  The outer two operators have bounded norm by [citation] IMT-Bilinear Proposition 3.3, and the inner operator has bounded norm by the above lemma, (and of course the perp operator is an isometry,) so 
\[ \norm{ P_i \Lambda^{-1/4} u_j}_\infty \leq C 2^{-i/4} \min(2^j, 2^i) 2^{-j} \norm{\theta}_\infty. \]
%
% so from [citation] IMT-Bilinear Proposition 3.3 we can see that
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty = \norm{\Lambda^{-1/4} \bar{P}_i P_i u_j}_\infty \leq C 2^{-i/4} \norm{P_i u_j}_\infty \]
%and also
%\[ P_i u_j = P_i \grad P_j \Lambda^{-1} \bar{P}_j \theta. \]
%Thus by the lemma,
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty \leq C 2^{-i/4} \min(2^j,2^i) \norm{\Lambda^{-1} \bar{P}_j \theta}_\infty \leq C 2^{-j} 2^{-i/4} \min(2^j,2^i) \norm{\theta}_\infty. \]
Summing these bounds on the projections of $\Lambda^{-1/4} u_j$, and noting that
\[ \sum_{i \in \Z} 2^{-j} 2^{-i/4} \min(2^j,2^i) = 2^{-j} \sum_{i \leq j} 2^{i 3/4} + \sum_{i>j} 2^{-i/4} \leq C 2^{-j/4}, \]
we obtain
\[ \norm{\Lambda^{-1/4} u_j}_\infty \leq C 2^{-j/4} \norm{\theta}_\infty. \]

Lastly, we'll show that $\grad u_j$ is in $L^\infty$.  Equivalently, we'll show that $\Lambda^{-1} P_j \theta$ is $C^{1,1}$.  This is essentially Schauder theory.  We will obtain our $C^{1,1}$ bound by interpolating between a $C^{0,1}$ bound and a $C^{2,\alpha}$ bound.  We could also obtain a $C^{1,\alpha}$ bound directly using the main theorem of [citation] Caffarelli-Stinga, but those estimates are not well-articulated in the specific context of our problem (namely, it's hard to make good use of the fact that $f$ near the boundary).  So instead, we use interpolation.  

The $C^{0,1}$ bound is already known, it's the estimate
\[ \norm{\grad \Lambda^{-1} P_j \theta}_\infty \leq C \norm{\theta}_\infty. \]
The $C^{2,\alpha}$ bound is classical Schauder theory.  For convenience, define 
\[ F := \Lambda^{-1} P_j \theta \]
and recall that $F$ is a finite linear combination of Dirichlet eigenfunctions, so in particular it is smooth and vanishes at the boundary.  Moreover, its Laplacian is 
\[ f := \Laplace F = \Lambda P_j \theta \]
which is also smooth, vanishes at the boundary, and has various bounds.  Specifically, we want to apply Theorem 6.6 from [citation] Gilbarg and Trudinger, page 98 in my library copy.  It says that since $\Omega$ is $C^{2,\alpha}$ and $F \in C^{2,\alpha}(\bar{\Omega})$, and since $f \in C^\alpha(\bar{\Omega})$, and since the boundary conditions are homogeneous (hence smooth), then
\[ \sup_{x,y \in \Omega} \frac{\abs{D^2 F(x)- D^2 F(y)}}{|x-y|^\alpha} \leq C \norm{F}_\infty + C \norm{f}_\infty + C \sup_{x,y\in\Omega} \frac{\abs{f(x)-f(y)}}{|x-y|^\alpha}. \]

A lemma with two interpolations:
\begin{lemma}
If $f \in L^\infty(\Omega) \cap C^{0,1}(\Omega)$ then for some universal constant $C$,
\[ \bracket{f}_\alpha \leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha. \]

If $f \in C^{0,1}(\Omega) \cap C^{2,\alpha}(\Omega)$ where $\Omega$ satisfies the cone condition, then 
\[ \norm{D^2 f}_\infty \leq C \norm{\grad f}_\infty^\frac{\alpha}{1+\alpha} \bracket{D^2 f}_\alpha^\frac{1}{1+\alpha}.\]
This last needs more caveats to be true, I'll list them once I have the proof written down.  
\end{lemma}
\begin{proof}
The first claim is incredibly straigtforward.  We include it for completeness.  
\begin{align*} 
\sup_{x,y \in \Omega} \frac{|f(x)-f(y)|}{|x-y|^\alpha} &= \sup |f(x)-f(y)|^{1-\alpha} \paren{\frac{|f(x)-f(y)|}{|x-y|}}^\alpha 
\\ &\leq \paren{2 \norm{f}_\infty}^{1-\alpha} \paren{ \sup \frac{|f(x)-f(y)|}{|x-y|} }^\alpha
\\ &\leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha.
\end{align*}

The second claim is more complicated.  We'll prove the equivalent claim that for $f$ smooth,
\[ \norm{\grad f}_\infty \leq C \norm{f}_{L^\infty(\bar{\Omega})}^\frac{\alpha}{1+\alpha} \bracket{\grad f}_{\alpha;\bar{\Omega}}^\frac{1}{1+\alpha}.\]
Since $\Omega$ satisfies the cone condition, we know that there exist positive constants $\ell$ and $a$ such that, at each point $x \in \bar{\Omega}$, there exist two unit vectors $e_1$ and $e_2$ such that $e_1\cdot e_2 \leq a$ and $x + \tau e_i \in \Omega$ for $i=1,2$, $0 < \tau \leq \ell$.  In other words, $\Omega$ contains rays at each point that extend for length $\ell$, end at $x$, and are non-parallel with angle $\cos\n(a)$.  

If we consider the directional derivative $\del_i f$ of $f$ along the direction $e_i$, then observe that for any $0 < \delta \leq \ell$,
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau = f(x+\delta e_i) - f(x). \]
This quantity on the right is bounded by the $L^\infty$ norm of $f$.  

On the other hand, since $\grad f$ and hence $\del_i f$ are continous functions, for any $\tau \in (0,\ell]$
\[ \abs{\del_i f(x) - \del_i f(x+\tau e_i)} \leq \bracket{\grad f}_\alpha \tau^\alpha. \]
From this bound, we obtain that
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau \leq \int_0^\delta \del_i f(x) + \bracket{\grad f}_\alpha \tau^\alpha \,d\tau = \delta \del_i f(x) + \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha} \]
and similarly from below, so
\[ \delta \del_i f(x) - \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha} \leq \int_0^\delta \del_i f(x + \tau e_i) \,d\tau \leq \delta \del_i f(x) + \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha}. \]

What we have shown is that the integral of $\del_i f$ over an interval of length $\delta$ is small, and also it differs not very much from $\delta \del_i f(x)$.  By rearranging, we find that $\del_i f(x)$ must therefore be small:
\[ \abs{\del_i f(x)} \leq \frac{2}{\delta} \norm{f}_\infty + \frac{\delta^\alpha}{1+\alpha} \bracket{\grad f}_\alpha. \]
This is true independent of $x$ and of $i=1,2$.  Since $e_1 \cdot e_2 \leq a$ by assumption, by a little linear algebra we can bound $\grad f$ in terms of the $\del_i f$ and obtain that, for all $\delta \in (0,\ell]$,
\[ \norm{\grad f}_\infty \leq \frac{C}{1-a^2} \paren{ \delta\n \norm{f}_\infty + \delta^\alpha \bracket{\grad f}_\alpha }. \]

We can minimize this over all eligible $\delta$, but let's hold off for now until we know what we need.  

\end{proof}

Let's bound the terms of the Gilbarg-Trudinger inequality.  By [citation] IMT-Bilinear Proposition 3.3
\[ \norm{f}_\infty = \norm{\Lambda P_j \theta}_\infty \leq C 2^j \norm{\theta}_\infty \]
while by [citation] IMT-Bilinear Lemma 3.6
\[ \norm{\grad f}_\infty = \norm{\grad \Lambda P_j \theta}_\infty \leq C 2^{2j} \norm{\theta}_\infty. \]
Therefore we can interpolate
\[ \bracket{f}_\alpha \leq C 2^{j(1+\alpha)} \norm{\theta}_\infty. \]
And of course, by [citation] IMT-Bilinear Proposition 3.3
\[ \norm{F}_\infty = \norm{\Lambda^{-1} P_j \theta}_\infty \leq C 2^{-j} \norm{\theta}_\infty. \]

Combining these estimates with [citation: the Gilbarg-Trudinger thingy] we find
\[ \bracket{D^2 F}_\alpha \leq C \paren{2^{-j} + 2^j + 2^{j(1+\alpha)}} \norm{\theta}_\infty. \]

At long last, the big estimate,
\[ \norm{D^2 F}_\infty \leq C \paren{\delta\n \norm{\grad F}_\infty + \delta^{\alpha} \bracket{D^2 F}_\alpha}. \]

Since $\Omega$ is bounded, there exists a $j_0$ such that $P_j = 0$ if $j < j_0$.  Therefore we assume withouth loss of generality that $j \geq j_0$.  Thus $2^{-j} \leq 2^{j(1+\alpha)} 2^{-j(2+\alpha)} \leq 2^{j(1+\alpha)} 2^{-j_0(2+\alpha)}$ and similarly $2^j \leq 2^{j(1+\alpha)}2^{-j\alpha} \leq 2^{j(1+\alpha)} 2^{-j_0\alpha}$.  We can therefore say that for all $\delta$ sufficiently small
\[ \bracket{D^2 F}_\infty \leq C \paren{\delta\n C + \delta^\alpha 2^{j(1+\alpha)}} \norm{\theta}. \]
We don't actually have to take $\delta$ all that small.  Set $\delta = \ell$.  The real interpolation we need is
\[ \norm{\grad g}_\infty \leq \norm{g}_\infty + \bracket{\grad g}_\alpha. \]
No, you idiot, we really need to get rid of all dependence on $\alpha$.  

Set $\delta = 2^{-j} 2^j_0 \ell \leq \ell$.  Then
\[ \bracket{D^2 F}_\infty \leq C \paren{C 2^j + 2^{-j\alpha} 2^{j(1+\alpha)}} \norm{\theta} = C(\Omega) 2^j \norm{\theta}. \]
But $D^2 F = \grad u_j$ so we are done.  




\end{document}