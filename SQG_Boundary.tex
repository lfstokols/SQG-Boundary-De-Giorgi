\documentclass[11pt]{amsart}
\usepackage{amssymb,amsbsy,upref,epsf,MnSymbol}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,mathtools,mathrsfs,wrapfig}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}



%-------------------------------------------<commands>--------------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Prj}{\mathbb{P}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\Four}{\mathcal{F}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\E}{\mathcal{E}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\eps}{\varepsilon}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\chevron}[1]{\langle #1 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\convex}{conv}
\DeclareMathOperator{\image}{Im}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\lspan}{span}
\DeclareMathOperator{\conv}{conv} % stands for conv, as in convex hull
\DeclareMathOperator{\Int}{int} % stands for int, as in interior of a set
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\rank}{rank}
%\DeclareMathOperator{\dim}{dim}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\cod}{\operatorname{cod}}
\newcommand{\Hom}{\operatorname{hom}}
\newcommand{\Ob}{\operatorname{Ob}}
\newcommand{\cl}{\operatorname{cl}}
\DeclareMathOperator{\BMO}{BMO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\del}{\partial}
\newcommand{\pvec}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\grad}{\nabla}
\newcommand{\ddt}{\frac{d}{dt}}
\renewcommand{\div}{\operatorname{div}}
\newcommand{\Laplace}{\Delta}
\newcommand{\kinet}{\bracket{\del_t + v\cdot \grad_x}}
\newcommand{\bessel}{\paren{1-\Laplace_v}}
\newcommand{\loc}{\text{loc}}
\newcommand{\Lip}{\text{Lip}}
\newcommand{\ddz}{\frac{d}{dz}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\into}{\hookrightarrow}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\isom}{\cong}
\newcommand{\rest}{{\upharpoonright}}
\newcommand{\weakly}{\rightharpoonup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ith}{^\mathrm{th}}
\newcommand{\n}{^{-1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\indic}[1]{\chi_{\{#1\}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\eigen}[1]{\eta_{#1}} %my eigenfunctions
\newcommand{\Ctest}{C_c^\infty}
\newcommand{\test}{\mathcal{D}}

\newcommand{\ulow}{u_l}
\newcommand{\uhigh}{u_h}
\newcommand{\ulowth}[1]{\ulow^{#1}}
\newcommand{\uhighth}[1]{\uhigh^{#1}}
\newcommand{\umidth}[1]{u_m^{#1}}

\newcommand{\Rom}[1]{\MakeUppercase{\romannumeral #1}}

\newcounter{step_count}[section]
\newcommand{\step}[1]{\stepcounter{step_count} \smallskip \noindent{\textbf{Step \arabic{step_count}:} #1}}


%-------------------------------------------</commands>--------------------------------------------------------

%\newcommand{\draftnum}{1}%-----------------------------UPDATE DRAFT NUM----------------------------------------

\title{SQG Boundary, \today}

\author[Stokols]{Logan F. Stokols} 
\address[L. F. Stokols]{\newline Department of Mathematics, \newline The University of Texas at Austin, Austin, TX 78712, USA}
\email{lstokols@math.utexas.edu}

\date{\today}

%\subjclass[2010]{35H10,35B65,47G20,35Q84} % hypoellptic, regularity, integro-differential, fokker-planck
%\keywords{Fokker-Planck Equation, Fractional Laplacian, H\"older regularity,  De Giorgi method}

%\thanks{\textbf{Acknowledgment.} This work was partially supported by the NSF Grant DMS 1614918. }

\begin{document}




\maketitle \centerline{\date}

We're gonna consider the equation 
\begin{equation}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ u = \grad^\perp \Lambda\n \theta.
\end{equation}

Here the operator 
\[ \Lambda := \sqrt{-\Laplace_D} \]
where $\Laplace_D$ is the Laplacian with Dirichlet boundary condition.  

We're going to linearize the equation by fixing $u$ independent of $\theta$.  What property do we want $u$ to have?  For some constant $\kappa$, we'll want
\begin{align*} 
u &= \sum_{j \in \Z} u_j, \\
\norm{u_j}_\infty \leq \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j. 
\end{align*}
The convergence of that sum is in, say, weak $L^2$.  

Recall the notation
\[ \bracket{f}_\alpha := \sup_{x,y \in \Omega, x \neq y} \frac{|f(x)-f(y)|}{|x-y|^\alpha}. \]


\section{Lemmas}

\begin{lemma}
If $f$ and $g$ are non-negative functions with disjoint support (i.e. $f(x)g(x) = 0$ for all $x$), then 
\[ \int \Lambda^s f \Lambda^s g \,dx \leq 0. \]
\end{lemma}

This proves, in particular, that $-\int \theta_+ \Lambda \theta_-$ is a positive term (hence dissipational and extraneous) and that $\int \Lambda^{1/2} (\theta-\psi) \Lambda^{1/2} (\theta-\psi)$ breaks down (bilinearly) into the doubly positive, the doubly negative, and the cross term, all of which are positive and hence each of which is positive.  

\begin{proof}
Use the characterization from Caffarelli-Stinga.  There exist non-negative functions $K(x,y)$ and $B(x)$, depending on the parameter $s$, such that
\[ \int \Lambda^s f \Lambda^s g \,dx = \iint [f(x)-f(y)][g(x)-g(y)] K(x,y) \,dxdy + \int f(x) g(x) B(x) \,dx. \]

Since $f$ and $g$ are non-negative and disjoint, the $B$ term vanishes.  Moreover, the product inside the $K$ term becomes
\[ [f(x)-f(y)][g(x)-g(y)] = -f(x)g(y)-f(y)g(x) \leq 0. \]
Since $K$ is non-negative, the result follows.  
\end{proof}

\begin{lemma}
For all functions $f$ in $H_D^1$,
\[ \int \abs{\grad f}^2 = \int \abs{\Lambda f}^2. \]

Moreover, if $f \in H_D^1$ then $\trace(f)=0$.  
\end{lemma}

\begin{proof}
Let $\eigen{i}$ and $\eigen{j}$ be two eigenfunctions of the Dirichlet Laplacian on $\Omega$.  Note that these functions are smooth in the interior of $\Omega$.  Because $\Omega$ has Lipschitz boundary, and because $\eigen{i} \grad \eigen{j}$ is smooth on $\Omega$ and countinuous and bounded on $\overline{\Omega}$ vanishing on the boundary, therefore 
\[ \int_\Omega \div(\eigen{i} \grad \eigen{j}) = \int_{\del \Omega} \eigen{i} \grad \eigen{j}. \]
But $\eigen{i} \grad \eigen{j}$ vanishes on the boundary, so the right hand side vanishes.  Moreover, $\div(\eigen{i} \grad \eigen{j}) = \grad \eigen{i} \cdot \grad \eigen{j} + \eigen{i} \Laplace \eigen{j}$.  Therefore
\[ \int \grad \eigen{i} \cdot \grad \eigen{j} = - \int \eigen{i} \Laplace \eigen{j} = \lambda_k \int \eigen{i} \eigen{j}. \]
Of course, the inner product of two eigenfunctions is 0 unless they are the same eigenfunction, in which case it is 1.  

Consider a function $f = \sum f_k \eigen{k}$ which is an element of $H_D^1$, by which we mean $\sum \lambda_k f_k^2 < \infty$.  Since $\norm{\grad \eigen{k}}_{L^2(\Omega)} = \sqrt{\lambda_k}$, the following sums all converge in $L^2(\Omega)$ and hence the calculation is justified:
\begin{align*}
\int \abs{\grad f}^2 &= \int \paren{\sum_i f_i \grad \eigen{i} } \paren{\sum_j f_j \grad \eigen{j}}
\\ &= \int \sum_{i,j} (f_i f_j) \grad \eigen{i} \cdot \grad \eigen{j}
\\ &= \sum_{i,j} (f_i f_j) \int \grad \eigen{i} \cdot \grad \eigen{j}.
\end{align*}
Since this double-sum vanishes except on the diagonal, we see from [citation] that in fact
\[ \norm{\grad f}_{L^2(\Omega)} = \norm{\Lambda f}_{L^2(\Omega)}. \]

To see that $\trace(f)$ vanishes, note that $f = \sum_{k=0}^\infty f_k \eigen{k}$ and that each finite partial sum for this series satisfies the Dirichlet boundary condition.  Since $\trace$ is a bounded operator on $H^1$, we need only show that this series is Cauchy in $H^1$, in which case its $H^1$ limit will exist and be equal to its $L^2$ limit which will be equal to $f$.  

For each $k$,
\[ \norm{ f_k \eigen{k} }_{H^1} \leq C_\textrm{Poincare} f_k \norm{\grad \eigen{k}}_2 = C f_k \sqrt{\lambda_k}. \]
This sequence is $\ell^2$ summable, since $f \in H_D^1$ by assumption.  Therefore $f$, being an $H^1$ limit of functions with vanishing trace, also has vanishing trace.  
\end{proof}

\begin{lemma}
For any function $f$, and any $0 < s < 1$,
\[ \int \abs{\Lambda^s f}^2 \simeq \int \abs{\paren{-\Laplace}^{s/2} \bar{f}}^2. \]
Here $\bar{f}$ is the extension of $f$ to $\R^2$ and $\paren{-\Laplace}^s$ is defined in the fourier sense.  
\end{lemma}

\begin{proof}
Let $g$ be any Schwarz function in $L^2(\R^2)$, and let $f$ be a function in $H^{s+1}_D$.  Let $E:H^1(\Omega) \to H^1(\R^2)$ be a bounded extension operator, where $H^1$ denotes the classical Sobolev space defined using the gradient.  Define the function
\[ \Phi(z) = \int_{\R^2} \paren{-\Laplace}^{z/2} g E \Lambda^{s-z} f. \]

When $\Re(z) = 0$, then $\norm{\paren{-\Laplace}^{z/2} g}_2 = \norm{g}_2$ and $\norm{\Lambda^{s-z} f}_2 = \norm{\Lambda^s f}_2$.  Hence
\[ \Phi(z) \leq \norm{g}_2 \norm{f}_{H^s_D}. \]

When $\Re(z)=1$, then $\norm{\paren{-\Laplace}^{(z-1)/2} g}_2 = \norm{g}_2$ and 
\[ \norm{\paren{-\Laplace}^{1/2} E\Lambda^{s-z} f}_{L^2(\R^2)} = \norm{\grad E \Lambda^{s-z} f}_{L^2(\R^2)} \leq \norm{E} \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)}. \]
It remains to ask whether $\Lambda^{s-z} f$ is in $H^1_D$ so that we can apply lemma [citation].  However, this is true based on our assumption $f \in H^{1+s}_D$, since the various powers of $\Lambda$ all commute and form a semigroup.  Ergo
\[ \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)} = \norm{\Lambda \Lambda^{s-z} f}_2 \leq \norm{\Lambda^s f}_2 \]
and we can bound
\[ \Phi(z) \leq \norm{E} \norm{g}_2 \norm{f}_{H^s_D}. \]

Now we will bound the derivative of $\Phi(z)$.  Specifically, compute the derivative in $z$ of the integrand, for $0<\Re(z)<1$, and hope that it is integrable.  To this end, we rewrite the integrand of $\Phi$ as
\[ \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k. \]
The derivative $\ddz$ commutes with linear operators like $\Four\n$ and $E$, so the derivative is
\[ \Four\n\paren{ \ln(|\xi|) |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k + \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \frac{-1}{2} \ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} f_k. \]

Since $0<\Re(z)<1$, $\ln(|\xi|)|\xi|$ is bounded as a multiplier operator from Schwarz functions to $L^2$.  Moreover, $\ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} \leq C \lambda_k^{\frac{s-z+\eps}{2}}$ for some $C$ independent of $k$ but dependent on $z$, $\eps$.  Since $f \in H^{1+s}_D$ this sum converges in $L^2$, in fact in $H_D^1$.  This makes our differentiated integrand a sum of two $H^1$ functions with compact support multiplied by two Schwarz functions.  In particular it is integrable, which means we can interchange the integral sign and the derivative $\ddz$ and prove that $\Phi'(z)$ is finite for all $0<\Re(z)<1$. 

This is sufficient now to apply the Hadamard three-lines lemma to our function $\Phi$.  

It follows that for any Schwarz function $g \in L^2(\R^n)$ and $H_D^{s+1}$ function $f$, 
\[ \int_{\R^2} \paren{-\Laplace}^{s/2} g E f = \Phi(s) \leq \norm{g}_{L^2(\R^2)} \norm{f}_{H_D^s}. \]

Since Schwarz functions are dense in $L^2(\R^2)$, this means by density that 
\[ \int \abs{ \paren{-\Laplace}^{s/2} E f }^2 \leq \int \abs{\Lambda^s f}^2 \]
or in other words it means that $E$ is a bounded operator from $H_D^s$ to $H^s$, at least on the subset $H_D^{s+1} \cap H_D^s$.  It remains to extend this bound to the whole space by density.  

We know from [citation] Caffarelli and Stinga that $\test(\Omega)$ is dense in $H_D^s$ for all $0 \leq s < 1$.  In fact, this takes a bit of interpretation, so I ought to illucidate that this is because $H_D^s = H_0^s$ (the latter in the Slobodekij sense) for most $s$ and at $s=1/2$ we get the Lions-Magenes spaces which still has $\test(\Omega)$ dense.  

Surely, right(?), test functions are all inside of $H_D^{1+s}$.  I should meditate on this, but it must be true.  
\end{proof}


\section{De Giorgi Estimates}

First let us derive an energy inequality.  

We know a priori that $\theta \in L^\infty(0,T; L^2(\Omega)) \cap L^2(0,T; H_D^{1/2}(\Omega))$.  Let $\psi: \Omega \to \R^+$ be a non-negative function in $H_D^{1/2}$ non-uniformly, and define $\theta = \theta_+ + \psi - \theta_-$.  Since $\theta - \psi$ is in $H_D^{1/2}$, by the lemma above, both $\theta_+$ and $\theta_-$ are in that space as well.  In particular, our weak solution can eat $\theta_+$.  

\begin{lemma}[Caccioppoli Estimate]
Let $\theta \in L^2(0,T; H_D^{1/2}(\Omega))$ and $u \in L^\infty(0,T; L^2(\Omega))$ solve
\begin{align*}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ \div u = 0
\end{align*}
in the sense of distributions.  Let $\psi \in L^\infty(0,T; H_D^{1/2}(\Omega))$ be non-negative, Lipschitz-in-space, and H\"{o}lder continuous-in-space with exponent $\gamma < 1/2$.  Then the decomposition
\[ \theta = \theta_+ + \psi - \theta_- \]
satisfies the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (\del_t \psi + u\cdot\grad\psi) } \]
with the constant $C$ depending on $\norm{\grad \psi}_\infty$ and $\sup_t \bracket{\psi(t,\cdot)}_\gamma$.  

\end{lemma}

\begin{proof}
We decompose $\theta-\psi = \theta_+ - \theta_-$ with both $\theta_+$ and $\theta_-$ non-negative and having disjoint support.  Since at a.e. time $t$ $\theta$ and $\psi$ are both in $H_D^{1/2}$, we can write
\[ \infty > \int \abs{\Lambda^{1/2}(\theta_+-\theta_-)}^2 = \int \abs{\Lambda^{1/2}\theta_+}^2 + \int \abs{\Lambda^{1/2} \theta_-}^2 - \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-. \]
By a lemma proved above, the final term (by disjoint support) is non-positive, hence all three terms are finite and in particular $\theta_+$ and $\theta_-$ are in $H_D^{1/2}$ at a.e. time.  

We can therefore multiply our equation [cite] by $\theta_+$ and integrate in space to obtain
\[ 0 = \int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \paren{\theta_+ + \psi - \theta_-} \]
which decomposes into three terms, corresponding to $\theta_+$, $\psi$, and $\theta_-$.  We analyze them one at a time.  

Firstly,
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_+ &= (1/2) \ddt \int \theta_+^2 + (1/2) \int \div u \, \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2
\\ &= (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2.
\end{align*}

The $\psi$ term produces important error terms:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \psi &= \int \theta_+ \del_t \psi + \int \theta_+ u \cdot \grad \psi + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\\ &= \int \theta_+ (\del_t \psi + u \cdot \grad \psi) + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\end{align*}

Since $\theta_+$ and $\theta_-$ have disjoint support, the $\theta_-$ term is nonnegative by lemma [citation]:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_- &= (1/2) \int \theta_+ \del_t \theta_- + \int \theta_+ u \cdot \grad \theta_- + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-
\\ &= \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_- \leq 0.
\end{align*}

Put together, we arrive at 
\[ (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 + \iint \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \leq \abs{\int \theta_+ (\del_t \psi + u \cdot \grad \psi) \cdot \grad \psi}. \]

At this point we break down the $\Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi$ term using the formula from [citation] Caffarelli-Stinga.  
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi = \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) + \int \theta_+ \psi B. \]
Since $B \geq 0$ (see Caff-Stinga [citation]) and $\psi$ is non-negative by assumption, the $B$ term is non-negative and so
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \geq \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y). \]
The remaining integral is symmetric in $x$ and $y$, and the integrand is only nonzero if at least one of $\theta_+(x)$ and $\theta_+(y)$ is nonzero.  Hence
\[ \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) \leq 2 \iint \indic{\theta_+>0}(x) \abs{[\theta_+(x)-\theta_+(y)][\psi_t(x)-\psi_t(y)]} K(x,y). \]
Now we can break up this integral using the Peter-Paul variant of H\"{o}lder's inequality.  
\[ \abs{\iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y)} \leq \eps \int \abs{\Lambda^{1/2}\theta_+}^2 + \frac{1}{\eps} \iint \indic{\theta_+>0}(x) [\psi(x)-\psi(y)]^2 K(x,y). \]

It remains to bound the quantity $[\psi(x)-\psi(y)]^2 K(x,y)$.  By Caffarelli-Stinga theorem 2.4 [citation], there is a universal constant $C$ such that
\[ K(x,y) \leq \frac{C}{|x-y|^{3}}. \]
The cutoff $\psi$ is Lipschitz, and H\"{o}lder continuous with exponent $\gamma < 1/2$ by assumption.  Therefore 
\[ [\psi(x)-\psi(y)]^2 K(x,y) \leq |x-y|^{-1} \wedge |x-y|^{2\gamma-3}. \]
Since $3-2\gamma > 2$, this quantity is integrable.  Thus
\[ \int \indic{\theta_+>0}(x) \int [\psi(x)-\psi(y)]^2 K(x,y) \,dxdy \leq C(\norm{\psi}_\textrm{Lip}, \bracket{\psi}_\gamma) \int \indic{\theta_+>0} \,dx. \]
Combining [citation, like 4 different things are combined] we arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \lesssim \int \theta_+ (\del_t\psi+u\cdot\grad\psi) + \int \indic{\theta_+>0}.\]
\end{proof}

We've completed the essential version of the Caccioppoli estimate.  However, much more can be said about the drift-term $u$.  In particular, we can design a cutoff $\psi$ in order to minimize the expression $\del_t \psi + u\cdot\grad\psi$.  

\begin{lemma}[Energy inequality]
Let $\theta \in L^2(0,T; H_D^{1/2}(\Omega))$ and $u \in L^\infty(0,T; L^2(\Omega))$ solve
\begin{align*}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ \div u = 0
\end{align*}
in the sense of distributions.  Let
\[ u = \ulow + \uhigh \]
where $\Lambda^{-1/4} \uhigh \in L^\infty(0,T; L^\infty(\Omega))$ and $\ulow \in L^\infty(0,T; \Lip(\Omega)) \cap L^\infty(0,T; \dot{C}^{3/4}(\Omega)$, and assume that $\ulow(\cdot,0) \in L^\infty(0,T)$.  
Then there exists a $\phi \in C^2(\Omega)$ and a $\gamma \in \Lip(0,T)$ such that
\[ \theta = \theta_+ + \phi(\cdot-\gamma) - \theta_- \]
satisfies the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ + \int \theta_+^2 } \]
with the constant $C$ depending on $\norm{\Lambda^{-1/4} \uhigh}_\infty$, $\bracket{\ulow}_{3/4}$, and on $\phi$.  
\end{lemma}

\begin{proof}
Define $\gamma(t)$ for $t \in [0,T]$ such that $\gamma(T)=0$ and $\dot{\gamma}(t) = \ulow(t,\gamma(t))$.  Use [citation] some lemma from Bahouri-Chemin-Danchin that's a generalization of Picard-Lindelof.  Note that $\gamma$ is Lipschitz and $L^\infty$.  

We'll apply the Caccioppoli estimate with
\[ \psi(t,x) := \phi(x - \gamma(t)), \]
\[ \phi(x) := \paren{|x|^{1/4} - 1}_+. \]
Except we have to smooth out $\phi$ to make it $C^2$.  

Now $\phi(x) = 0$ for $|x|\leq 1$, $\psi(t,\cdot)$ is Lipschitz and H\"{o}lder continuous with exponent $1/4$, and
\[ \del_t \psi + u\cdot\grad \psi = (u - \ulow(t,0))\cdot \grad \phi(x-\gamma(t)). \]

We arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (u-\ulow(t,0)) \cdot \grad\phi(x-\gamma(t)) }. \]

Consider the high pass term $\int \theta_+ \uhigh\cdot\grad\phi$.  This breaks up, according to the formula of Caffarelli-Stinga [citation], into a $K$-term and a $B$-term.  We consider first the $K$ term
\[ \iint [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)][\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)] K_{1/4}(x,y). \]

Decompose this into the far part $|x-y|>1$ whose integral we call \Rom{1} and the far part $|x-y|\leq 1$ whose integral we call \Rom{2}.  For the far part,
\begin{align*} 
\Rom{1} &\leq 2 \norm{\Lambda^{-1/4} \uhigh}_\infty \iint_{|x-y|>1} \abs{\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)} \,dxdy
\\ &\leq 4 \norm{\Lambda^{-1/4} \uhigh}_\infty \int \theta_+\grad\phi \int_{|x-y|>1} \frac{dy}{|x-y|^{2.25}} \,dx
\\ &\leq C \norm{\Lambda^{-1/4} \uhigh}_\infty \norm{\theta_+\grad\phi}_1.
\end{align*}

For the near part, recall first that by the upper- and lower-bounds on $K$ in Caffarelli-Stinga [citation], we know that
\[ K_{1/4}(x,y) \leq C(\Omega) |x-y|^{3/4} K_1(x,y). \]
In principle the constant relating these quantities may depend on $\Omega$, though since both sides of the inequality scale the same way, the constant must be the same for scalings of $\Omega$.  

Since the integrand of \Rom{2} vanishes unless at least one of $x$ or $y$ is in the support of $\theta_+$, we can say
\[ \Rom{2} \leq 2 \iint_{|x-y|\leq 1} \indic{\theta_+>0}(x) [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)][\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]. \]
Therefore, applying H\"{o}lder's inequality with Peter-Paul,
\begin{align*}
\Rom{2} &\leq \frac{1}{\eps}\iint _{\leq 1} \indic{\theta_+>0}(x) [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)]^2 |x-y|^{3/4} K_{1/4} + \eps \iint_{\leq 1} [\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2 \frac{K_1}{|x-y|^{3/4}}
\\ &\leq \frac{C}{\eps} \norm{\Lambda^{-1/4} \uhigh}_\infty \int_{|y|\leq 1} |y|^{-1.5} \,dy \norm{\indic{\theta_+>0}}_1 + \eps \iint_{\R^2\times\R^2} \frac{[\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2}{|x-y|^3} \,dxdy
\end{align*}

The bounds [cite] and [cite] are sufficient to bound the $K$-term by $\int \theta_+$, $\int \indic{\theta_+>0}$, and the classical $H^{1/2}$ norm of $\theta_+ \grad \phi$ (extended by 0 to a function on $\R^2$).  But for the classical $H^{1/2}$ norm, we have by [citation, product rule] combined with the fact that the $H^{1/2}_D$ norm dominates the $H^{1/2}$ norm
\[ \norm{\theta_+ \grad \phi}_{H^{1/2}} \leq \norm{\theta_+}_{H^{1/2}_D} \norm{\grad\phi}_\infty + \norm{\theta_+}_\infty \norm{\grad\phi}_{H^{1/2}}. \] 

Alternatively,
\[ \iint [\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2 K_1 \leq \iint \theta_+(x)^2 [\grad\phi(x)-\grad\phi(y)]^2 K_1 + \iint \grad\phi(y)^2[\theta_+(x)-\theta_+(y)]^2 K_1 \]
\[ \leq C(\norm{\grad\phi}_{\textrm{Lip}}, \norm{\grad\phi}_\infty, \eps) \int \theta_+^2 + \eps \norm{\grad\phi}_\infty^2  \norm{\theta_+}_{H_D^{1/2}}^2. \]

Therefore 
\[ K-\textrm{term} \lesssim \int \indic{\theta_+>0} + \int \theta_+ + \int \theta_+^2 + \eps \int \abs{\Lambda^{1/2} \theta_+(x)}^2. \]

For the $B$ part, on the other hand, 
\[ \int \Lambda^{-1/4} \uhigh \theta_+ \grad\phi B_{1/4} \leq \norm{\Lambda^{-1/4} \uhigh}_\infty \norm{\grad\phi}_\infty \int \theta_+ B_{1/4} \]
and, since $[\theta_+(x)-\theta_+(y)][\indic{\theta_+>0}(x)-\indic{\theta_+>0}(y)] \geq 0$,
\[ \int \theta_+ B_{1/4} \leq \int \indic{\theta_+>0} \Lambda^{1/4} \theta_+ \leq \frac{1}{\eps} \int \indic{\theta_+>0} + \eps \int \abs{\Lambda^{1/4} \theta_+}^2. \]

Now that we have an $L^2$ norm of $\Lambda^{1/4} \theta_+$, since the $H^s_D$ norm is simply an $\ell^2$ norm of the eigndecomposition and $\lambda_k^{1/4} \leq 1 + \lambda_k^{1/2}$, we can easily bound this $H^{1/4}_D$ norm by interpolation and find
\[ B-\textrm{term} \lesssim \int \indic{\theta_+>0} + \int \theta_+^2 + \eps \int \abs{\Lambda^{1/2} \theta_+}^2. \]

From [cite] and [cite] we find that for any $\eps > 0$ arbitrarily small and some constant $C$ depending on $\eps$, $\norm{\grad\phi}_\infty$, $\norm{D^2 \phi}_\infty$, and on the shape (but not the size) of $\Omega$,
\[ \int \uhigh \theta_+ \grad \phi(x - \gamma(t)) \,dx \leq C \norm{\Lambda^{-1/4}\uhigh}_\infty \paren{\int \indic{\theta_+>0} + \int \theta_+ + \int \theta_+^2} + \eps \int \abs{\Lambda^{1/2} \theta_+}^2. \]

For the low pass term, we know that $\ulow$ is Lipschitz and hence $\ulow(t,x) - \ulow(t,\gamma(t))$ is small in a neighborhood of $x=0$.  Specifically, if we assume that $\theta_+$ is supported, at each point in time, in a ball of radius $R$ around $\gamma(t)$, then
\[ \int (\ulow - \ulow(t,\gamma)) \theta_+\grad\phi(x-\gamma) \leq \norm{\ulow}_\Lip \sup_r (r \]

We can actually say that $\ulow$, in addition to being Lipschitz (necessary for Picard-Lindelof) is also H\"{o}lder continuous for any exponent in $(0,1)$ that we want.  In particular, since $\phi$ grows like $|x|^{1/4}$, if $\ulow \in \dot{C}^{3/4}$ then
\[ [\ulow(t,x) - \ulow(t,\gamma(t))] \grad \phi(x-\gamma(t)) \leq \bracket{\ulow}_{3/4} |x-\gamma|^{3/4} C |x-\gamma|^{-3/4} \leq C \bracket{\ulow}_{3/4}. \]

Therefore, for some constant $C$ depending on $\phi$ (specifically the decay rate of its gradient),
\[ \int (\ulow - \ulow(t,\gamma)) \theta_+\grad\phi(x-\gamma) \leq C \bracket{\ulow}_{3/4} \int \theta_+. \]

From this the result follows.  
\end{proof}

\begin{lemma}[Energy inequality, take 2]
Let $\theta \in L^2(0,T; H_D^{1/2}(\Omega))$ and $u \in L^\infty(0,T; L^2(\Omega))$ solve
\begin{align*}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ \div u = 0
\end{align*}
in the sense of distributions.  Let
\[ u = \ulow + \uhigh \]
where $\Lambda^{-1/4} \uhigh \in L^\infty(0,T; L^\infty(\Omega))$ and $\ulow \in L^\infty(0,T; \Lip(\Omega)) \cap L^\infty(0,T; \dot{C}^{3/4}(\Omega)$.  
Suppose that $\Gamma, \gamma \in \Lip(0,T)$ satisfy $\norm{\dot{\gamma}}_\infty \leq C_\gamma$ and
\[ \dot{\Gamma}(t) + \dot{\gamma}(t) = \ulow(t, \Gamma(t) + \gamma(t)). \]

Then there exists a $\phi \in C^2(\Omega)$ such that
\[ \theta = \theta_+ + \phi(\cdot-\Gamma) - \theta_- \]
satisfies the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ + \int \theta_+^2 } \]
with the constant $C$ depending on $C_\gamma$ and $T$, on $\norm{\Lambda^{-1/4} \uhigh}_\infty$, $\bracket{\ulow}_{3/4}$, and $\norm{\ulow}_\Lip$, and on $\norm{D^2 \phi}_\infty$, $\norm{\grad\phi}_\infty$, and $\sup \norm{|x|^{3/4} \grad\phi(x)}_\infty$.  
\end{lemma}

\begin{proof}
We'll apply the Caccioppoli estimate with
\[ \psi(t,x) := \phi(x - \Gamma(t)), \]
\[ \phi \in C^2(\R^2) \cap \dot{C}^{1/4}(\R^2). \]

Now
\[ \del_t \psi + u\cdot\grad \psi = (u - \dot{\Gamma})\cdot \grad \phi(x-\Gamma(t)). \]

We arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (u-\dot{\Gamma}(t)) \cdot \grad\phi(x-\Gamma(t)) }. \]

Consider the high pass term $\int \theta_+ \uhigh\cdot\grad\phi$.  This breaks up, according to the formula of Caffarelli-Stinga [citation], into a $K$-term and a $B$-term.  We consider first the $K$ term
\[ \iint [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)][\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)] K_{1/4}(x,y). \]

Decompose this into the far part $|x-y|>1$ whose integral we call \Rom{1} and the far part $|x-y|\leq 1$ whose integral we call \Rom{2}.  For the far part,
\begin{align*} 
\Rom{1} &\leq 2 \norm{\Lambda^{-1/4} \uhigh}_\infty \iint_{|x-y|>1} \abs{\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)} K_{1/4} \,dxdy
\\ &\leq 4 \norm{\Lambda^{-1/4} \uhigh}_\infty \int \theta_+\grad\phi \int_{|x-y|>1} \frac{dy}{|x-y|^{2.25}} \,dx
\\ &\leq C \norm{\Lambda^{-1/4} \uhigh}_\infty \norm{\grad\phi}_\infty  \int \theta_+.
\end{align*}

For the near part, recall first that by the upper- and lower-bounds on $K$ in Caffarelli-Stinga [citation], we know that
\[ K_{1/4}(x,y) \leq C(\Omega) |x-y|^{3/4} K_1(x,y). \]
In principle the constant relating these quantities may depend on $\Omega$, though since both sides of the inequality scale the same way, the constant must be the same for scalings of $\Omega$.  

Since the integrand of \Rom{2} vanishes unless at least one of $x$ or $y$ is in the support of $\theta_+$, we can say
\[ \Rom{2} \leq 2 \iint_{|x-y|\leq 1} \indic{\theta_+>0}(x) [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)][\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]. \]
Therefore, applying H\"{o}lder's inequality with Peter-Paul,
\begin{align*}
\Rom{2} &\leq \frac{1}{\eps}\iint _{\leq 1} \indic{\theta_+>0}(x) [\Lambda^{-1/4} \uhigh(x)-\Lambda^{-1/4}\uhigh(y)]^2 |x-y|^{3/4} K_{1/4} + \eps \iint_{\leq 1} [\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2 K_1
\\ &\leq \frac{C}{\eps} \norm{\Lambda^{-1/4} \uhigh}_\infty^2 \int_{|y|\leq 1} |y|^{-1.5} \,dy \norm{\indic{\theta_+>0}}_1 + \eps \iint [\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2 K_1 \,dxdy
\end{align*}

For this final term,
\[ \eps \iint [\theta_+(x)\grad\phi(x)-\theta_+(y)\grad\phi(y)]^2 K_1 \leq \iint \theta_+(x)^2 [\grad\phi(x)-\grad\phi(y)]^2 K_1 + \iint \grad\phi(y)^2[\theta_+(x)-\theta_+(y)]^2 K_1 \]
\[ \leq C(\norm{\grad\phi}_{\textrm{Lip}}, \norm{\grad\phi}_\infty, \eps) \int \theta_+^2 + \eps \norm{\grad\phi}_\infty^2  \norm{\theta_+}_{H_D^{1/2}}^2. \]

Therefore 
\[ K-\textrm{term} \lesssim \int \indic{\theta_+>0} + \int \theta_+ + \int \theta_+^2 + \eps \int \abs{\Lambda^{1/2} \theta_+(x)}^2. \]

For the $B$ part, on the other hand, 
\[ \int \Lambda^{-1/4} \uhigh \theta_+ \grad\phi B_{1/4} \leq \norm{\Lambda^{-1/4} \uhigh}_\infty \norm{\grad\phi}_\infty \int \theta_+ B_{1/4} \]
and, since $[\theta_+(x)-\theta_+(y)][\indic{\theta_+>0}(x)-\indic{\theta_+>0}(y)] \geq 0$,
\[ \int \theta_+ B_{1/4} \leq \int \indic{\theta_+>0} \Lambda^{1/4} \theta_+ \leq \frac{1}{\eps} \int \indic{\theta_+>0} + \eps \int \abs{\Lambda^{1/4} \theta_+}^2. \]

Now that we have an $L^2$ norm of $\Lambda^{1/4} \theta_+$, since the $H^s_D$ norm is simply an $\ell^2$ norm of the eigndecomposition and $\lambda_k^{1/4} \leq 1 + \lambda_k^{1/2}$, we can easily bound this $H^{1/4}_D$ norm by interpolation and find
\[ B-\textrm{term} \lesssim \int \indic{\theta_+>0} + \int \theta_+^2 + \eps \int \abs{\Lambda^{1/2} \theta_+}^2. \]

From [cite] and [cite] we find that for any $\eps > 0$ arbitrarily small and some constant $C$ depending on $\eps$, $\norm{\grad\phi}_\infty$, $\norm{D^2 \phi}_\infty$, and on the shape (but not the size) of $\Omega$,
\[ \int \uhigh \theta_+ \grad \phi(x - \gamma(t)) \,dx \leq C \norm{\Lambda^{-1/4}\uhigh}_\infty \paren{\int \indic{\theta_+>0} + \int \theta_+ + \int \theta_+^2} + \eps \int \abs{\Lambda^{1/2} \theta_+}^2. \]

Time for the low pass term.  

Recall that
\[ \dot{\Gamma} + \dot{\gamma} = \ulow(t, \Gamma+\gamma) \]
and the low pass term is 
\[ \int (\ulow - \dot{\Gamma}) \theta_+ \grad\phi(x-\Gamma). \]

Calculate
\[ \ulow(t,x) - \dot{\Gamma}(t) = \ulow(t,x) - \ulow(t,\Gamma+\gamma) - \dot{\gamma} \leq |x-\Gamma-\gamma|^{3/4}. \]

It's easy to bound
\[ \dot{\gamma} \grad\phi(x-\Gamma) \leq C_\gamma \norm{\grad\phi}_\infty. \]

We can bound
\[ \ulow(t,x) - \ulow(t,\Gamma+\gamma) = (x)-(\Gamma) + (\Gamma)-(\Gamma+\gamma) \leq \bracket{\ulow}_{3/4} |x-\Gamma|^{3/4} + \norm{\ulow}_\Lip |t| C_\gamma. \]

All in all, for $t \in [-T,0]$,
\[ \abs{(\ulow-\dot{\Gamma}) \grad\phi(x-\Gamma)} \leq C(\phi, C_\gamma, \bracket{\ulow}_{3/4}, \norm{\ulow}_\Lip, T). \]

Thus
\[ \int (\ulow - \dot{\Gamma}) \theta_+ \grad\phi(x-\Gamma). \]

From this the result follows.  
\end{proof}

At last we can prove the De Giorgi lemmas.  

\begin{lemma}
Suppose that $\theta$ and $u = \ulow + \uhigh$ solve [cite] on $[-T,0]\times \Omega$ for some open $C^{2,\alpha}$ set $\Omega \subseteq \R^2$.  

Suppose that for some $\Gamma:[-T,0]\to \R^2$, 
\[ \theta(t,x) \leq |x-\Gamma(t)|^{1/4} \qquad \forall x \notin B_2(\Gamma(t)). \]
Suppose also that
\[ \ulow(t,\Gamma(t)+\gamma(t)) = \dot{\Gamma}(t) + \dot{\gamma}(t) \]
for some $\gamma$ with Lipschitz norm less than $C_\gamma$.  

Then there exist constants $\delta_0>0$ and $\eps > 0$ such that
\[ \int_{-2}^0 \int_{\Gamma(t)+B_2} \max(\theta,0)^2 \,dxdt \leq \delta_0 \]
implies that
\[ \theta(t,x) \leq 1 \qquad \forall (t,x) \in [-\eps,0]\times B_\eps(\Gamma(t) + \gamma(t)). \]

\end{lemma}

\begin{proof}
Let $\phi$ be such that $\phi = 0$ on $B_1$ and $\phi(x) \leq |x|^{1/4}$ for $|x|>2$ while $\phi$ is Lipschitz and $C^2$ and its gradient decays like $|x|^{-3/4}$.  Assume also that $\phi(x) \geq |x|^{1/4}$ for $|x|>2$.

Take $\eps$ small enough that $\eps C_\gamma \leq 1/2$.  Logan: this is circular, since $C_\gamma$ grows as $\eps$ shrinks.  In fact $C_\gamma$ grows logarithmically so the condition is satisfiable, but it must be rewritten eventually. 

Consider the sequence of functions
\[ \theta_k := (\theta(t,x) - \phi(x - \Gamma(t)) - 1 + 2^{-k})_+ \]
and define
\[ \E_k := \int_{-1-2^{-k}}^0 \int_\Omega \theta_k^2 \,dxdt. \]

Notice that
\[ \E_0 = \int_{-2}^0 \int_\Omega (\theta - \phi(x-\Gamma))_+ \,dxdt \leq \delta_0. \]
Moreover, as $k \to \infty$ we have
\[ \E_k \to \int_{-1}^0 \int_\Omega (\theta - \phi(x-\Gamma) - 1)_+ \]
so in particular, if we can show $\E_k \to 0$ then $\theta \leq 1$ for $t \in [-1,0]$ and $x \in B_1(\Gamma)$.  
%We want to show that $\E_0 \leq \delta_0$.  Certainly, for $|x-\Gamma|\leq 2$ this is the case.  What we need to show is that if $|x-\Gamma| \geq 2$ then $\theta(t,x) \leq \phi(x-\Gamma-\gamma)$.  Recall that in such a circumstance, by assumption, $\theta(t,x) \leq |x-\Gamma|^{1/4}$.  Thus we need to show that $|y|\geq 2$ implies $|y|^{1/4} \leq \phi(y-\gamma)$.  But $\gamma \leq 2 C_\gamma$ and $\phi$ is radially symmetric so $\phi(y-\gamma) \geq \phi(|y|-2 C_\gamma)$.  This is completely impossible, because we know $\phi(0)=0$ but $\gamma$ itself might get outside the region where we have control on the measure of $\theta$.  


%The question here is, it's hard to utilize the information about $\theta$ near $\Gamma$ since $\Gamma+\gamma$ moves away over such a long time scale.  This is solved on utilizing the output by shrinking the time scale, but how is it solved on the input?  I'm tempted to just use the energy inequality on $\phi$ shifted by $\Gamma$ (not $\Gamma + \gamma$) but that would require at least rewriting the energy inequality.  I also thought about using good bounds on $\phi$, like maybe if it grows slowly everything will just work out.  

While $t \in [-\eps, 0]$, since $\eps C_\gamma \leq 1/2$, we have
\[ |x - \gamma - \Gamma| \leq |x-\Gamma| + 1/2 \]
and hence $x \in B_{1/2}(\Gamma+\gamma)$ implies $x \in B_1(\Gamma)$.  Thus if we can show that $\E_k \to 0$ then
\[ \theta(t,x) \leq 1 \qquad \forall t,x \in [-\eps,0]\times B_{1/2}(\Gamma+\gamma). \]

That's enough setup, let's argue that $\E_k \to 0$.  Notice that when $\theta_{k+1}>0$, then in particular $\theta_k \geq 2^{-k}$ [or something similar].  Thus for any finite $p$, there exists a constant $C$ so
\[ \indic{\theta_{k+1}>0} \leq C^k \theta_k^p. \]
In particular,
\[ \E_{k+1} \leq C^k \int_{-1-2^{-k}}^0 \int \theta_k^3. \]

Applying the energy inequality $\theta$, $\phi$, and $\Gamma$ we obtain
\[ \sup_{-1-2^{-k-1}<t<0} \int \theta_{k+1}^2 + \int_{-1-2^{-k-1}}^0 \int \abs{\Lambda^{1/2}\theta_{k+1}}^2 \leq C^k \int_{-1-2^{-k}}^0 \theta_k^2 = \E_k. \]

However, by Sobolev embedding and the fact that $H_D^{1/2}$ controls classical $H^{1/2}$ controls $L^4$,
\[ \norm{\theta_{k+1}}_{L^3([-1-2^{-k-1},0]\times\Omega)} \leq C^k \E_k^{1/2}. \]

Therefore
\[ \E_{k+1} \leq C^k \E_k^{3/2}. \]

It follows by a well known result [citation] that for $\E_0$ sufficiently small (say less than $\delta_0$), $\E_k \to 0$ as $k \to \infty$ which we already established is sufficient to obtain our result.  
\end{proof}


This is coming along quite nicely.  We can move on to DG2, the isoperimetric inequality.  

\begin{lemma}
Let $\theta$ and $u = \ulow + \uhigh$ be solutions to [cite] satisfying the desired bounds.  Let $\Gamma$ and $\gamma$ be paths with the desired properties, in particular
\[ \dot{\Gamma} +\dot{\gamma} = \ulow(t,\gamma + \Gamma). \]

Suppose that for $t \in [-3,0]$, $\theta(t,x)$ has some tbd growth condition on $|x-\Gamma| > 3$ and $\theta \leq 2$ when $|x-\Gamma| \leq 3$.  

There exists a small constant $\mu$ such that the three conditions
\[ \abs{\{\theta \geq 1\} \cap [-2,0]\times B_2(\Gamma)} \geq \delta_0, \]
\[ \abs{\{0 < \theta < 1\} \cap [-3,0]\times B_3(\Gamma)} \leq \mu, \]
\[ \abs{\{\theta \leq 0\} \cap [-3,0]\times B_3(\Gamma)} \geq \frac{3 |B_3|}{2} \]
cannot simultaneously be met.  
\end{lemma}

\begin{proof}
Suppose that $\theta_n$ is a sequence of counterexamples for $\mu = 1/n$.  We wish to show that these counterexamples have a limit which violates basic principles.  

Let $\phi$ be a function which vanishes on $B_2$ but has all the growth and smoothness properties.  In particular assume that $\phi$ exceeds the growth condition (whatever it turns out to be) on $\theta$ for $|x|>3$.  Apply the energy inequality with $\phi(x-\Gamma)$, and find that
\[ \sup_{[-2,0]} \int \theta_+^2 + \int_{-2}^0 \int \abs{\Lambda^{1/2}\theta_+}^2 \leq C \int_0^3 \int \paren{\indic{\theta_+>0} + \theta_+ + \theta_+^2}. \]
This proves in particular that $\theta_+ \in L^2([-2,0]; H_D^{1/2}(\Omega))$ is uniformly bounded.  Because, by equivalence of $H^s$ and $H^s_D$, this space is compact in $L^2(\Omega)$, this is the first ingredient in applying the Aubin-Lions lemma.  

Since $\theta_n$ solves the desired equation, 
\[ \del_t \theta_+ + \indic{+}\del_t \phi(\cdot-\Gamma) + u\cdot\grad\theta_+ + \indic{+}u\cdot\grad\phi(\cdot-\Gamma) + \Lambda \theta_+ + \indic{+} \Lambda\phi(\cdot-\Gamma) - \indic{+}\Lambda\theta_- = 0. \]

In fact we can simplify
\[ -\indic{+} \dot{\Gamma} \cdot\grad\phi + u\cdot\grad\theta_+ + \indic{+} u\cdot\grad\phi + = \indic{+} (u - \dot{\Gamma})\grad\phi + u\grad\theta_+. \]
Therefore
\[ -\del_t\theta_+ = \indic{+} (u - \dot{\Gamma})\grad\phi + u\grad\theta_+ + \Lambda \theta_+ + \indic{+}\Lambda\phi - \indic{+}\Lambda \theta_-. \]

\end{proof}

\section{Control on $u$}
Let's assume that our drift term is a sum of $u_j$ for $j \in \Z$ and a constant which is tbd.  Assume that each $u_j$ is an $L^\infty$ function, and that their sum converges to $u$ in $L^2(\Omega)$, and that each $u_j$ specfies the bounds as stated.  First we show that they sum up to $u_h$ and $u_l$ in the ways desired.  Then we show that the properties required are maintained as we zoom.  Then at last we argue that, before any zooming, $u$ really does have this property.  

Firstly, assume that 
\[ u = \lim_{L^2} \sum_{-N}^N u_j, \]
with the $u_j$ satisfying
\begin{align*} 
\norm{u_j}_\infty &\leq \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j, \\
\bracket{u_j}_{3/4} &\leq \kappa 2^{j 3/4}. 
\end{align*}
We then define
\[ u_h = \sum_{j=0}^\infty u_j \]
and 
\[ u_\ell = \sum_{-\infty}^{j=-1} u_j. \]

Since $u_j \in L^\infty$ in particular they are $L^2$ functions which sum in $L^2$.  Remember that only finitely many negative $j$ have $u_j \neq 0$.  The sequence $u_j$ is thus singly infinite and in particular is a Cauchy sequence, so $u_h$ also converges in $L^2$.  Since $\Lambda^{-1/4}$ is a continuous linear operator, it passes to the partial sums and so
\[ \Lambda^{-1/4} u = \lim_{L^2} \sum_{j=0}^\infty \Lambda^{-1/4} u_j. \]
In particular, the sum converges in the sense of distributions, i.e. in $\test(\Omega)'$.  Since test functions are dense in $L^1(\Omega)$, and the partial sums are uniformly bounded in the dual of $L^1(\Omega)$ (namely $L^\infty(\Omega)$), therefore the limit $\Lambda^{-1/4} u_h$ is also bounded in the dual of $L^1(\Omega)$.  
\[ \norm{\Lambda^{-1/4} u_h}_\infty \leq \sum_{j=0}^\infty \norm{\Lambda^{-1/4} u_j}_\infty \leq \kappa \frac{1}{1-2^{-1/4}}. \]

As for $u_\ell$, we have that $\sum_{j < 0} u_j$ converges in $L^2$, and hence also in the sense of distributions $\test(\Omega)'$.  Since $\grad$ is continuous on distributions, also $\sum_{j<0} \grad u_j$ converges to $\grad u_\ell$.  But each partial sum is uniformly bounded in the dual of $L^1(\Omega)$, meaning that the limit $\grad u_\ell$ is also bounded in the dual, $L^\infty(\Omega)$.  
\[ \norm{\grad u_\ell}_\infty \leq \sum_{j < 0} \norm{\grad u_j}_\infty \leq \kappa \frac{1/2}{1 - 2^{-1}} = \kappa. \]

\begin{lemma}{Scaling}
Suppose that $\theta$ solves the PDE
\[ \bracket{\del_t + u\cdot\grad + \Lambda} \theta = 0\]
where the velocity $u$ satisfies
\[ u = \sum_{j=-\infty}^\infty u_j \]
with that sum converging in $L^2(\Omega)$.  Suppose that the domain of definition is $(-T,0) \times \Omega$, and $0 \in \del \Omega$.  Suppose that
\begin{align*}
\norm{u_j}_\infty &\leq \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq \kappa 2^{-j/4}, \\
\norm{\grad u_j}_\infty &\leq \kappa 2^j.
\end{align*}

Let $\eps$ be a small constant which is a power of 2, $\eps = 2^{-N}$. Then
\[ \bar{\theta}(t,x) = \theta(\eps t, \eps x) \]
satisfies all of the same constraints for $(t,x) \in [-T/\eps, 0]\times \Omega_\eps$.  

Moreover, 
\[ \norm{\sum_{j=-\infty}^0 \bar{u}_j(t,0) - \sum_{j=-\infty}^0 u_j(\eps t, 0)}_\infty \leq \kappa N. \]
\end{lemma}

\begin{proof}
Denote $p = (t,x)$ and $\bar{p} = (\eps t, \eps x + \gamma(\eps t))$.  

We calculate
\[ \del_t \bar{\theta}(p) = \eps \del_t \theta(\bar{p}) + \eps \dot{\gamma}(\bar{p}) \cdot \grad \theta (\bar{p}) \]
and 
\[ \grad \bar{\theta}(p) = \eps \grad \theta(\bar{p}) \]
and
\[ \Lambda \bar{\theta}(p) = \eps \Lambda \theta(\bar{p}). \]

Thus, if we define
\[ \bar{u}(p) = u(\bar{p}) - \dot{\gamma}(\bar{p}) \]
then it will be the case that, for $p \in [-T/\eps,0]\times \Omega_\eps$, 
\[ \bracket{\del_t + \bar{u}\cdot\grad + \Lambda} \bar{\theta}(p) = \eps \bracket{\del_t + u\cdot\grad + \Lambda} \theta(\bar{p}). \]

It remains to demonstrate the decomposition of $\bar{u}$ and that $\bar{\gamma}$ still makes $\bar{u}_\ell(0)=0$, let alone that $0$ is still on the boundary of $\Omega_\eps$.  

Recall that for a positive integer $N$, $2^N \eps = 1$.  We define 
\[ \bar{u}_j(p) := u_{j+N}(\bar{p}), \]
that is each $u_j$ is scaled appropriately and then the labels are shifted by $N$.  Our new decomposition of $\bar{u}$ is
\begin{align*} 
\bar{u}(p) &= u(\bar{p}) - \dot{\gamma}(\bar{p})
\\ &= \upsilon(\bar{p}) + \sum u_j(\bar{p}) + \dot{\gamma}(\bar{p})
\\ &= \bracket{\upsilon(\bar{p}) + \dot{\gamma}(\bar{p})} + \sum \bar{u}_j (p)
\end{align*}
which means
\[ \bar{\upsilon}(p) = \upsilon(\bar{p}) + \dot{\gamma}(\bar{p}). \]

We easily bound the $\bar{u}_j$:
\begin{align*}
\norm{\Lambda^{-1/4} \bar{u}_j}_\infty &= \eps^{-1/4}\norm{\Lambda^{-1/4} u_{j+N}}_\infty 
\\ &\leq \eps^{-1/4} \kappa 2^{-(j+N)/4}
\\ &= (\eps 2^N)^{-1/4} \kappa 2^{-j/4} = \kappa 2^{-j/4}.
\end{align*}
Also,
\begin{align*}
\norm{\grad \bar{u}_j}_\infty &= \eps \norm{\grad u_{j+N}}_\infty
\\ &\leq \eps \kappa 2^{j+N} = \kappa 2^j.
\end{align*}

To confirm the desired properties of $\bar{\upsilon}$, we want to say that
\[ \bar{\upsilon}(t) = \sum_{j<0} \bar{u}_j(t,0) \]
or equivalently
\[ \dot{\gamma}(\eps t) = -\upsilon(\eps t) +  \sum_{j<0} u_{j+N}(\eps t, \gamma(\eps t)). \]
By the Caratheodory Existence theorem, there exists a function $\gamma$ which satisfies this relationship for a.e. $t \in [-T/\eps, 0]$.  I can choose the initial condition, and I don't know what I want, so how about $\gamma(0)=0$.  

In fact, since $-\upsilon(t) + \sum_{j<-N} u_{j+N}(t,0)$ vanishes by assumption, we can say in fact that 
\[ -\upsilon(t) +  \sum_{j<0} u_{j+N}(t, 0) = \sum_{j=0}^{N-1} u_j(t,0) \leq N \norm{u_j}_\infty. \]
Here it's relevant that $\norm{u_j}_\infty$ is independent of $j$, which I know but have not proven or even stated before.  Since $\sum_{j<N} u_j$ is a Lipschitz function, with Lipschitz constant $\kappa 2^N$, we can bound $\gamma$
\[ \dot{\gamma}(t) \leq N \norm{u_j}_\infty + \kappa 2^N |\gamma(t)|. \]
That's a Lipschitz bound on $\gamma$.  It becomes a real bound
\[ \gamma(t) \leq N 2^{-N} (\exp(\kappa 2^N t)-1). \]

All that remains is the most important part.  Showing that our $\gamma$ is small enough and of the correct nature such that the information we get about $\bar{\theta}$ will be useful.  

For example, we probably want that $\gamma(t) \in \del \Omega$ for all $t$.  Why would that be true?  It's actually not.  No matter what $\gamma$ is, the $u_j$ terms point along the boundary and hence they can never turn $\dot{\gamma}$ in a direction so as to go ``off the rails'' so to speak.  On the other hand, $\upsilon$ is only tangential at the origin.  Elsewhere, $\upsilon$ might as well have a tangential component.  

Wait, I'm adding $\dot{\gamma}$ to $\upsilon$.  But $\upsilon$ is a scalar, it's the value of $u_\ell$ at 0, while $\dot{\gamma}$ is a vector, it's the time derivative of a moving point in $\R^2$.  That seems off.  No way man, $u$ is vector valued, so $\upsilon$ is too.  All good.  

Let's get to it.  Define
\[ f(t,x) = -\upsilon(t) + \sum_{j < N} u_j(t,x). \]
This function is Lipschitz in $x$, with constant $\kappa 2^N$.  Morever, $f(t,0) \leq \kappa N$.  

It's important that $(t,0) \mapsto (\eps t, \gamma(\eps t))$ is on the boundary of $\Omega$.  So we want that $\dot{\gamma}(t)$ is pointing along the boundary of $\Omega$ at $\gamma(t)$.  


\end{proof}

New idea is to drop all the $\gamma$ nonsense.  Instead, we argue that even though $u_\ell(t,0)$ is large in the $L^\infty(L^\infty)$ sense, it is small in the $L^1(L^\infty)$ sense (that's integration in time).  This makes sense, because every time we zoom in by $\eps = 2^N$, we increse the $L^\infty(\Omega)$ norm by $\kappa N$ but we also shrink the time interval by $2^N$.  I believe that this is essentially the property that we exploit in the drift formulation, namely that the correction term $\gamma$ may be large in principle but $\dot{\gamma}$ is small so over small enough time intervals, $\gamma$ is small.  It's important that the $L^1(L^\infty)$ norm not only grow slowly but actually grow in a summable manner, so that after 1 million zooms still the error introduced is bounded.  

Even if we can do all that, how do we formulate that error term and how do we deal with it in the energy inequality?  Well, let's say that
\[ u_\ell = \tau + \sigma \]
where $\tau$ is a function of time alone and $\sigma$ is both Lipschitz in space and $\sigma(t,0) = 0$.  The Lipschitz constant of $\sigma$ grows with each zoom, in such a way as to effectively cancel out the gains we get from zooming so the effective $L^\infty$ norm remains constant.  Similarly, the quantitative bound on $\tau$ grows with each zoom in such a way as to cancel out the gains of zooming so that its integral remains constant.  

Now in the energy inequality, we have three terms $u = \tau + \sigma + u_h$.  Remember that the energy inequality contains
\[ \iint \theta_+ u \cdot \grad \psi. \]
We bound this integral using the duality pairing, $L^1(L^\infty)$ vs $L^\infty(L^2)$ and absorb the $\theta_+$ into the $\sup \int \theta_+^2$ term on the left hand side.  We do some pro forma nonsense to keep a factor of $\int \chi_+$ involved on the remainder and zoop zop wop we're done.  I'm a genius.  

Okay, this has gotten ridiculous.  As of April 24th, the statement of the scaling theorem seems right but the proof is well out of date.  




\section{The Japanese Stuff}

Logan: The japanese paper's Lemma 3.6, used extensively here, only applies in the case $j \geq 0$. Obviously I need it and use it for $j > j_0$.  This is equivalent, I can see from the proof, but maybe mention the issue somewhere so it doesn't seem like I didn't notice.  

In this section we will prove that $u$ breaks up into pieces with various norms under control.  

We know that $\theta \in L^\infty$.  Let $\phi$ be a Schwartz function on $\R$ which is suited to Littlewood-Paley decomposition.  That is, for example, $\phi(2^j x) \phi(2^i x) = 0$ unless $|i-j|\leq 1$ and $\sum \phi(2^j) = 1$.  We have some projections 
\[ P_j f := \sum_k \phi(2^j \lambda_k^{1/2}) f_k \eigen{k}. \]

Recall that $P_j = 0$ for $j$ sufficiently small, because $-\Laplace_D$ has a smallest eigenvalue.  

For each $j \in \Z$, I'll define
\[ u_j := \grad^\perp \Lambda^{-1} P_j \theta. \]
Qualitatively, we know that $\theta \in L^2$ and hence $u_j \in L^2$.  In fact, $u = \sum u_j$ in the $L^2$ sense.  

Firstly, we know by [citation] Fornare, Metafune and Priola that if $\Omega$ is $C^{2,\alpha}$ then
\[ \norm{\grad e^{-t\Laplace_D}}_{L^\infty \to L^\infty} \leq \frac{C}{\sqrt{t}} \qquad 0 < t \leq 1. \]
According to [citation] Iwabuchi, Matsuyama, and Tanaguchi's paper Bilinear Estimates, Lemma 3.6, this is enough to show that
\[ \norm{u_j}_\infty \leq C \norm{\theta}_\infty. \]

We'll need a lemma now,
\begin{lemma}
For any function $f$,
\[ \norm{P_i \grad P_j f}_\infty \leq C \min(2^j,2^i) \norm{f}_\infty. \]
\end{lemma}
\begin{proof}
Let $g$ be an $L^1$ function.  Then
\[ \int g P_i \grad P_j f = \int (P_i g) \grad P_j f \leq C 2^j \norm{g}_1 \norm{f}_\infty \]
from [citation] IMT-Bilinear, Lemma 3.6 and Proposition 3.3 (which is also IMT Boundedness of Spectral Multiplies for Schrodinger Operators on Open Sets, Theorem 1.1).  

Further integrating by parts,
\[ \int g P_i \grad P_j f = - \int (\grad P_i g) P_j f \leq C 2^i \norm{g}_1 \norm{f}_\infty. \]
This follows from the same theorems as above.  

The result follows.  
\end{proof}

Since $u_j \in L^2$, we know that
\[ \Lambda^{-1/4} u_j = \sum_{i \in \Z} P_i \Lambda^{-1/4} u_j. \]
Define $\bar{P}_j$ a projection which is 1 on the support of $P_j$ (functional calculus-wise).  Then $\bar{P}_j P_j = P_j$, and since both types of projections are spectral operators, they both commute with $\Lambda^s$.  We therefore rewrite
\[ \paren{P_i \Lambda^{-1/4} u_j}^\perp = \paren{\Lambda^{-1/4} \bar{P}_i} P_i \grad P_j \paren{\Lambda^{-1} \bar{P}_j} \theta. \]
We apply sequentially three bounded operators on $L^\infty$.  The outer two operators have bounded norm by [citation] IMT-Bilinear Proposition 3.3, and the inner operator has bounded norm by the above lemma, (and of course the perp operator is an isometry,) so 
\[ \norm{ P_i \Lambda^{-1/4} u_j}_\infty \leq C 2^{-i/4} \min(2^j, 2^i) 2^{-j} \norm{\theta}_\infty. \]
%
% so from [citation] IMT-Bilinear Proposition 3.3 we can see that
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty = \norm{\Lambda^{-1/4} \bar{P}_i P_i u_j}_\infty \leq C 2^{-i/4} \norm{P_i u_j}_\infty \]
%and also
%\[ P_i u_j = P_i \grad P_j \Lambda^{-1} \bar{P}_j \theta. \]
%Thus by the lemma,
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty \leq C 2^{-i/4} \min(2^j,2^i) \norm{\Lambda^{-1} \bar{P}_j \theta}_\infty \leq C 2^{-j} 2^{-i/4} \min(2^j,2^i) \norm{\theta}_\infty. \]
Summing these bounds on the projections of $\Lambda^{-1/4} u_j$, and noting that
\[ \sum_{i \in \Z} 2^{-j} 2^{-i/4} \min(2^j,2^i) = 2^{-j} \sum_{i \leq j} 2^{i 3/4} + \sum_{i>j} 2^{-i/4} \leq C 2^{-j/4}, \]
we obtain
\[ \norm{\Lambda^{-1/4} u_j}_\infty \leq C 2^{-j/4} \norm{\theta}_\infty. \]

Lastly, we'll show that $\grad u_j$ is in $L^\infty$.  Equivalently, we'll show that $\Lambda^{-1} P_j \theta$ is $C^{1,1}$.  This is essentially Schauder theory.  We will obtain our $C^{1,1}$ bound by interpolating between a $C^{0,1}$ bound and a $C^{2,\alpha}$ bound.  We could also obtain a $C^{1,\alpha}$ bound directly using the main theorem of [citation] Caffarelli-Stinga, but those estimates are not well-articulated in the specific context of our problem (namely, it's hard to make good use of the fact that $f$ near the boundary).  So instead, we use interpolation.  

The $C^{0,1}$ bound is already known, it's the estimate
\[ \norm{\grad \Lambda^{-1} P_j \theta}_\infty \leq C \norm{\theta}_\infty. \]
The $C^{2,\alpha}$ bound is classical Schauder theory.  For convenience, define 
\[ F := \Lambda^{-1} P_j \theta \]
and recall that $F$ is a finite linear combination of Dirichlet eigenfunctions, so in particular it is smooth and vanishes at the boundary.  Moreover, its Laplacian is 
\[ f := \Laplace F = \Lambda P_j \theta \]
which is also smooth, vanishes at the boundary, and has various bounds.  Specifically, we want to apply Theorem 6.6 from [citation] Gilbarg and Trudinger, page 98 in my library copy.  It says that since $\Omega$ is $C^{2,\alpha}$ and $F \in C^{2,\alpha}(\bar{\Omega})$, and since $f \in C^\alpha(\bar{\Omega})$, and since the boundary conditions are homogeneous (hence smooth), then
\[ \sup_{x,y \in \Omega} \frac{\abs{D^2 F(x)- D^2 F(y)}}{|x-y|^\alpha} \leq C \norm{F}_\infty + C \norm{f}_\infty + C \sup_{x,y\in\Omega} \frac{\abs{f(x)-f(y)}}{|x-y|^\alpha}. \]

A lemma with two interpolations:
\begin{lemma}
If $f \in L^\infty(\Omega) \cap C^{0,1}(\Omega)$ then for some universal constant $C$,
\[ \bracket{f}_\alpha \leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha. \]

If $f \in C^{0,1}(\Omega) \cap C^{2,\alpha}(\Omega)$ where $\Omega$ satisfies the cone condition, then for some constants $C$ and $\ell$ depending on $\Omega$,
\[ \norm{D^2 f}_\infty \leq C \delta\n \norm{\grad f}_\infty  + \delta^\alpha \bracket{D^2 f}_\alpha\]
for all $\delta < \ell$.  
\end{lemma}
\begin{proof}
The first claim is incredibly straigtforward.  We include it for completeness.  
\begin{align*} 
\sup_{x,y \in \Omega} \frac{|f(x)-f(y)|}{|x-y|^\alpha} &= \sup |f(x)-f(y)|^{1-\alpha} \paren{\frac{|f(x)-f(y)|}{|x-y|}}^\alpha 
\\ &\leq \paren{2 \norm{f}_\infty}^{1-\alpha} \paren{ \sup \frac{|f(x)-f(y)|}{|x-y|} }^\alpha
\\ &\leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha.
\end{align*}

The second claim is more complicated.  We'll prove the equivalent claim that for $f$ smooth,
\[ \norm{\grad f}_\infty \leq C \delta\n \norm{f}_{L^\infty(\bar{\Omega})} + \delta^\alpha \bracket{\grad f}_{\alpha;\bar{\Omega}}.\]
Since $\Omega$ satisfies the cone condition, we know that there exist positive constants $\ell$ and $a$ such that, at each point $x \in \bar{\Omega}$, there exist two unit vectors $e_1$ and $e_2$ such that $e_1\cdot e_2 \leq a$ and $x + \tau e_i \in \Omega$ for $i=1,2$, $0 < \tau \leq \ell$.  In other words, $\Omega$ contains rays at each point that extend for length $\ell$, end at $x$, and are non-parallel with angle at least $\cos\n(a)$.  

The idea of the proof is that the average of $\grad f$ along an interval is bounded since $f$ is bounded, and the same average is close to the value of $\grad f$ at a point because $\grad f$ is continuous, hence the value of $\grad f$ at any point must be bounded.  By varying the length $\delta$ of the aforementioned interval, we actually get a parameterized family of bounds.  

If we consider the directional derivative $\del_i f$ of $f$ along the direction $e_i$, then observe that for any $0 < \delta \leq \ell$,
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau = f(x+\delta e_i) - f(x). \]
This quantity on the right is bounded by the $L^\infty$ norm of $f$.  

On the other hand, since $\grad f$ and hence $\del_i f$ are continous functions, for any $\tau \in (0,\ell]$
\[ \abs{\del_i f(x) - \del_i f(x+\tau e_i)} \leq \bracket{\grad f}_\alpha \tau^\alpha. \]
From this bound, we obtain that
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau \leq \int_0^\delta \del_i f(x) + \bracket{\grad f}_\alpha \tau^\alpha \,d\tau = \delta \del_i f(x) + \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha} \]
and similarly from below, so
\[ \delta \del_i f(x) - \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha} \leq \int_0^\delta \del_i f(x + \tau e_i) \,d\tau \leq \delta \del_i f(x) + \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha}. \]

What we have shown is that the integral of $\del_i f$ over an interval of length $\delta$ is small, and also it differs not very much from $\delta \del_i f(x)$.  By rearranging, we find that $\del_i f(x)$ must therefore be small:
\[ \abs{\del_i f(x)} \leq \frac{2}{\delta} \norm{f}_\infty + \frac{\delta^\alpha}{1+\alpha} \bracket{\grad f}_\alpha. \]
This is true independent of $x$ and of $i=1,2$.  Since $e_1 \cdot e_2 \leq a$ by assumption, by a little linear algebra we can bound $\grad f$ in terms of the $\del_i f$ and obtain that, for all $\delta \in (0,\ell]$,
\[ \norm{\grad f}_\infty \leq \frac{C}{1-a^2} \paren{ \delta\n \norm{f}_\infty + \delta^\alpha \bracket{\grad f}_\alpha }. \]

\end{proof}

Let's bound the terms of the Gilbarg-Trudinger inequality.  By [citation] IMT-Bilinear Proposition 3.3
\[ \norm{f}_\infty = \norm{\Lambda P_j \theta}_\infty \leq C 2^j \norm{\theta}_\infty \]
while by [citation] IMT-Bilinear Lemma 3.6
\[ \norm{\grad f}_\infty = \norm{\grad \Lambda P_j \theta}_\infty \leq C 2^{2j} \norm{\theta}_\infty. \]
Therefore we can interpolate
\[ \bracket{f}_\alpha \leq C 2^{j(1+\alpha)} \norm{\theta}_\infty. \]
And of course, by [citation] IMT-Bilinear Proposition 3.3
\[ \norm{F}_\infty = \norm{\Lambda^{-1} P_j \theta}_\infty \leq C 2^{-j} \norm{\theta}_\infty. \]

Combining these estimates with [citation: the Gilbarg-Trudinger thingy] we find
\[ \bracket{D^2 F}_\alpha \leq C \paren{2^{-j} + 2^j + 2^{j(1+\alpha)}} \norm{\theta}_\infty. \]

At long last, the big estimate,
\[ \norm{D^2 F}_\infty \leq C \paren{\delta\n \norm{\grad F}_\infty + \delta^{\alpha} \bracket{D^2 F}_\alpha}. \]

Since $\Omega$ is bounded, there exists a $j_0$ such that $P_j = 0$ if $j < j_0$.  Therefore we assume withouth loss of generality that $j \geq j_0$.  Thus $2^{-j} \leq 2^{j(1+\alpha)} 2^{-j(2+\alpha)} \leq 2^{j(1+\alpha)} 2^{-j_0(2+\alpha)}$ and similarly $2^j \leq 2^{j(1+\alpha)}2^{-j\alpha} \leq 2^{j(1+\alpha)} 2^{-j_0\alpha}$.  We can therefore say that for all $\delta \leq \ell$,
\[ \bracket{D^2 F}_\infty \leq C \paren{\delta\n C + \delta^\alpha 2^{j(1+\alpha)}} \norm{\theta}_\infty. \]

Set $\delta = 2^{-j} 2^{j_0} \ell \leq \ell$.  Then
\[ \bracket{D^2 F}_\infty \leq C \paren{C 2^j + 2^{-j\alpha} 2^{j(1+\alpha)}} \norm{\theta} = C(\Omega) 2^j \norm{\theta}. \]
But $D^2 F = \grad u_j$ so we are done.  


\section{Harnack Inequality}

\[ \dot{\gamma} = \ulow(t,\Gamma + \gamma) \]
it's lipschitz, $\ulow = u_1 + u_2$ and $\dot{\Gamma} = u_1(t,\Gamma)$ and $u_2 \leq N$
\[ |\dot{\gamma} - \dot{\Gamma}| \leq |u_2(t,\Gamma + \gamma)| + |u_1(t,\Gamma+\gamma) - u_1(t,\Gamma)|. \]
Nope.  
\[ \dot{\gamma} = u_1(t,\Gamma + \gamma) + u_2(t,\Gamma + \gamma) \leq N + \norm{u_1}_\Lip |\gamma| \]
which means we must solve the ODE
\[ \int \frac{\gamma'}{N + k \gamma} \,dt = t + C, \]
\[ \ln(N+k \gamma) = k t + C \]
\[ N + k \gamma = C e^{k t} \]
\[ \gamma = C e^{k t} - \frac{N}{k}. \]
And recall $\gamma(0)=\Gamma(0) = 0$ so
\[ \gamma(t) \leq \frac{N}{k} e^{kt} - \frac{N}{k}. \]
Since I'm only considering timescales up to $T$ anyways, that's still bounded.  Is that okay?  I have no idea.  

%\newcommand{\uhighth}[1]{\uhigh^{#1}}
%\newcommand{\ulowth}[1]{\ulow^{#1}}

Define
\begin{align*} 
\theta_k(t,x) &:= (1-\lambda)^{-k} \theta(\eps^k t, \eps^t x), \\
\ulowth{0}(t,x) &:= \sum_{j \leq 0} u_j(t,x), \\
\umidth{0}(t,x) &:= 0, \\
\uhighth{0}(t,x) &:= \sum_{j > 0} u_j(t,x), \\
\ulowth{k}(t,x) &:= \sum_{j \leq -(k-1) \ln(\eps)} u_j(\eps^k t, \eps^k x), \qquad k > 0, \\
\umidth{k}(t,x) &:= \sum_{-(k-1) \ln(\eps) < j \leq - k \ln(\eps)} u_j(\eps^k t, \eps^k x), \qquad k > 0, \\
\uhighth{k}(t,x) &:= \sum_{j > -k \ln(\eps)} u_j(\eps^k t, \eps^k x), \qquad k > 0, \\
\Gamma_0(t) &:= 0 \\
\dot{\gamma}_k(t) &:= (\ulowth{k} + \umidth{k})(t, \Gamma_k(t) + \gamma_k(t)) - \Gamma_k(t) \\
\gamma_k(0) &:= 0 \\
\Gamma_k(t) &:= \eps\n \gamma_{k-1}(\eps t) + \eps^{-2} \gamma_{k-2}(\eps^2 t) + \cdots + \eps^{-k} \gamma_0(\eps^k t). 
\end{align*}

The idea is that $u = \ulowth{0} + \uhighth{0}$ but that after zooming $u(\eps^k t, \eps^k x) = \ulowth{k}(t,x) + \umidth{k}(t,x) + \uhighth{k}(t,x)$.  That is, each $u_j$ zooms in as $k$ increases, and that a few of the $u_j$ get peeled out of the high piece and placed into the middle piece, while the old middle piece is added to the new low piece.  It is $\umidth{k}$ and $\ulowth{k}$ together that will be put into the De Giorgi lemmas, acting as $\ulow$.  

Note that
\[ \ulowth{k+1}(t,x) = \ulowth{k}(\eps t, \eps x) + \umidth{k}(\eps t, \eps x). \]

Maybe instead of any of this ``middle'' nonsense, we introduce the notation
\[ \sum_k = \sum_{j > - k \ln(\eps)} \]
while
\[ \sum^k = \sum_{j \leq -k \ln(\eps)}. \]

Define
\begin{align*} 
\theta_k(t,x) &:= (1-\lambda)^{-k} \theta(\eps^k t, \eps^t x), \\
\ulowth{k}(t,x) &:= \sum^k u_j(\eps^k t, \eps^k x), \\
\uhighth{k}(t,x) &:= \sum_k u_j(\eps^k t, \eps^k x), \\
\Gamma_0(t) &:= 0 \\
\dot{\gamma}_k(t) &:= \ulowth{k}(t, \Gamma_k(t) + \gamma_k(t)) - \dot{\Gamma}_k(t) \\
\gamma_k(0) &:= 0 \\
\Gamma_k(t) &:= \eps\n \gamma_{k-1}(\eps t) + \eps^{-2} \gamma_{k-2}(\eps^2 t) + \cdots + \eps^{-k} \gamma_0(\eps^k t). 
\end{align*}
Use [citation] some lemma from Bahouri-Chemin-Danchin that's a generalization of Picard-Lindelof.  

Recall the bounds, which will be rephrased to match the proofs above later (the above will be rephrased, that is),
\[ \norm{\Lambda^{-1/4} \uhighth{k} }_\infty \leq \sum_k \eps^{-k/4} 2^{-j/4} \kappa \leq \eps^{-k/4} C 2^{k \ln_2(\eps) /4} \kappa = C \kappa \]
for some universal constant $C$ (it's literally a decimal, it's that universal).  Similarly, for some different universal constant,
\[ \norm{\grad \uhighth{k} }_\infty \leq \sum^k \eps^{k} 2^{j} \kappa \leq \eps^{k} C 2^{-k \ln_2(\eps)} \kappa = C \kappa. \]
For each norm of interest, there's a constant corresponding to that norm such that, for $\ulow$ and $\uhigh$, it's less than $C \kappa$.  Note that these bounds do not depend on $k$.  

I want to claim that 
\[ \dot{\Gamma}_k(t) = \sum^{k-1} (\eps^k t, \eps^k \Gamma_k(t)). \]
This makes sense, because $\Gamma_{k+1}(t) = \eps\n \gamma_k(\eps t) + \eps\n \Gamma_k(\eps t)$.  

Well, $\dot{\gamma}_0(t) = \ulowth{0}(t,\gamma_0(t))$.  Moreover, 
\[ \ulowth{k}(t,\Gamma_{k+1}(t)) = \ulowth{k}(\eps\n \eps t, \eps\n \bracket{\gamma_k(\eps t) + \Gamma_k(\eps t)}) \]
or
\begin{align*} 
\sum^k u_j(\eps^{k+1} t, \eps^{k+1} \Gamma_{k+1}(t)) &= \sum^k u_j(\eps^k \eps t, \eps^k \bracket{\gamma_k(\eps t) + \Gamma_k(\eps t)})
\\ &= \ulowth{k}(\eps t, \gamma_k(\eps t) + \Gamma_k(\eps t))
\\ &= \dot{\gamma}_k(\eps t) + \dot{\Gamma}_k(\eps t)
\\ &= \del_t \bracket{\eps\n \gamma_k(\eps t) + \eps\n \Gamma_k(\eps t)}
\\ &= \dot{\Gamma}_{k+1}(t).
\end{align*}

In other words,
\[ \dot{\Gamma}_k(t) = \sum^{k-1} u_j(\eps^k t, \eps^k \Gamma_k(t)) \qquad k \geq 5. \]
I should think more about what exactly happens at the edge case of $j=0,1$.  

With this in hand, we can bound the size of $\gamma_k$.  Namely,
\begin{align*}
\dot{\gamma}_k(t) &= \ulowth{k}(t, \Gamma_k(t) + \gamma_k(t)) - \dot{\Gamma}_k(t)
\\ &= \sum^k u_j(\eps^k t, \eps^k \Gamma_k(t) + \eps^k \gamma_k(t)) - \sum^{k-1} u_j(\eps^k t, \eps^k \Gamma_k(t))
\\ &= \sum^{k-1} \bracket{u_j(\eps^k t, \eps^k \Gamma_k(t)+\eps^k \gamma_k(t)) - u_j(\eps^k t, \eps^k \Gamma_k(t))} + \sum_{k-1}^k u_j(\eps^k t, \eps^k \ldots).
\end{align*}
The sum $\sum^{k-1} u_j(\eps^k \cdot, \eps^k \cdot) = \ulowth{k-1}(\eps \, \cdot, \eps \, \cdot)$ is Lipschitz in space, with Lipschitz constant less than $\eps C \kappa$.  Moreover, each $u_j$ has $\norm{u_j}_\infty \leq \kappa$.  Thus both terms of $\dot{\gamma}_k(t)$ are bounded
\[ |\dot{\gamma}_k(t)| \leq \eps C \kappa |\gamma_k(t)| - \kappa \ln_2(\eps). \]
This, by Gronwall's inequality, tells us that for $t \in [-T,0]$,
\[ |\gamma_k(t)| \leq \frac{-\ln_2(\eps)}{\eps C} \paren{ e^{ \eps C \kappa T} - 1} \]
and hence
\[ |\dot{\gamma}_k(t)| \leq -\kappa \ln_2(\eps) e^{\eps C \kappa T} = C_\gamma = C_\gamma(T,\eps,\kappa). \]
Note in particular that $C_\gamma$ cannot be made small by altering any quantity that we have fine control over.  Since we may have trouble making the same argument for $\gamma_0$, we can if necessary take the max of $C_\gamma$ as defined above and $C \kappa j_0$.  The key is that the $\gamma_k$ are uniformly Lipschitz.  Trivially
\[ |\dot{\Gamma}_k(t)| \leq k C_\gamma. \]

Lastly, let us state for the record that
\[ \del_t \bracket{\gamma_k(t) + \Gamma_k(t)} = \ulowth{k}(t,\gamma_k(t)+\Gamma_k(t)). \]

\end{document}