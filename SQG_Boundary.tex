\documentclass[11pt]{amsart}
\usepackage{amssymb,amsbsy,upref,epsf,MnSymbol}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx,mathtools,mathrsfs,wrapfig}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{enumerate}



%-------------------------------------------<commands>--------------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Prj}{\mathbb{P}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\Four}{\mathcal{F}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\E}{\mathcal{E}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\eps}{\varepsilon}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\chevron}[1]{\langle #1 \rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\convex}{conv}
\DeclareMathOperator{\image}{Im}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\lspan}{span}
\DeclareMathOperator{\conv}{conv} % stands for conv, as in convex hull
\DeclareMathOperator{\Int}{int} % stands for int, as in interior of a set
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\rank}{rank}
%\DeclareMathOperator{\dim}{dim}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\cod}{\operatorname{cod}}
\newcommand{\Hom}{\operatorname{hom}}
\newcommand{\Ob}{\operatorname{Ob}}
\newcommand{\cl}{\operatorname{cl}}
\DeclareMathOperator{\BMO}{BMO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\del}{\partial}
\newcommand{\pvec}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\grad}{\nabla}
\newcommand{\ddt}{\frac{d}{dt}}
\renewcommand{\div}{\operatorname{div}}
\newcommand{\Laplace}{\Delta}
\newcommand{\kinet}{\bracket{\del_t + v\cdot \grad_x}}
\newcommand{\bessel}{\paren{1-\Laplace_v}}
\newcommand{\loc}{\text{loc}}
\newcommand{\Lip}{\text{Lip}}
%\newcommand{\BMO}{\text{BMO}}
\newcommand{\ddz}{\frac{d}{dz}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\into}{\hookrightarrow}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\isom}{\cong}
\newcommand{\rest}{{\upharpoonright}}
\newcommand{\weakly}{\rightharpoonup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ith}{^\mathrm{th}}
\newcommand{\n}{^{-1}}
\newcommand{\half}{\frac{1}{2}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\indic}[1]{\chi_{\{#1\}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\eigen}[1]{\eta_{#1}} %my eigenfunctions
\newcommand{\Ctest}{C_c^\infty}
\newcommand{\test}{\mathcal{D}}

\newcommand{\ulow}{u_l}
\newcommand{\uhigh}{u_h}
\newcommand{\ulowth}[1]{\ulow^{#1}}
\newcommand{\uhighth}[1]{\uhigh^{#1}}
\newcommand{\umidth}[1]{u_m^{#1}}

\newcommand{\HD}[2]{\int \abs{\Lambda^{#1} #2}^2}
\newcommand{\HDh}[1]{\HD{1/2}{#1}}

\newcommand{\Rom}[1]{\MakeUppercase{\romannumeral #1}}

\newcounter{step_count}[section]
\newcommand{\step}[1]{\stepcounter{step_count} \smallskip \noindent{\textbf{Step \arabic{step_count}:} #1}}


%-------------------------------------------</commands>--------------------------------------------------------

%\newcommand{\draftnum}{1}%-----------------------------UPDATE DRAFT NUM----------------------------------------

\title{SQG Boundary, \today}

\author[Stokols]{Logan F. Stokols} 
\address[L. F. Stokols]{\newline Department of Mathematics, \newline The University of Texas at Austin, Austin, TX 78712, USA}
\email{lstokols@math.utexas.edu}

\author[Vasseur]{Alexis F. Vasseur}
\address[A. F. Vasseur]{\newline Department of Mathematics, \newline The University of Texas at Austin, Austin, TX 78712, USA}
\email{vasseur@math.utexas.edu}

\date{\today}

%\subjclass[2010]{35H10,35B65,47G20,35Q84} % hypoellptic, regularity, integro-differential, fokker-planck
%\keywords{Fokker-Planck Equation, Fractional Laplacian, H\"older regularity,  De Giorgi method}

%\thanks{\textbf{Acknowledgment.} This work was partially supported by the NSF Grant DMS 1614918. }

\begin{document}




\maketitle \centerline{\date}

\tableofcontents

We're gonna consider the equation 
\begin{align} \label{eq:main nonlinear}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0 \qquad (0,T) \times \Omega,
\\ u = \grad^\perp \Lambda\n \theta \qquad [0,T] \times \Omega,
\\ \theta = \theta_0 \qquad \{0\} \times \Omega
\end{align}
on an open domain $\Omega \subseteq \R^2$ and a time interval $[0,T]$, with given initial data $\theta_0$.  

Here the operator 
\[ \Lambda := \sqrt{-\Laplace_D} \]
is the square root of $-\Laplace_D$, the Laplacian on $\Omega$ with Dirichlet boundary condition.  More specifically, if $(\eigen{k})_{k \in \Z}$ is a family of eigenfunctions of $-\Laplace_D$ with corresponding eigenvalues $\lambda_k$, then
\[ \Lambda f := \sum_{k=0}^\infty \sqrt{\lambda_k} \chevron{f,\eigen{k}}_{L^2(\Omega)} \eigen{k}. \]

Our main result will be to show that $\theta$ is H\"{o}lder continuous.  

\begin{theorem} \label{thm:main continuity}
Let $\theta_0 \in L^2(\Omega)$ and let $\Omega \subseteq \R^2$ be an open set and $T > 0$ a time.  Then there exist functions $\theta, u \in L^\infty(0,T; L^2(\Omega))$ which solve \eqref{eq:main nonlinear}.  Moreover, for any $t \in (0,T)$, $\theta$ is H\"{o}lder continuous uniformly on $(t,T)\times\Omega$.  

In fact, for some $\alpha \in (0,1)$ depending only on $\Omega$ and some constant $C$ depending only on $\Omega$, $T$, and $t$
\[ \norm{\theta}_{C^\alpha((t,T)\times\Omega)} \leq C \norm{\theta_0}_{L^2(\Omega)}. \]
\end{theorem}

The existence of a weak solution (meaning solution in the sense of distributions) $\theta \in L^\infty(0,T; L^2(\Omega)) \cap L^2(0,T; H_D^{1/2}(\Omega))$ is proven in [citation, Constantin and Ignatova].  

The technique to prove this is, like in [citation, Caff \& Vasseur], to linearize the equation by forgetting the dependence of $u$ on $\theta$, and then prove a Harnack inequality for fractional diffusion equations with ``bounded'' drift.  Then we zoom in on the solution and apply the Harnack inequality again.  By iterating this process, we can show that $\theta$ is H\"{o}lder continuous.  

The difficulty is in finding a bound on $u$ which remains bounded no matter how much we zoom in.  Ideally this would simply be $L^\infty$ which is of course scaling invariant.  The problem is that the Riesz operator $\grad \Lambda^{-1}$ is not bounded from $L^\infty$ to $L^\infty$.  In [citation Caff \& Vasseur], Caffareli and Vasseur utilize the fact that the Riesz operator is bounded $L^\infty \to \BMO$.  The space of functions with Bounded Mean Oscillation is scaling invariant, and one can show the Harnack inequality with $\BMO$ drift using De Giorgi's method with a shifting refrence frame.  

In the case of bounded domains, it is not known that the Riesz operator is bounded $L^\infty \to \BMO$.  Another well known scaling invariant function space is the Besov space $B^0_{\infty,\infty}$, and this is closer to what we want.  

One complication is that, on bounded domains, we have no access to the Fourier transform.  However, an analogue involving the spectral decomposition of the Dirichlet Laplacian (where classical Littlewood-Paley theory involves the spectral decomposition of the Laplacian) has been developed by e.g. [citation, IMT] and [citation, Bui-Duong-Yan].  This theory is an outgrowth of the theory of Schrodinger Operators from mathematical physics.  We will continue to refer to this theory using the terminology of Littlewood-Paley, but it is a significant generalization.  

What's more, instead of considering the Littlewood-Paley projections of the Riesz transform of $\theta$, we will actually seek to control the Riesz transforms of the Littlewood-Paley projections of $\theta$.  Because the Dirichlet Laplacian is not translation invariant, the gradient is not a spectral operator and the Riesz transform does not commute with the Littlewood-Paley projection operators.  For this reason we cannot utilize the theory of Besov spaces, but the bounds on $u$ that we do utilize are computationally similar.  

Finally, because the gradient does not commute with the Dirichlet Laplacian, saying that $u$ is bounded in this way which is analogous to $B^0_{\infty,\infty}$ is not equivalent to saying that $\Lambda^{-1/4} u$ is bounded in a way analogous to the space $B^{1/4}_{\infty,\infty}$ or that $\grad u$ is bounded in a way analogous to $B^{-1}_{\infty,\infty}$.  Therefore we must bound $u$ in each sense indendently, though in the classical case all of these bounds would be identical.  

We make this notion precise with the following definition.  

\begin{definition}[Calibrated sequence]
We call a sequence $u_j$ \textbf{calibrated} for a constant $\kappa$ and a center $N$ if each term of the sequence satisfies the following bounds.  

\begin{align*}
\norm{u_j}_\infty &\leq \kappa, \\
\norm{\grad u_j}_\infty &\leq 2^{j} 2^{-N} \kappa, \\
\bracket{u_j}_{3/4} &\leq 2^{j \frac{3}{4}} 2^{- N \frac{3}{4}} \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq 2^{-j/4} 2^{N/4} \kappa.  
\end{align*} 

We call a function \textbf{calibrated} if it is the sum of a calibrated sequence, with the infinite sum converging in the sense of $L^2$.  

\end{definition}

In sections \ref{sec:littlewood paley} and \ref{sec:calibrated functions} we will show that $u$ is calibrated and that it remains calibrated at all scales.  Thereafter we will consider the linear equation
\begin{equation} \label{eq:main linear} \begin{cases}
\del_t \theta + u \cdot \grad \theta + \Lambda \theta = 0, \\
\div u = 0
\end{cases} \end{equation}
where $u$ is assumed to be calibrated.  In sections \ref{sec:de giorgi} and \ref{sec:harnack} we will show a Harnack inequality for solutions to \eqref{eq:main linear}.  

Recall the notation
\[ \bracket{f}_\alpha := \sup_{x,y \in \Omega, x \neq y} \frac{|f(x)-f(y)|}{|x-y|^\alpha}. \]

Throughout, we will use the notation $(x)_+ := \max(0,x)$.  When the parentheses are ommited, the subscript $+$ is merely a label.  

\newcommand{\shape}[1]{\text{Shp}(#1)}

If a constant depends on ``the shape of $\Omega$'' we mean that the constant depends on $\shape{\Omega} = \{S: \eps \in \R^+, S = \eps \Omega \}$ the equivalence class of $\Omega$ up to scaling.  In other words, if we zoom in and double the size of $\Omega$, constant that depend on the shape of $\Omega$ will  not change.  


\section{Properties of $\Lambda$} \label{sec:lemmas}

\begin{lemma} \label{thm:disjoint}
If $f$ and $g$ are non-negative functions with disjoint support (i.e. $f(x)g(x) = 0$ for all $x$), then 
\[ \int \Lambda^s f \Lambda^s g \,dx \leq 0. \]
\end{lemma}

This proves, in particular, that $-\int \theta_+ \Lambda \theta_-$ is a positive term (hence dissipational and extraneous) and that $\int \Lambda^{1/2} (\theta-\psi) \Lambda^{1/2} (\theta-\psi)$ breaks down (bilinearly) into the doubly positive, the doubly negative, and the cross term, all of which are positive and hence each of which is bounded.  

\begin{proof}
Use the characterization from Caffarelli-Stinga.  There exist non-negative functions $K(x,y)$ and $B(x)$, depending on the parameter $s$, such that
\[ \int \Lambda^s f \Lambda^s g \,dx = \iint [f(x)-f(y)][g(x)-g(y)] K(x,y) \,dxdy + \int f(x) g(x) B(x) \,dx. \]

Since $f$ and $g$ are non-negative and disjoint, the $B$ term vanishes.  Moreover, the product inside the $K$ term becomes
\[ [f(x)-f(y)][g(x)-g(y)] = -f(x)g(y)-f(y)g(x) \leq 0. \]
Since $K$ is non-negative, the result follows.  
\end{proof}

\begin{lemma}
For all functions $f$ in $H_D^1$,
\[ \int \abs{\grad f}^2 = \int \abs{\Lambda f}^2. \]

Moreover, if $f \in H_D^1$ then $\trace(f)=0$.  
\end{lemma}

\begin{proof}
Let $\eigen{i}$ and $\eigen{j}$ be two eigenfunctions of the Dirichlet Laplacian on $\Omega$.  Note that these functions are smooth in the interior of $\Omega$.  Because $\Omega$ has Lipschitz boundary, and because $\eigen{i} \grad \eigen{j}$ is smooth on $\Omega$ and countinuous and bounded on $\overline{\Omega}$ vanishing on the boundary, therefore 
\[ \int_\Omega \div(\eigen{i} \grad \eigen{j}) = \int_{\del \Omega} \eigen{i} \grad \eigen{j}. \]
But $\eigen{i} \grad \eigen{j}$ vanishes on the boundary, so the right hand side vanishes.  Moreover, $\div(\eigen{i} \grad \eigen{j}) = \grad \eigen{i} \cdot \grad \eigen{j} + \eigen{i} \Laplace \eigen{j}$.  Therefore
\[ \int \grad \eigen{i} \cdot \grad \eigen{j} = - \int \eigen{i} \Laplace \eigen{j} = \lambda_j \int \eigen{i} \eigen{j} = \lambda_j \delta_{i=j}. \]
Of course, the inner product of two eigenfunctions is 0 unless they are the same eigenfunction, in which case it is 1.  

Consider a function $f = \sum f_k \eigen{k}$ which is an element of $H_D^1$, by which we mean $\sum \lambda_k f_k^2 < \infty$.  Since $\norm{\grad \eigen{k}}_{L^2(\Omega)} = \sqrt{\lambda_k}$, the following sums all converge in $L^2(\Omega)$ and hence the calculation is justified:
\begin{align*}
\int \abs{\grad f}^2 &= \int \paren{\sum_i f_i \grad \eigen{i} } \paren{\sum_j f_j \grad \eigen{j}}
\\ &= \int \sum_{i,j} (f_i f_j) \grad \eigen{i} \cdot \grad \eigen{j}
\\ &= \sum_{i,j} (f_i f_j) \int \grad \eigen{i} \cdot \grad \eigen{j}.
\end{align*}
Since this double-sum vanishes except on the diagonal, we see from [citation] that in fact
\[ \norm{\grad f}_{L^2(\Omega)} = \norm{\Lambda f}_{L^2(\Omega)}. \]

To see that $\trace(f)$ vanishes, note that $f = \sum_{k=0}^\infty f_k \eigen{k}$ and that each finite partial sum for this series satisfies the Dirichlet boundary condition.  Since $\trace$ is a bounded operator on $H^1$, we need only show that this series is Cauchy in $H^1$, in which case its $H^1$ limit will exist and be equal to $f$.  

For each $k$,
\[ \norm{ f_k \eigen{k} }_{H^1} \leq C_\textrm{Poincare} f_k \norm{\grad \eigen{k}}_2 = C f_k \sqrt{\lambda_k}. \]
This sequence is $\ell^2$ summable, since $f \in H_D^1$ by assumption.  Therefore $f$, being an $H^1$ limit of functions with vanishing trace, also has vanishing trace.  
\end{proof}

\begin{lemma} \label{thm:hadamard 3 lines}
For any function $f$, and any $0 < s < 1$,
\[ \int \abs{\Lambda^s f}^2 \gtrsim \int \abs{\paren{-\Laplace}^{s/2} \bar{f}}^2. \]
Here $\bar{f}$ is the extension of $f$ to $\R^2$ and $\paren{-\Laplace}^s$ is defined in the fourier sense.  
\end{lemma}

\begin{proof}
Let $g$ be any Schwarz function in $L^2(\R^2)$, and let $f$ be a function in $H^{s+1}_D$.  Let $E:H^1(\Omega) \to H^1(\R^2)$ be a bounded extension operator, where $H^1$ denotes the classical Sobolev space defined using the gradient.  Define the function
\[ \Phi(z) = \int_{\R^2} \paren{-\Laplace}^{z/2} g E \Lambda^{s-z} f. \]

When $\Re(z) = 0$, then $\norm{\paren{-\Laplace}^{z/2} g}_2 = \norm{g}_2$ and $\norm{\Lambda^{s-z} f}_2 = \norm{\Lambda^s f}_2$.  Hence
\[ \Phi(z) \leq \norm{g}_2 \norm{f}_{H^s_D}. \]

When $\Re(z)=1$, then $\norm{\paren{-\Laplace}^{(z-1)/2} g}_2 = \norm{g}_2$ and 
\[ \norm{\paren{-\Laplace}^{1/2} E\Lambda^{s-z} f}_{L^2(\R^2)} = \norm{\grad E \Lambda^{s-z} f}_{L^2(\R^2)} \leq \norm{E} \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)}. \]
It remains to ask whether $\Lambda^{s-z} f$ is in $H^1_D$ so that we can apply lemma [citation].  However, this is true based on our assumption $f \in H^{1+s}_D$, since the various powers of $\Lambda$ all commute and form a semigroup.  Ergo
\[ \norm{\grad \Lambda^{s-z} f}_{L^2(\Omega)} = \norm{\Lambda \Lambda^{s-z} f}_2 \leq \norm{\Lambda^s f}_2 \]
and we can bound
\[ \Phi(z) \leq \norm{E} \norm{g}_2 \norm{f}_{H^s_D}. \]

Now we will bound the derivative of $\Phi(z)$.  Specifically, compute the derivative in $z$ of the integrand, for $0<\Re(z)<1$, and hope that it is integrable.  To this end, we rewrite the integrand of $\Phi$ as
\[ \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k. \]
The derivative $\ddz$ commutes with linear operators like $\Four\n$ and $E$, so the derivative is
\[ \Four\n\paren{ \ln(|\xi|) |\xi|^z \hat{g} } E \sum_k \lambda_k^{\frac{s-z}{2}} f_k + \Four\n\paren{ |\xi|^z \hat{g} } E \sum_k \frac{-1}{2} \ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} f_k. \]

Since $0<\Re(z)<1$, $\ln(|\xi|)|\xi|$ is bounded as a multiplier operator from Schwarz functions to $L^2$.  Moreover, $\ln(\lambda_k) \lambda_k^{\frac{s-z}{2}} \leq C \lambda_k^{\frac{s-z+\eps}{2}}$ for some $C$ independent of $k$ but dependent on $z$, $\eps$.  Since $f \in H^{1+s}_D$ this sum converges in $L^2$, in fact in $H_D^1$.  This makes our differentiated integrand a sum of two $H^1$ functions with compact support multiplied by two Schwarz functions.  In particular it is integrable, which means we can interchange the integral sign and the derivative $\ddz$ and prove that $\Phi'(z)$ is finite for all $0<\Re(z)<1$. 

This is sufficient now to apply the Hadamard three-lines lemma to our function $\Phi$.  

It follows that for any Schwarz function $g \in L^2(\R^n)$ and $H_D^{s+1}$ function $f$, 
\[ \int_{\R^2} \paren{-\Laplace}^{s/2} g E f = \Phi(s) \leq \norm{g}_{L^2(\R^2)} \norm{f}_{H_D^s}. \]

Since Schwarz functions are dense in $L^2(\R^2)$, this means by density that 
\[ \int \abs{ \paren{-\Laplace}^{s/2} E f }^2 \leq \int \abs{\Lambda^s f}^2 \]
or in other words it means that $E$ is a bounded operator from $H_D^s$ to $H^s$, at least on the subset $H_D^{s+1} \cap H_D^s$.  It remains to extend this bound to the whole space by density.  

We know from [citation] Caffarelli and Stinga that $\test(\Omega)$ is dense in $H_D^s$ for all $0 \leq s < 1$.  In fact, this takes a bit of interpretation, so I ought to illucidate that this is because $H_D^s = H_0^s$ (the latter in the Slobodekij sense) for most $s$ and at $s=1/2$ we get the Lions-Magenes spaces which still has $\test(\Omega)$ dense.  

Surely, right(?), test functions are all inside of $H_D^{1+s}$.  I should meditate on this, but it must be true.  
\end{proof}

\begin{lemma}
Let $g:\Omega \to \R$ be a non-negative function on $\Omega$ a bounded Lipschitz domain such that, for some $s \in (0,2)$,
\[ \int \frac{|g(x)-g(y)|^2}{|x-y|^{2+s}} < \infty. \]

Then for any $f \in H_D^s(\Omega)$, the function $(f-g)_+ \in H_D^s(\Omega)$ as well.  
\end{lemma}

A similar result can be proven using the Cordoba-Cordoba pointwise inequality $\Lambda^s (f)_+ \leq \indic{f>0} \Lambda^s f$.  Normally, if we can assume regularity on $g$, we could apply this inequality to the function $f-g$ and obtain the result. Here, we do not assume that $g$ vanishes at the boundary, which means $f-g$ does not have finite $H_D^{1/2}$ norm.  In the proof below, such an assumption would show up in the $B$ term, which we bound instead using the alternative assumption that $g \geq 0$.  

\begin{proof}
Consider
\[ \HDh{(f-g)_+} = \iint [(f(x)-g(x))_+ - (f(y)-g(y))_+]^2 K + \int (f-g)_+^2 B. \]

Because $\max(0,\cdot)$ is a contraction on $\R$ and $g$ is non-negative, we can say that $\abs{(f-g)_+(x)-(f-g)_+(y)} \leq \abs{(f-g)(x)-(f-g)(y)}$ and also $0 \leq (f-g)_+ \leq f$.  

Looking at the integrand of the $K$ term, because $\max(0,\cdot)$ is a contraction on $\R$ we can bound
\[ [(f(x)-g(x))_+ - (f(y)-g(y))_+]^2 \leq [f(x)-g(x) - f(y) + g(y)]^2 \leq [f(x)-f(y)]^2 + [g(x)-g(y)]^2. \]

Thus
\[ \HDh{(f-g)_+} \leq \iint [f(x)-f(y)]^2 K + \iint [g(x)-g(y)]^2 K + \int f^2 B = \iint [g(x)-g(y)]^2 K + \HD{s}{f}. \]

%Since $g$ is continuous with two moduli of continuity,
%\[ |g(x)-g(x)| \leq C\paren{\norm{g}_\Lip + \bracket{g}_{\gamma} } |x-y| \wedge |x-y|^\gamma. \]
%Since $K(x,y) \leq C_{s} |x-y|^{-2-s}$,
%\[ \iint [g(x)-g(y)]^2 K \leq C\paren{\norm{g}_\Lip + \bracket{g}_{\gamma} }^2 \iint \frac{|x-y|^2 \wedge |x-y|^{2\gamma}}{|x-y|^{2+s}}. \]
\end{proof}

\begin{lemma} \label{thm:product rule}
Let $s \in (0,1)$.  If $g \in L^\infty \cap \Lip(\Omega)$ then
\[ \int \Lambda^s (fg) \Lambda^s h \leq \norm{g}_\infty \int \Lambda^s f \Lambda^s h \,dx + \norm{f}_1 \norm{h}_{H_D^s} \sup_x \int \frac{|g(x)-g(y)|^2}{|x-y|^{2+s}} \,dy. \]

Also
\[ \norm{fg}_{H_D^s} \leq \norm{g}_\infty \norm{f}_{H_D^s} + \norm{f}_\infty \norm{g}_{H_D^s}. \]

Also
\[ \norm{fg}_{H_D^s} \leq \norm{g}_\infty \norm{f}_{H_D^s} + \norm{f}_2 \sup_y \int \frac{|g(x)-g(y)|^2}{|x-y|^{2+2s}} \,dx. \]

In particular, 
\[  \norm{fg}_{H_D^s} \leq \norm{g}_\infty \norm{f}_{H_D^s} + \norm{f}_2 \paren{\norm{g}_\infty + \norm{g}_\Lip}. \]

I can prove any of these, if they are worth citing.  
\end{lemma}

\begin{proof}
\[ \int |\Lambda^s (fg)|^2 = \iint \paren{g(x)[f(x)-f(y)] + f(y)[g(x)-g(x)]}^2 K + \int f^2 g^2 B \]
\[ \leq \norm{g}_\infty^2 \norm{f}_{H_D^s}^2 + \int f(y)^2 \int \frac{|g(x)-g(y)|^2}{|x-y|^{2+2s}}. \]
\end{proof}

\begin{lemma} \label{thm:L1 of Lambda bounded}
Let $g$ an $L^\infty$ function and $f \in H^{2s}$ be non-negative with compact support.  Then
\[ \int \Lambda^s g \Lambda^s f \leq C \norm{g}_\infty |\supp(f)|^{1/2} \paren{ \norm{f}_2 + \norm{f}_{H_D^{2s}}}. \]
\end{lemma}

\begin{proof}
Break up the integral according to the Caff \& Stinga decomposition [cite]
\[ \int \Lambda^s g \Lambda^s f = \Rom{1} + \Rom{2} \]
where
\begin{align*} 
\Rom{1} &:= \iint [g(x)-g(y)][f(x)-f(y)] K_s, \\
\Rom{2} &:= \int f g B_s. 
\end{align*}

We know from [citation, Caff \& Stinga] that for any $\Omega$
\begin{equation} \label{K bounded between orders} K_s(x,y) \leq C |x-y|^s K_{2s}(x,y). \end{equation}
Ostencibly this constant $C$ depends on $s$ and $\Omega$.  However, because both sides of the inequality scale the same way, this constant must depend only on the shape of Omega.  

From \eqref{K bounded between orders} and the fact that $[f(x)-f(y)]$ vanishes unless at least one of $f(x)$ or $f(y)$ is non-zero,
\[ \abs{\Rom{1}} \leq 2 \iint \indic{f \neq 0}(x) [g(x)-g(y)] [f(x)-f(y)] |x-y|^s K_{2s}. \]
The term $|x-y|^2$ can be rewritten $[1 \wedge |x-y|^s] [1 \vee |x-y|^s]$ so we can break this up by Holder's inequality
\[ \Rom{1} \leq C \paren{\iint \indic{f \neq 0}(x) [g(x)-g(y)]^2 (1 \wedge |x-y|^{2s}) K_{2s} }^{1/2} \paren{\iint [f(x)-f(y)]^2 (1 \vee |x-y|^{2s}) K_{2s} }^{1/2}. \]
The kernel $(1 \wedge |x-y|^{2s}) K_{2s}$ is integrable in $y$ for $x$ fixed, and $(1 \vee |x-y|^{2s}) K_{2s}$ is $K_{2s}$ plus a function which is integrable in $y$ for $x$ fixed.  Therefore
\begin{equation} \label{K of L1 less than L2 stuff} \Rom{1} \leq C \paren{ 2\norm{g}_\infty^2 \int C \indic{f\neq 0}(x) \,dx }^{1/2} \paren{ \norm{f}_{H^{2s}_D}^2 + C \int f(x)^2 \,dx + C \int f(y)^2 \,dy}^{1/2}. \end{equation}

For the boundary term \Rom{2}, 
\[ \Rom{2} \leq \norm{g}_\infty \int\indic{f\neq 0} f B. \]
Since $f \geq 0$, $[f(x)-f(y)][\indic{f \neq 0}(x) - \indic{f \neq 0}(y)] \geq 0$.  Therefore
\[ \int \indic{f \neq 0} f B \leq \int \Lambda^s \indic{f \neq 0} \Lambda^s f = \int \indic{f\neq 0} \Lambda^{2s} f. \]
Applying H\"{o}lder's inequality, we arrive at
\[ \Rom{2} \leq \norm{g}_\infty |\supp(f)|^{1/2} \norm{f}_{H_D^{2s}}. \]
This combined with \eqref{K of L1 less than L2 stuff} proves the lemma.  
\end{proof}

\begin{lemma} \label{thm:weak product rule}
For two functions $f \geq 0$ with compact support and $g \in L^\infty \cap \Lip$, their product is bounded
\[ \norm{\Lambda^{1/4} fg}_{L^1(\Omega)} \leq C \paren{\norm{g}_\infty + \norm{\grad g}_\infty} \paren{\norm{f}_1 + |\supp(f)|^{1/2} \paren{ \norm{f}_{L^2} + \norm{f}_{H_D^{1/2}}}}. \]
The constant $C$ depends on $\Omega$, but is independent of scaling.  

Logan: you don't actually prove $L^1$ because you don't know the quantity is a function.  As proven, it could contain a dirac or a Banach limit. 
\end{lemma}

\begin{proof}
Consider some $L^\infty$ test function $h$.  To determine the $L^1$ norm of $\Lambda^{1/4} fg$ we consider the integral
\[ \int h \Lambda^{1/4} (fg) = \iint [h(x)-h(y)][f(x)g(x) - f(y)g(y)] K_{1/4} \,dxdy + \int hfg B_{1/4} \,dx. \]

By the result of a lemma I wrote,
\[ \uparrow \leq \norm{h}_\infty |\supp(f)|^{1/2} \paren{\norm{fg}_2 + \norm{fg}_{H_D^{1/2}} }. \]

By the other lemma,
\[ \norm{fg}_{H_D^{1/2}} \leq \norm{g}_\infty \norm{f}_{H_D^{1/2}} + \norm{f}_2 \sup_x \int \frac{|g(x)-g(y)|^2}{|x-y|^3} \,dy. \]

But $|g(x)-g(y)|^2 \leq (\norm{g}_\infty + \norm{g}_\Lip) (1 \wedge |x-y|^2)$.  The result follows.  
\end{proof}

%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{Littlewood-Paley Theory} \label{sec:littlewood paley}

Logan: The japanese paper's Lemma 3.6, used extensively here, only applies in the case $j \geq 0$. Obviously I need it and use it for $j > j_0$.  This is equivalent, I can see from the proof, but maybe mention the issue somewhere so it doesn't seem like I didn't notice.  

In this section we will prove that $u$ breaks up into pieces with various norms under control.  

We know that $\theta \in L^\infty$.  Let $\phi$ be a Schwartz function on $\R$ which is suited to Littlewood-Paley decomposition.  That is, for example, $\phi(2^j x) \phi(2^i x) = 0$ unless $|i-j|\leq 1$ and $\sum \phi(2^j) = 1$.  We have some projections 
\[ P_j f := \sum_k \phi(2^j \lambda_k^{1/2}) f_k \eigen{k}. \]

Recall that $P_j = 0$ for $j$ sufficiently small, because $-\Laplace_D$ has a smallest eigenvalue.  

For each $j \in \Z$, I'll define
\[ u_j := \grad^\perp \Lambda^{-1} P_j \theta. \]
Qualitatively, we know that $\theta \in L^2$ and hence $u_j \in L^2$.  In fact, $u = \sum u_j$ in the $L^2$ sense.  

Firstly, we know by [citation] Fornare, Metafune and Priola that if $\Omega$ is $C^{2,\alpha}$ then
\[ \norm{\grad e^{-t\Laplace_D}}_{L^\infty \to L^\infty} \leq \frac{C}{\sqrt{t}} \qquad 0 < t \leq 1. \]
According to [citation] Iwabuchi, Matsuyama, and Taniguchi's paper Bilinear Estimates, Lemma 3.6, this is enough to show that
\[ \norm{u_j}_\infty \leq C \norm{\theta}_\infty. \]

We'll need a lemma now,
\begin{lemma} \label{thm:grad and proj}
For any function $f$,
\[ \norm{P_i \grad P_j f}_\infty \leq C \min(2^j,2^i) \norm{f}_\infty. \]
\end{lemma}
\begin{proof}
Let $g$ be an $L^1$ function.  Then
\[ \int g P_i \grad P_j f = \int (P_i g) \grad P_j f \leq C 2^j \norm{g}_1 \norm{f}_\infty \]
from [citation] IMT-Bilinear, Lemma 3.6 and Proposition 3.3 (which is also IMT Boundedness of Spectral Multiplies for Schrodinger Operators on Open Sets, Theorem 1.1).  

Further integrating by parts,
\[ \int g P_i \grad P_j f = - \int (\grad P_i g) P_j f \leq C 2^i \norm{g}_1 \norm{f}_\infty. \]
This follows from the same theorems as above.  

The result follows.  
\end{proof}

Since $u_j \in L^2$, we know that
\[ \Lambda^{-1/4} u_j = \sum_{i \in \Z} P_i \Lambda^{-1/4} u_j. \]
Define $\bar{P}_j$ a projection which is 1 on the support of $P_j$ (functional calculus-wise).  Then $\bar{P}_j P_j = P_j$, and since both types of projections are spectral operators, they both commute with $\Lambda^s$.  We therefore rewrite
\[ \paren{P_i \Lambda^{-1/4} u_j}^\perp = \paren{\Lambda^{-1/4} \bar{P}_i} P_i \grad P_j \paren{\Lambda^{-1} \bar{P}_j} \theta. \]
We apply sequentially three bounded operators on $L^\infty$.  The outer two operators have bounded norm by [citation] IMT-Bilinear Proposition 3.3, and the inner operator has bounded norm by Lemma \ref{thm:grad and proj}, (and of course the perp operator is an isometry,) so 
\[ \norm{ P_i \Lambda^{-1/4} u_j}_\infty \leq C 2^{-i/4} \min(2^j, 2^i) 2^{-j} \norm{\theta}_\infty. \]
%
% so from [citation] IMT-Bilinear Proposition 3.3 we can see that
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty = \norm{\Lambda^{-1/4} \bar{P}_i P_i u_j}_\infty \leq C 2^{-i/4} \norm{P_i u_j}_\infty \]
%and also
%\[ P_i u_j = P_i \grad P_j \Lambda^{-1} \bar{P}_j \theta. \]
%Thus by the lemma,
%\[ \norm{\Lambda^{-1/4} P_i u_j}_\infty \leq C 2^{-i/4} \min(2^j,2^i) \norm{\Lambda^{-1} \bar{P}_j \theta}_\infty \leq C 2^{-j} 2^{-i/4} \min(2^j,2^i) \norm{\theta}_\infty. \]
Summing these bounds on the projections of $\Lambda^{-1/4} u_j$, and noting that
\[ \sum_{i \in \Z} 2^{-j} 2^{-i/4} \min(2^j,2^i) = 2^{-j} \sum_{i \leq j} 2^{i 3/4} + \sum_{i>j} 2^{-i/4} \leq C 2^{-j/4}, \]
we obtain
\[ \norm{\Lambda^{-1/4} u_j}_\infty \leq C 2^{-j/4} \norm{\theta}_\infty. \]

Lastly, we'll show that $\grad u_j$ is in $L^\infty$.  Equivalently, we'll show that $\Lambda^{-1} P_j \theta$ is $C^{1,1}$.  This is essentially Schauder theory.  We will obtain our $C^{1,1}$ bound by interpolating between a $C^{0,1}$ bound and a $C^{2,\alpha}$ bound.  We could also obtain a $C^{1,\alpha}$ bound directly using the main theorem of [citation] Caffarelli-Stinga, but those estimates are not well-articulated in the specific context of our problem (namely, it's hard to make good use of the fact that $f$ near the boundary).  So instead, we use interpolation.  

The $C^{0,1}$ bound is already known, it's the estimate
\[ \norm{\grad \Lambda^{-1} P_j \theta}_\infty \leq C \norm{\theta}_\infty. \]
The $C^{2,\alpha}$ bound is classical Schauder theory.  For convenience, define 
\[ F := \Lambda^{-1} P_j \theta \]
and recall that $F$ is a finite linear combination of Dirichlet eigenfunctions, so in particular it is smooth and vanishes at the boundary.  Moreover, its Laplacian is 
\[ f := \Laplace F = \Lambda P_j \theta \]
which is also smooth, vanishes at the boundary, and has various bounds.  Specifically, we want to apply Theorem 6.6 from [citation] Gilbarg and Trudinger, page 98 in my library copy.  It says that since $\Omega$ is $C^{2,\alpha}$ and $F \in C^{2,\alpha}(\bar{\Omega})$, and since $f \in C^\alpha(\bar{\Omega})$, and since the boundary conditions are homogeneous (hence smooth), then
\[ \sup_{x,y \in \Omega} \frac{\abs{D^2 F(x)- D^2 F(y)}}{|x-y|^\alpha} \leq C \norm{F}_\infty + C \norm{f}_\infty + C \sup_{x,y\in\Omega} \frac{\abs{f(x)-f(y)}}{|x-y|^\alpha}. \]

A lemma with two interpolations:
\begin{lemma} \label{thm:Holder interpolation}
If $f \in L^\infty(\Omega) \cap C^{0,1}(\Omega)$ then for some universal constant $C$,
\[ \bracket{f}_\alpha \leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha. \]

If $f \in C^{0,1}(\Omega) \cap C^{2,\alpha}(\Omega)$ where $\Omega$ satisfies the cone condition, then for some constants $C$ and $\ell$ depending on $\Omega$,
\[ \norm{D^2 f}_\infty \leq C \delta\n \norm{\grad f}_\infty  + \delta^\alpha \bracket{D^2 f}_\alpha\]
for all $\delta < \ell$.  
\end{lemma}
\begin{proof}
The first claim is incredibly straigtforward.  We include it for completeness.  
\begin{align*} 
\sup_{x,y \in \Omega} \frac{|f(x)-f(y)|}{|x-y|^\alpha} &= \sup |f(x)-f(y)|^{1-\alpha} \paren{\frac{|f(x)-f(y)|}{|x-y|}}^\alpha 
\\ &\leq \paren{2 \norm{f}_\infty}^{1-\alpha} \paren{ \sup \frac{|f(x)-f(y)|}{|x-y|} }^\alpha
\\ &\leq C \norm{f}_\infty^{1-\alpha} \norm{\grad f}_\infty^\alpha.
\end{align*}

The second claim is more complicated.  We'll prove the sufficient claim that for $f$ smooth,
\[ \norm{\grad f}_\infty \leq C \delta\n \norm{f}_{L^\infty(\bar{\Omega})} + \delta^\alpha \bracket{\grad f}_{\alpha;\bar{\Omega}}.\]
Since $\Omega$ satisfies the cone condition, we know that there exist positive constants $\ell$ and $a<1$ such that, at each point $x \in \bar{\Omega}$, there exist two unit vectors $e_1$ and $e_2$ such that $|e_1\cdot e_2| \leq a$ and $x + \tau e_i \in \Omega$ for $i=1,2$, $0 < \tau \leq \ell$.  In other words, $\Omega$ contains rays at each point that extend for length $\ell$, end at $x$, and are non-parallel with angle at least $\cos\n(a)$.  

The idea of the proof is that the average of $\grad f$ along an interval is bounded since $f$ is bounded, and the same average is close to the value of $\grad f$ at a point because $\grad f$ is continuous, hence the value of $\grad f$ at any point must be bounded.  By varying the length $\delta$ of the aforementioned interval, we actually get a parameterized family of bounds.  

If we consider the directional derivative $\del_i f$ of $f$ along the direction $e_i$, then observe that for any $0 < \delta \leq \ell$,
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau = f(x+\delta e_i) - f(x). \]
This quantity on the right is bounded by the $L^\infty$ norm of $f$.  

On the other hand, since $\grad f$ and hence $\del_i f$ are continous functions, for any $\tau \in (0,\ell]$
\[ \abs{\del_i f(x) - \del_i f(x+\tau e_i)} \leq \bracket{\grad f}_\alpha \tau^\alpha. \]
From this bound, we obtain that
\[ \int_0^\delta \del_i f(x + \tau e_i) \,d\tau \leq \int_0^\delta \del_i f(x) + \bracket{\grad f}_\alpha \tau^\alpha \,d\tau = \delta \del_i f(x) + \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha} \]
and a similar bound holds from below, so
\[ \abs{ \delta \del_i f(x) - \int_0^\delta \del_i f(x + \tau e_i) \,d\tau} \leq \bracket{\grad f}_\alpha \frac{\delta^{1+\alpha}}{1+\alpha}. \]

What we have shown is that the integral of $\del_i f$ over an interval of length $\delta$ is small, and also it differs not very much from $\delta \del_i f(x)$.  By rearranging, we find that $\del_i f(x)$ must therefore be small:
\[ \abs{\del_i f(x)} \leq \frac{2}{\delta} \norm{f}_\infty + \frac{\delta^\alpha}{1+\alpha} \bracket{\grad f}_\alpha. \]
This is true independent of $x$ and of $i=1,2$.  Since $e_1 \cdot e_2 \leq a$ by assumption, by a little linear algebra we can bound $\grad f$ in terms of the $\del_i f$ and obtain that, for all $\delta \in (0,\ell]$,
\[ \norm{\grad f}_\infty \leq \frac{C}{1-a^2} \paren{ \delta\n \norm{f}_\infty + \delta^\alpha \bracket{\grad f}_\alpha }. \]

\end{proof}

Let's bound the terms of the Gilbarg-Trudinger inequality.  By [citation] IMT-Bilinear Proposition 3.3
\[ \norm{f}_\infty = \norm{\Lambda P_j \theta}_\infty \leq C 2^j \norm{\theta}_\infty \]
while by [citation] IMT-Bilinear Lemma 3.6
\[ \norm{\grad f}_\infty = \norm{\grad \Lambda P_j \theta}_\infty \leq C 2^{2j} \norm{\theta}_\infty. \]
Therefore we can interpolate
\[ \bracket{f}_\alpha \leq C 2^{j(1+\alpha)} \norm{\theta}_\infty. \]
And of course, by [citation] IMT-Bilinear Proposition 3.3
\[ \norm{F}_\infty = \norm{\Lambda^{-1} P_j \theta}_\infty \leq C 2^{-j} \norm{\theta}_\infty. \]

Combining these estimates with [citation: the Gilbarg-Trudinger thingy] we find
\[ \bracket{D^2 F}_\alpha \leq C \paren{2^{-j} + 2^j + 2^{j(1+\alpha)}} \norm{\theta}_\infty. \]

At long last, the big estimate,
\[ \norm{D^2 F}_\infty \leq C \paren{\delta\n \norm{\grad F}_\infty + \delta^{\alpha} \bracket{D^2 F}_\alpha}. \]

Since $\Omega$ is bounded, there exists a $j_0$ such that $P_j = 0$ if $j < j_0$.  Therefore we assume withouth loss of generality that $j \geq j_0$.  Thus $2^{-j} \leq 2^{j(1+\alpha)} 2^{-j(2+\alpha)} \leq 2^{j(1+\alpha)} 2^{-j_0(2+\alpha)}$ and similarly $2^j \leq 2^{j(1+\alpha)}2^{-j\alpha} \leq 2^{j(1+\alpha)} 2^{-j_0\alpha}$.  We can therefore say that for all $\delta \leq \ell$,
\[ \bracket{D^2 F}_\infty \leq C \paren{\delta\n C + \delta^\alpha 2^{j(1+\alpha)}} \norm{\theta}_\infty. \]

Set $\delta = 2^{-j} 2^{j_0} \ell \leq \ell$.  Then
\[ \bracket{D^2 F}_\infty \leq C \paren{C 2^j + 2^{-j\alpha} 2^{j(1+\alpha)}} \norm{\theta} = C(\Omega) 2^j \norm{\theta}. \]
But $D^2 F = \grad u_j$ so we are done.  


%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{Properties of Calibrated Functions} \label{sec:calibrated functions}
We've shown that our drift term $u$ is a sum of $u_j$ for $j \in \Z$, $j \geq j_0$.  (Equivalently, $u$ is a sum of $u_j$ for $j \in \Z$ and $u_j = 0$ for $j < j_0$.)  Each $u_j$ is an $L^\infty$ function, and their sum converges in $L^2$ to $u$.  Each $u_j$ satisfies a collection of bounds which are exponential in $j$.  

In this section, we will first show that these terms sum to two functions $\ulow$ and $\uhigh$ with appropriate bounds.  Then we will show that these bounds remain true as we zoom in space and time.  

We begin by stating what we mean by ``appropriate'' bounds on the $u_j$.  
\begin{definition}[Calibrated sequence]
We call a sequence $u_j$ \textbf{calibrated} for a constant $\kappa$ and a center $N$ if each term of the sequence satisfies the following bounds.  

\begin{align*}
\norm{u_j}_\infty &\leq \kappa, \\
\norm{\grad u_j}_\infty &\leq 2^{j} 2^{-N} \kappa, \\
\bracket{u_j}_{3/4} &\leq 2^{j \frac{3}{4}} 2^{- N \frac{3}{4}} \kappa, \\
\norm{\Lambda^{-1/4} u_j}_\infty &\leq 2^{-j/4} 2^{N/4} \kappa.  
\end{align*} 

\end{definition}

The most important property of a calibrated sequence is that its sum decomposes into two functions, which we call the high-pass term and the low-pass term.  

\begin{proposition} \label{thm:calibration is good}
Let 
\[ u = \sum_{j_0}^\infty u_j \]
with the sum converging the the $L^2$ sense.  Assume that $(u_j)_{j \in \Z}$ is a calibrated sequence with constant $\kappa$ and some center.  

Then there exist some universal constants $C_i$ such that
\[ u = \ulow + \uhigh \]
with 
\[ \norm{\ulow}_{\Lip} \leq C_1 \kappa\]
and
\[ \bracket{\ulow}_{3/4} \leq C_2 \kappa \]
and
\[ \norm{\Lambda^{-1/4} \uhigh}_\infty \leq C_3 \kappa. \]
\end{proposition}

\begin{proof}
Let $N$ be the center to which $(u_j)_{j \in \Z}$ is calibrated.  

We define
\[ \uhigh = \sum_{j > N} u_j \]
and 
\[ \ulow = \sum_{j \leq N} u_j. \]

Since $u_j \in L^\infty$ in particular they are $L^2$ functions which sum in $L^2$.  Remember that only finitely many negative $j$ have $u_j \neq 0$.  The sequence $u_j$ is thus singly infinite and in particular is a Cauchy sequence, so $\uhigh$ also converges in $L^2$.  Since $\Lambda^{-1/4}$ is a continuous linear operator, it passes to the partial sums and so
\[ \Lambda^{-1/4} \uhigh = \lim_{L^2} \sum_{j>N} \Lambda^{-1/4} u_j. \]
In particular, the sum converges in the sense of distributions, i.e. in $\test(\Omega)'$.  Since test functions are dense in $L^1(\Omega)$, and the partial sums are uniformly bounded in the dual of $L^1(\Omega)$ (namely $L^\infty(\Omega)$), therefore the limit $\Lambda^{-1/4} \uhigh$ is also bounded in the dual of $L^1(\Omega)$.  
\[ \norm{\Lambda^{-1/4} \uhigh}_\infty \leq \sum_{j>N} \norm{\Lambda^{-1/4} u_j}_\infty \leq \kappa \frac{2^{-1/4}}{1-2^{-1/4}}. \]

As for $\ulow$, we have that $\sum_{j \leq N} u_j$ is a finite sum of Lipschitz and H\"{o}lder continuous functions.  We can simply bound
\[ \norm{\grad \ulow}_\infty \leq \sum_{j \leq N} \norm{\grad u_j}_\infty \leq \kappa \frac{1}{1 - 2^{-1}} \]
and
\[ \bracket{\ulow}_{3/4} \leq \sum_{j \leq N} \bracket{u_j}_{3/4} \leq \kappa \frac{1}{1 - 2^{-3/4}}. \]
\end{proof}

We showed in section \ref{sec:littlewood paley} that $u$ is a sum of a calibrated sequence, and now we have shown that the sum of a calibrated sequence is actually a finite sum of functions that are bounded in certain function spaces.  Any bound we place on $u$ directly will blow up as we zoom in, but a calibrated sequence remains calibrated (with increasing center).  In the next lemma, we show that, thanks to this notion of calibration, our PDE is scale-invariant.  

\begin{lemma}[Scaling] \label{thm:scaling}
Suppose that $\theta$ and $u$ solve the PDE
\[ \bracket{\del_t + u\cdot\grad + \Lambda} \theta = 0,\]
\[ \div u = 0, \]
where the velocity $u$ satisfies
\[ u = \sum_{j=j_0}^\infty u_j \]
with that sum converging in $L^2(\Omega)$ and $(u_j)_j$ calibrated with constant $\kappa$ and center $N$.  Suppose that the domain of definition is $(-T,0) \times \Omega$.  

Let $\eps>0$ be a small constant. 

Then
\[ \bar{\theta}(t,x) := \theta(\eps t, \eps x) \]
and
\[ \bar{u}(t,x) := \sum_{j=j_0}^\infty u_j(\eps t, \eps x) \]
satisfies the same PDE for $(t,x) \in [-T/\eps, 0]\times \Omega_\eps$.  

Moreover, $(u_j)_j$ is calibrated with the same constant $\kappa$ and center $N - \ln_2(\eps)$.  

%\[ \norm{\sum_{j=-\infty}^0 \bar{u}_j(t,0) - \sum_{j=-\infty}^0 u_j(\eps t, 0)}_\infty \leq \kappa N. \]
\end{lemma}

\begin{proof}
We calculate
\[ \del_t \bar{\theta}(p) = \eps \del_t \theta(\bar{p}) \]
and 
\[ \grad \bar{\theta}(p) = \eps \grad \theta(\bar{p}) \]
and
\[ \Lambda \bar{\theta}(p) = \eps \Lambda \theta(\bar{p}). \]

\& cetera...

It remains to show that $(u_j(eps\,\cdot, \eps\,\cdot))_j$ is still calibrated.  Define
\[ \bar{u}_j(t,x) := u_j(\eps t, \eps x). \]

Then
\[ \norm{\bar{u}_j}_\infty = \norm{u_j}_\infty \leq \kappa \]
and
\[ \norm{\grad \bar{u}_j}_\infty = \eps \norm{\grad u_j}_\infty \leq 2^{\ln_2(\eps)} 2^j 2^{-N} \kappa = 2^j 2^{-(N-\ln_2(\eps))} \kappa. \]

The entire thing is so straightforward I literally can't bring myself to type out the rest.  

\end{proof}


%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{De Giorgi Estimates} \label{sec:de giorgi}

First let us derive an energy inequality.  

\begin{lemma}[Caccioppoli Estimate] \label{thm:caccioppoli}
Let $\theta \in L^2(0,T; H_D^{1/2}(\Omega))$ and $u \in L^\infty(0,T; L^2(\Omega))$ solve \eqref{eq:main linear} in the sense of distributions.  Let $\psi: [-T,0]\times \Omega \to \R$ be non-negative, Lipschitz-in-space, and H\"{o}lder continuous-in-space with exponent $\gamma < 1/2$.  Then the decomposition
\[ \theta = \theta_+ + \psi - \theta_- \]
satisfies the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 - \chevron{\theta_+,\theta_-}_{1/2} \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (\del_t \psi + u\cdot\grad\psi) } \]
with the constant $C$ depending on $\norm{\grad \psi}_\infty$ and $\sup_t \bracket{\psi(t,\cdot)}_\gamma$.  

\end{lemma}

\begin{proof}
From Lemma \ref{thm:cutoff in sobolev}, we know that $\theta_+$ is in $H_D^{1/2}(\Omega)$ for a.e. $t \in [0,T]$.  We can therefore multiply our equation [cite] by $\theta_+$ and integrate in space to obtain
\[ 0 = \int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \paren{\theta_+ + \psi - \theta_-} \]
which decomposes into three terms, corresponding to $\theta_+$, $\psi$, and $\theta_-$.  We analyze them one at a time.  

Firstly,
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_+ &= (1/2) \ddt \int \theta_+^2 + (1/2) \int \div u \, \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2
\\ &= (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2.
\end{align*}

The $\psi$ term produces important error terms:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \psi &= \int \theta_+ \del_t \psi + \int \theta_+ u \cdot \grad \psi + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\\ &= \int \theta_+ (\del_t \psi + u \cdot \grad \psi) + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi
\end{align*}

Since $\theta_+$ and $\theta_-$ have disjoint support, the $\theta_-$ term is nonnegative by Lemma \ref{thm:disjoint}:
\begin{align*} 
\int \theta_+ \bracket{ \del_t + u \cdot \grad + \Lambda } \theta_- &= (1/2) \int \theta_+ \del_t \theta_- + \int \theta_+ u \cdot \grad \theta_- + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_-
\\ &= \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_- \leq 0.
\end{align*}

Put together, we arrive at 
\[ (1/2) \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 - \int \Lambda^{1/2}\theta_+ \Lambda^{1/2} \theta_- + \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \leq \abs{\int \theta_+ (\del_t \psi + u \cdot \grad \psi) \cdot \grad \psi}. \]

At this point we break down the $\Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi$ term using the formula from [citation] Caffarelli-Stinga.  
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi = \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) + \int \theta_+ \psi B. \]
Since $B \geq 0$ (see Caff-Stinga [citation]) and $\psi$ is non-negative by assumption, the $B$ term is non-negative and so
\[ \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \psi \geq \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y). \]
The remaining integral is symmetric in $x$ and $y$, and the integrand is only nonzero if at least one of $\theta_+(x)$ and $\theta_+(y)$ is nonzero.  Hence
\[ \iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y) \leq 2 \iint \indic{\theta_+>0}(x) \abs{[\theta_+(x)-\theta_+(y)][\psi_t(x)-\psi_t(y)]} K(x,y). \]
Now we can break up this integral using the Peter-Paul variant of H\"{o}lder's inequality.  
\[ \abs{\iint [\theta_+(x)-\theta_+(y)][\psi(x)-\psi(y)] K(x,y)} \leq \eps \int \abs{\Lambda^{1/2}\theta_+}^2 + \frac{1}{\eps} \iint \indic{\theta_+>0}(x) [\psi(x)-\psi(y)]^2 K(x,y). \]

It remains to bound the quantity $[\psi(x)-\psi(y)]^2 K(x,y)$.  By Caffarelli-Stinga theorem 2.4 [citation], there is a universal constant $C$ such that
\[ K(x,y) \leq \frac{C}{|x-y|^{3}}. \]
The cutoff $\psi$ is Lipschitz, and H\"{o}lder continuous with exponent $\gamma < 1/2$ by assumption.  Therefore 
\[ [\psi(x)-\psi(y)]^2 K(x,y) \leq |x-y|^{-1} \wedge |x-y|^{2\gamma-3}. \]
Since $3-2\gamma > 2$, this quantity is integrable.  Thus
\[ \int \indic{\theta_+>0}(x) \int [\psi(x)-\psi(y)]^2 K(x,y) \,dxdy \leq C(\norm{\psi}_\textrm{Lip}, \bracket{\psi}_\gamma) \int \indic{\theta_+>0} \,dx. \]
Combining [citation, like 4 different things are combined] we arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 - \chevron{\theta_+,\theta_-}_{1/2} \lesssim \int \theta_+ (\del_t\psi+u\cdot\grad\psi) + \int \indic{\theta_+>0}.\]
\end{proof}

This is sufficient to prove that a solution to [cite] the PDE with $L^2$ initial data is $L^\infty$ in finite time.  

Logan: I haven't completed this proof at all, I'm sure it's possible but I'm putting my energy elsewhere, especially since it's not strictly necessary.  

\begin{proposition}[$L^2$ to $L^\infty$] \label{thm:L2 to Linfty}
If $\theta$ and $u$ solve [cite] on $[0,T] \times \Omega$ and $\theta_0 \in L^2$, then for any time $S \in (0,T)$ there exists a constant $C = C(S)$ such that
\[ \norm{\theta}_{L^\infty([S,T]\times \Omega)} \leq C \norm{\theta_0}_{L^2(\Omega)}. \]
\end{proposition}

\begin{proof}
It is trivial to show that the $L^2(\Omega)$ norm of any solution $\theta$ to \eqref{eq:main linear} does not increase in time.  Simply multiply the function by $\theta$ and integrate.  

Moreover, using Lemma \ref{thm:caccioppoli} with $\psi(t,x) = \norm{\theta(T,\cdot)}_{L^\infty(\Omega)}$ tells us that the $L^\infty(\Omega)$ norm of a solution, once finite, is non-increasing in time.

To show that the $L^\infty(\Omega)$ norm of a solution with $L^2(\Omega)$ initial data becomes finite in finite time, consider the sequence of functions
\[ \theta_k := (\theta(t,x) - 1 + 2^{-k})_+ \]
and define
\[ \E_k := \int_{-1-2^{-k}}^0 \int_\Omega \theta_k^2 \,dxdt. \]

When $\theta_{k+1}>0$, then in particular $\theta_k \geq 2^{-k}$ [or something similar].  Thus for any finite $p$, there exists a constant $C$ so
\[ \indic{\theta_{k+1}>0} \leq C^k \theta_k^p. \]
In particular,
\[ \E_{k+1} \leq C^k \int_{-1-2^{-k}}^0 \int \theta_k^3. \]

Applying the energy inequality $\theta$, $\phi$, and $\Gamma$ we obtain
\[ \sup_{-1-2^{-k-1}<t<0} \int \theta_{k+1}^2 + \int_{-1-2^{-k-1}}^0 \int \abs{\Lambda^{1/2}\theta_{k+1}}^2 \leq C^k \int_{-1-2^{-k}}^0 \theta_k^2 = \E_k. \]

However, by Sobolev embedding and the fact that $H_D^{1/2}$ controls classical $H^{1/2}$ controls $L^4$,
\[ \norm{\theta_{k+1}}_{L^3([-1-2^{-k-1},0]\times\Omega)} \leq C^k \E_k^{1/2}. \]

Therefore
\[ \E_{k+1} \leq C^k \E_k^{3/2}. \]

It follows by a well known result [citation] that for $\E_0$ sufficiently small (say less than $\bar{C}$), $\E_k \to 0$ as $k \to \infty$.  

Notice that, since the $L^2(\Omega)$ norm of $\theta$ does not increase in time,
\[ \E_0 = \int_{-2}^0 \int_\Omega (\theta)_+ \,dxdt \leq 2 \int \theta_0^2 \,dx . \]
Moreover, as $k \to \infty$ we have
\[ \E_k \to \int_{-1}^0 \int_\Omega (\theta - 1)_+ \,dxdt \]

Thus, if $\norm{\theta_0}_{L^2(\Omega)} \leq \sqrt{\bar{C}/2}$ then $\theta \leq 1$ on $[-1,0]$.  

Since \eqref{eq:main linear} is linear and scales in time and space as in Lemma \ref{thm:scaling} (and since the constant $\bar{C}$ does not depend on $\Omega$), we can take a solution $\theta$ with arbitrary initial $L^2$ norm and apply this result to a scaled version. 

The result follows.  
\end{proof}

We've completed the essential version of the Caccioppoli estimate.  However, much more can be said about the drift-term $u$.  In particular, we can design a cutoff $\psi$ in order to minimize the expression $\del_t \psi + u\cdot\grad\psi$.  


\begin{lemma}[Energy inequality] \label{thm:energy inequality}
Let $\theta \in L^2(-T,0; H_D^{1/2}(\Omega))$ and $u \in L^\infty(-T,0; L^2(\Omega))$ solve
\begin{align*}
\del_t \theta + u\cdot \grad \theta + \Lambda \theta = 0,
\\ \div u = 0
\end{align*}
in the sense of distributions.  Let
\[ u = \ulow + \uhigh \]
where $\Lambda^{-1/4} \uhigh \in L^\infty(0,T; L^\infty(\Omega))$ and $\ulow \in L^\infty(0,T; \Lip(\Omega)) \cap L^\infty(0,T; \dot{C}^{3/4}(\Omega)$.  
Suppose that $\Gamma, \gamma \in \Lip([-T,0])$ satisfy $\norm{\dot{\gamma}}_\infty \leq C_\gamma$, $\gamma(0)=0$, and
\[ \dot{\Gamma}(t) + \dot{\gamma}(t) = \ulow(t, \Gamma(t) + \gamma(t)). \]

Then for any $\phi \in C^2(\Omega)$ such that $|x|^{3/4} \grad \phi(x)| \in L^\infty$, the functions
\[ \theta_+ := \paren{\theta - \phi(\cdot-\Gamma)}_+, \qquad \theta_- := \paren{\phi(\cdot-\Gamma) - \theta}_+ \]
satisfy the inequality
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 - \chevron{\theta_+,\theta_-}_{1/2} \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ + \int \theta_+^2 } \]
with the constant $C$ depending on $C_\gamma$ and $T$, on $\norm{\Lambda^{-1/4} \uhigh}_\infty$, $\bracket{\ulow}_{3/4}$, and $\norm{\ulow}_\Lip$, and on $\norm{D^2 \phi}_\infty$, $\norm{\grad\phi}_\infty$, and $\sup \norm{|x|^{3/4} \grad\phi(x)}_\infty$.  
\end{lemma}

\begin{proof}
We'll apply the Caccioppoli estimate with
\[ \psi(t,x) := \phi(x - \Gamma(t)), \]
\[ \phi \in C^2(\R^2) \cap \dot{C}^{1/4}(\R^2). \]

Now
\[ \del_t \psi + u\cdot\grad \psi = (u - \dot{\Gamma})\cdot \grad \phi(x-\Gamma(t)). \]

We arrive at
\[ \ddt \int \theta_+^2 + \int \abs{\Lambda^{1/2} \theta_+}^2 - \chevron{\theta_+,\theta_-}_{1/2} \leq C \paren{ \int \indic{\theta_+ > 0} + \int \theta_+ (u-\dot{\Gamma}(t)) \cdot \grad\phi(x-\Gamma(t)) }. \]

Consider the high pass term $\int \theta_+ \uhigh\cdot\grad\phi$.  Integrating by parts (or, since $\Lambda$ is self adjoint) and then applying the Lemma \ref{thm:weak product rule}
\[ \int \Lambda^{-1/4} \uhigh \Lambda^{1/4} (\theta_+ \grad\phi) \leq C \norm{\Lambda^{-1/4} \uhigh}_\infty \paren{\norm{\grad\phi}_\infty + \norm{D^2 \phi}_\infty} \paren{\norm{\theta_+}_1 + |\supp(\theta_+)|^{1/2} \paren{ \norm{\theta_+}_{L^2} + \norm{\theta_+}_{H_D^{1/2}}}}. \]
From H\"{o}lder's inequality with Peter-Paul, we obtain
%\[ \int \Lambda^{-1/4} \uhigh \Lambda^{1/4} (\theta_+ \grad\phi) \leq C(\phi,\eps) \norm{\Lambda^{1/4} \uhigh}_\infty \paren{\int \theta_+ + |\{\theta_+>0\}| + \int \theta_+^2 + \eps\n |\{\theta_+ > 0\}| + \eps \int \abs{\Lambda^{1/2} \theta_+}^2 }. \]
\[ \int \uhigh \theta_+ \grad \phi(x - \gamma(t)) \,dx \leq C(\phi,\eps) \norm{\Lambda^{-1/4}\uhigh}_\infty \paren{\int \indic{\theta_+>0} + \int \theta_+ + \int \theta_+^2} + \eps \int \abs{\Lambda^{1/2} \theta_+}^2. \]

Time for the low pass term.  

Recall that
\[ \dot{\Gamma} + \dot{\gamma} = \ulow(t, \Gamma+\gamma) \]
so
\[ \ulow(t,x) - \dot{\Gamma}(t) = \ulow(t,x) - \ulow(t,\Gamma+\gamma) + \dot{\gamma}. \]

By assumption, $|\dot{\gamma}|\leq C_\gamma$ and so for $t \in [-T,0]$ we have $|\gamma(t)| \leq T C_\gamma$.  

Since $\ulow$ is Lipschitz and H\"{o}lder continuous,
\begin{align*} 
|\ulow(t,x) - \ulow(t,\Gamma+\gamma)| &\leq  |\ulow(t,x)-\ulow(t,\Gamma)| + |\ulow(t,\Gamma) - \ulow(t,\Gamma+\gamma)| 
\\ &\leq \bracket{\ulow}_{3/4} |x-\Gamma|^{3/4} + \norm{\ulow}_\Lip T C_\gamma. 
\end{align*}

Plugging these bounds int [cite] we obtain
\[ \abs{\ulow(t,x) - \dot{\Gamma}(t)} \leq (1+\norm{\grad\ulow}_\infty T) C_\gamma + \bracket{\ulow}_{3/4} |x-\Gamma|^{3/4}. \]

Now we can bound the low pass term
\begin{align*}
\int (\ulow - \dot{\Gamma}) \theta_+ \grad\phi(x-\Gamma) &\leq (1+\norm{\grad\ulow}_\infty T) C_\gamma \int |\grad\phi(x-\Gamma)| \theta_+ \,dx +  \bracket{\ulow}_{3/4} \int |x-\Gamma|^{3/4} \theta_+ |\grad \phi(x-\Gamma)| \,dx
\\ &\leq (1+\norm{\grad\ulow}_\infty T) C_\gamma \norm{\grad\phi}_\infty \int \theta_+ \,dx +  \bracket{\ulow}_{3/4} \norm{|x|^{3/4} \grad\phi(x)}_\infty \int \theta_+ \,dx.
\end{align*}

From this the result follows.  
\end{proof}

At last we can prove the De Giorgi lemmas.  

\begin{lemma}[First De Giorgi Lemma] \label{thm:DG1}
Suppose that $\theta$ and $u = \ulow + \uhigh$ solve [cite] on $[-T,0]\times \Omega$ for some open $C^{2,\alpha}$ set $\Omega \subseteq \R^2$.  

Suppose that for some $\Gamma:[-T,0]\to \R^2$, 
\[ \theta(t,x) \leq 2 + \paren{|x-\Gamma(t)|^{1/4}-2^{1/4}}_+ \qquad \forall x \notin B_2(\Gamma(t)). \]
Suppose also that
\[ \ulow(t,\Gamma(t)+\gamma(t)) = \dot{\Gamma}(t) + \dot{\gamma}(t) \]
for some $\gamma$ with Lipschitz norm less than $C_\gamma$.  

Then there exist constants $\delta_0>0$ and $\eps > 0$ such that
\[ \int_{-2}^0 \int_{B_2(\Gamma(t))} \max(\theta,0)^2 \,dxdt \leq \delta_0 \]
implies that
\[ \theta(t,x) \leq 1 \qquad \forall (t,x) \in [-1,0]\times B_1(\Gamma(t)). \]

\end{lemma}

\begin{proof}
Let $\phi$ be such that $\phi = 0$ on $B_1$ and $\phi(x) \geq 2 + \paren{|x|^{1/4}-2^{1/4}}_+$ for $|x|>2$ while $\phi$ is Lipschitz and $C^2$ and its gradient decays like $|x|^{-3/4}$.  

Consider the sequence of functions
\[ \theta_k := (\theta(t,x) - \phi(x - \Gamma(t)) - 1 + 2^{-k})_+ \]
and define
\[ \E_k := \int_{-1-2^{-k}}^0 \int_\Omega \theta_k^2 \,dxdt. \]

Notice that
\[ \E_0 = \int_{-2}^0 \int_\Omega (\theta - \phi(x-\Gamma))_+^2 \,dxdt \leq \delta_0. \]
Moreover, as $k \to \infty$ we have
\[ \E_k \to \int_{-1}^0 \int_\Omega (\theta - \phi(x-\Gamma) - 1)_+^2 \,dxdt \]
so in particular, if we can show $\E_k \to 0$ then $\theta \leq 1$ for $t \in [-1,0]$ and $x \in B_1(\Gamma)$.  

That's enough setup, let's argue that $\E_k \to 0$.  Notice that when $\theta_{k+1}>0$, then in particular $\theta_k \geq 2^{-k}$ [or something similar].  Thus for any finite $p$, there exists a constant $C$ so
\[ \indic{\theta_{k+1}>0} \leq C^k \theta_k^p. \]
In particular,
\[ \E_{k+1} \leq C^k \int_{-1-2^{-k}}^0 \int \theta_k^3. \]

Applying the energy inequality $\theta$, $\phi$, and $\Gamma$ we obtain
\[ \sup_{-1-2^{-k-1}<t<0} \int \theta_{k+1}^2 + \int_{-1-2^{-k-1}}^0 \int \abs{\Lambda^{1/2}\theta_{k+1}}^2 \leq C^k \int_{-1-2^{-k}}^0 \theta_k^2 = \E_k. \]

However, by Sobolev embedding and the fact that $H_D^{1/2}$ controls classical $H^{1/2}$ controls $L^4$,
\[ \norm{\theta_{k+1}}_{L^3([-1-2^{-k-1},0]\times\Omega)} \leq C^k \E_k^{1/2}. \]

Therefore
\[ \E_{k+1} \leq C^k \E_k^{3/2}. \]

It follows by a well known result [citation] that for $\E_0$ sufficiently small (say less than $\delta_0$), $\E_k \to 0$ as $k \to \infty$ which we already established is sufficient to obtain our result.  
\end{proof}


This is coming along quite nicely.  We can move on to DG2, the isoperimetric inequality.  

\begin{lemma}[Second De Giorgi Lemma] \label{thm:DG2}
Let $\theta$ and $u = \ulow + \uhigh$ be solutions to [cite] satisfying the desired bounds.  Let $\Gamma$ and $\gamma$ be paths with the desired properties, in particular
\[ \dot{\Gamma} +\dot{\gamma} = \ulow(t,\gamma + \Gamma). \]

Suppose that for $t \in [-5,0]$ and any $x \in \Omega$,
\[ \theta(t,x) \leq 2 + \paren{|x-\Gamma(t)|^{1/4}-2^{1/4}}_+. \]

There exists a small constant $\mu$ such that the three conditions
\[ \abs{\{\theta \geq 1\} \cap [-2,0]\times B_2(\Gamma)} \geq \delta_0, \]
\[ \abs{\{0 < \theta < 1\} \cap [-4,0]\times B_4(\Gamma)} \leq \mu, \]
\[ \abs{\{\theta \leq 0\} \cap [-4,0]\times B_4(\Gamma)} \geq \frac{4 |B_4|}{2} \]
cannot simultaneously be met.  
\end{lemma}

\begin{proof}
Suppose that the theorem is false, i.e. that there exist functions $\theta_n: [-5,0]\times \Omega_n \to \R$ and $\ulow^n, \uhigh^n: [-5,0]\times\Omega_n \to \R^2$ which satisfy the desired bounds on $\Omega_n$ some scaling of $\Omega$, namely that
\[ \dot{\Gamma}_n + \dot{\gamma}_n = \ulow^n(t, \Gamma_n + \gamma_n) \]
for paths $\Gamma_n:[-5,0] \to \Omega_n$ and $\gamma_n:[-5,0]\to \Omega_n$ satisfying $|\dot{\gamma}| \leq C_\gamma$, but for which
\[ \abs{\{0 < \theta_n < 1\} \cap [-4,0]\times B_4(\Gamma_n)} \leq 1/n. \]

Let $\phi$ be a function which vanishes on $B_2$ but has all the growth and smoothness properties.  In particular assume that $\phi$ exceeds $2 + \paren{|x|^{1/4}-2^{1/4}}_+$ for $|x|>3$.  

Fix $n$ and define 
\[ \theta_+ := \paren{\theta_n - \phi(x-\Gamma_n)}_+. \]
Then $\theta_+$ is supported on $B_3(\Gamma_n)$ and is less than $2 + 3^{1/4} - 2^{1/4} \leq 3$ everywhere.  

Apply the energy inequality Lemma \ref{thm:energy inequality} with $\phi(x-\Gamma_n)$, and find that
\[ \sup_{[-4,0]} \int \theta_+^2 + \int_{-4}^0 \int \abs{\Lambda^{1/2}\theta_+}^2 \leq C \int_0^4 \int \paren{\indic{\theta_+>0} + \theta_+ + \theta_+^2}. \]
This proves in particular that $\theta_+ \in L^2([-2,0]; H_D^{1/2}(\Omega))$ is uniformly bounded.  

What's more, $\norm{\theta_+^3}_{H_D^{1/2}(\Omega_n)}$ is uniformly bounded because
\begin{align*} 
\norm{\Lambda^{1/2}(\theta_+^3)}_2^2 &= \iint [\theta_+(x)^3 - \theta_+(y)^3]^2 K + \int \theta_+^6 B 
\\ &\leq \iint \theta_+(x)^4 [\theta_+(x)-\theta_+(y)]^2 K + \iint \theta_+(y)^4[\theta_+(x)-\theta_+(y)]^2 K + \norm{\theta_+}_\infty^4 \int \theta_+^2 B
\\ &\leq \norm{\theta_+}_\infty^4 \norm{\theta_+}_{H_D^{1/2}}^2 \leq C.
\end{align*}

By Lemma \ref{thm:hadamard 3 lines}, if $E \theta_+^3$ is the zero-extension of $\theta_+^3$ from $\Omega_n$ to $\R^2$, then
\[ \norm{ E \theta_+^3}_{L^2(-5,0; H^{1/2}(\R^2))} \leq C \]
where $C$ does not depend on $n$.  

Since $\theta_n$ solves the equation [cite], multiply the equation by $\varphi \theta_+^2$, where $\varphi$ is any function in $C^2(\R^2)$ restricted to $\Omega_n$, and integrate to obtain
\[ \frac{1}{3} \int \varphi \del_t \theta_+^3 + \frac{1}{3} \int \varphi \dot{\Gamma}_n \cdot \grad \theta_+^3 = \frac{-1}{3} \int \varphi (u^n - \dot{\Gamma}_n) \cdot \grad \theta_+^3 - \int \varphi \theta_+^2 \Lambda \theta_+ - \int \varphi \theta_+^2 (u^n - \dot{\Gamma}_n) \cdot \grad \phi - \int \varphi \theta_+^2 \Lambda \phi + \int \varphi \theta_+^2 \Lambda \theta_-. \]
We will bound the terms on the right hand side one at a time.  

Each instance of $C$ in the following bounds is independent of $n$.  

Recall $|\ulow^n - \dot{\Gamma}_n| \leq C \kappa + 4C_\gamma$ on $[-4,0]\times B_3(\Gamma_n)$ which is precisely the support of $\theta_+$.  Integrating by parts,
\[ \int \varphi (\ulow^n - \dot{\Gamma}_n) \grad \theta_+^3 = \int \grad\varphi (\ulow^n - \dot{\Gamma}_n) \theta_+^3 \leq C \norm{\grad \varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))}. \]
Similarly,
\[ \int \varphi \theta_+^2 (\ulow^n - \dot{\Gamma}_n) \cdot \grad \phi \leq C \norm{ \grad \varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))}. \]

By Lemmas \ref{thm:L1 of Lambda bounded} and \ref{thm:product rule}
\[ \int \varphi \uhigh^n \grad \theta_+^3 = \int \Lambda^{-1/4} \uhigh^n \Lambda^{1/4}(\theta_+^3 \grad \varphi) \leq C (\norm{\grad \varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))} + \norm{D^2 \varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))}). \]
By the same lemmas,
\begin{align*}
\int \varphi \theta_+^2 \uhigh^n \grad \phi &\leq C \paren{\norm{\varphi \grad\phi)}_{L^1(L^\infty)} + \norm{\grad(\varphi \grad\phi)}_{L^1(L^\infty)} }
\\ &\leq C \paren{\norm{\varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))} + \norm{\grad \varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))} }. 
\end{align*}

This completes both of the drift terms.  The $\Lambda$ terms remain.  These are bounded by relentless use of the Caffarelli-Stinga representation formula.  

For the $\theta_+$ term
\begin{align*}
\int \varphi \theta_+^2 \Lambda \theta_+ &= \iint [\varphi(x)\theta_+(x)^2 - \varphi(y)\theta_+(y)^2][\theta_+(x)-\theta_+(y)] K + \int \varphi \theta_+^3 B
\\ &= \iint \varphi(x)(\theta_+(x)+\theta_+(y))[\theta_+(x)-\theta_+(y)]^2 K + \iint \theta_+(y)^2 [\varphi(x)-\varphi(y)][\theta_+(x)-\theta_+(y)] K + \iint \varphi \theta_+^3 B
\\ &\leq C \norm{\varphi}_{L^1(-4,0; L^\infty(\Omega_n))} + C \norm{\grad \varphi}_{L^1(-4,0; L^\infty(\Omega_n))}
\end{align*}

For any non-negative function $f$ we know by Lemma \ref{thm:disjoint} that
\[ \int f \theta_+^2 \Lambda \theta_- \leq 0. \]
It follows that $-\theta_+^2 \Lambda \theta_-$ is a pointwise non-negative distribution.  If we can bound its integral, then we will have bounded it as an element of $L^\infty(\mathcal{M}(\Omega_n))$.  
From [cite], its integral is simply
\[ -\int \theta_+^2 \Lambda \theta_- \leq - \norm{\theta_+}_\infty \int \Lambda^{1/2} \theta_+ \Lambda^{1/2} \theta_- \leq C. \]
Since $\varphi$ is continuous, 
\[ \int \varphi \theta_+^2 \Lambda \theta_- \leq \norm{\varphi}_\infty \norm{\theta_+^2 \Lambda \theta_-}_{\mathcal{M}(\Omega_n)} \leq C \norm{\varphi}_{L^1(-4,0; L^\infty(\Omega_n))}. \]

Lastly, 
\begin{align*} 
\int \varphi \theta_+^2 \Lambda \phi &= \iint [\varphi(x) \theta_+(x)^2 - \varphi(y) \theta_+(y)^2][\phi(x)-\phi(y)] K + \int \varphi \theta_+^2 \phi B
\\ &= \iint \varphi(x) [\theta_+(x)^2 - \theta_+(y)^2][\phi(x)-\phi(y)] K + \iint \theta_+(y)^2[\varphi(x) - \varphi(y)][\phi(x)-\phi(y)] K + \int \varphi \theta_+^2 \phi B
\\ &\leq C\paren{\iint \varphi(x)^2 [\phi(x)-\phi(y)]^2 K}^{1/2} + \paren{ \norm{\varphi}_\infty + \norm{\grad \varphi}_\infty } \int \theta_+(y)^2 \,dy + \int \varphi \theta_+^2 \phi B
\\ &\leq C \norm{\varphi}_{L^2} + C \norm{\varphi}_{\infty} + C \norm{\grad \varphi}_\infty + \norm{\phi\indic{\theta_+>0}}_\infty \norm{\theta_+}_{H_D^{1/2}}^2 \norm{\varphi}_{\infty}
\\ &= C \norm{\phi}_{L^\infty(-4,0; L^2(\Omega_n))} + C \norm{\varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))} + C \norm{\grad\varphi}_{L^\infty(-4,0; L^\infty(\Omega_n))}.
\end{align*}

Taken all together, we conclude that there exists a constant $C$ indepnendent of $n$ such that, for any $\varphi \in L^\infty(-4,0; C^2(\R^2)) \cap L^\infty(-4,0; L^2(\R^2))$, 
\[ \int_{-4}^0 \int_{\Omega_n} \paren{ \del_t \theta_+^3 + \dot{\Gamma}_n \cdot \grad \theta_+^3 } \varphi \,dxdt \leq C \norm{\varphi}_{L^\infty(-4,0; C^2(\R^2))} + C \norm{\varphi}_{L^\infty(-4,0; L^2(\R^2))}. \]

Over time, the support of $\theta_+^3$ moves around in $\Omega_n$ following the path $\Gamma_n$.  If we try to take a limit, that limit will vanish except at points where infinitely many $\Gamma$ pass nearby, which is generally unhelpful.  Instead, we extend each $\theta_+^3$ to a function on $\R^2$ and then shift them around to remain supported near the origin.  To that end, define a new function on $[-4,0] \times \R^2$ by
\[ v_n(t,x) := \begin{cases}
\theta_+^3(t, x + \Gamma_n(t)), & x + \Gamma_n(t) \in \Omega_n, \\
0, & x + \Gamma_n(t) \notin \Omega_n.
\end{cases} \]

Let $X \subseteq C^2(\R^2)$ be the Banach space of $C^2$ functions with norm $\norm{\cdot}_X = \norm{\cdot}_{C^2(\R^2)} + \norm{\cdot}_{L^2(\R^2)}$ finite.  Note that
\[ \del_t v_n(t,x) = \del_t \theta_+^3(t,x+\Gamma_n) + \dot{\Gamma}_n \cdot \grad \theta_+^3(t,x+\Gamma_n). \]

We know that
\[ \norm{ v_n }_{L^2(-4,0; H^{1/2}(\R^2)} \leq C \]
and
\[ \norm{ \del_t v_n }_{L^1(-4,0; X^*)} \leq C. \]

Moreover, 
\[ \ddt \int_{\R^2} v_n^{2/3} \,dx = \ddt \int_{\Omega_n} \theta_+^3 \,dx \leq C. \]

Finally, from [cite],
\[ \abs{\{v_n \geq 1\} \cap [-2,0]\times B_2(0)} \geq \delta_0, \]
\[ \abs{\{0 < v_n < [1-\phi(x)]^3\} \cap [-4,0]\times B_4(0} \leq 1/n, \]
\[ \abs{\{v_n \leq 0\} \cap [-4,0]\times B_4(0)} \geq \frac{4 |B_4|}{2}. \]

By [cite], [cite], and the Aubin-Lions lemma, the set $\{v_n\}_n$ is compactly embedded in $L^2(-4,0; L^2(\R^2))$.  Up to a subsequence, there is a function $v \in L^2(-4,0; L^2(\R^2))$ such that
\[ v_n \to v. \]
By elementary properties of $L^2$ convergence, we know that $v \in L^\infty$, $\supp(v) \subseteq [-4,0]\times B_3(0)$, $v \in L^2(H^{1/2})$ and 
\begin{equation} \label{ddt v bounded} \ddt \int v(t,\cdot)^{2/3} \leq C. \end{equation} 
Also, the properties [cite] hold still in the limit.  

For any $(t,x) \in [-4,0]\times B_4(0)$, either $v(t,x) \geq [1 - \phi(x)]^3$ or else $v(t,x) = 0$.  In fact, since $\norm{v(t,\cdot)}_{H^{1/2}} < \infty$ for almost every $t$ and $H^{1/2}$ does not cantain functions with jump discontinuities, the function $v$ is either identically 0 or else $\geq [1-\phi(x)]^3$ at each $t$.  

Thus $\int v(t,x)^{2/3} \,dx$ is either 0 or else $\geq \int [1-\phi(x)]^3 \,dx > 0$ at each $t$.  By \eqref{ddt v bounded} and [cite, mass bounds], $v$ must be identically zero for all $t > -2$.  This contradicts [cite], so our assumption that the sequence $\theta_n$ exists must have been false.  The proposition must be true.  

\end{proof}


%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{Harnack Inequality} \label{sec:harnack}

We put together Propositions \ref{thm:DG1} and \ref{thm:DG2} to produce a Harnack inequality.  

\begin{proposition}[Oscillation Lemma] \label{thm:oscillation general}
Let $\theta$ and $u = \ulow + \uhigh$ be solutions to [cite] the PDE.  Let $\Lambda^{-1/4} \uhigh \in L^\infty$ while $\ulow \in \Lip \cap L^{3/4}$.  Moreover, let $\gamma$ and $\Gamma$ be such that
\[ \dot{\Gamma} + \dot{\gamma} = \ulow(t,\Gamma+\gamma) \]
and $\norm{\dot{\gamma}}_\infty \leq C_\gamma$. 

There exists a number $k_0$ and a small constant $\lambda>0$ such that if for all $t \in [-5,0]$, $x \in \Omega$,
\[ \theta(t,x) \leq 2 + 2^{-k_0} \paren{|x-\Gamma(t)|^{1/4}-2^{1/4}}_+ \]
and
\[ \abs{\{\theta \leq 0\} \cap [-4,0]\times B_4(\Gamma)} \geq \frac{4|B_4|}{2} \]
then for all $t \in [-1,0]$, $x \in B_1(\Gamma)$ we have
\[ \theta(t,x) \leq 2 - \lambda. \]
\end{proposition}

\begin{proof}
Let $\mu$ and $\delta_0$ as in Proposition \ref{thm:DG2}, and take $k_0$ large enough that $(k_0-1) \mu > 4 |B_4|$.  

Consider the sequence of functions,
\[ \theta_k(t,x) := 2 + 2^k (\theta(t,x) - 2). \]
That is, $\theta_0 = \theta$ and as $k$ increases, we scale vertically by a factor of 2 while keeping height 2 as a fixed point.  Note that since $\theta$ satisfies [cite, boundedness], each $\theta_k$ for $k \leq k_0$ and $(t,x) \in [-5,0] \times \Omega$ satisfies
\[ \theta_k(t,x) \leq 2 + \paren{|x-\Gamma(t)|^{1/4}-2^{1/4}}_+. \]
This is precisely the assumption in Proposition \ref{thm:DG2}.  

Note also that
\[ \abs{\{\theta_k \leq 0\} \cap [-4,0]\times B_4(\Gamma)} \]
is an increasing function of $k$, and hence is greater than $2|B_4|$ for all $k$.  

Assume, for means of contradiction, that
\[ \abs{\{1 \leq \theta_k \} \cap [-2,0]\times B_2(\Gamma)} \geq \delta_0 \]
for $k = k_0-1$.  Since this quantity is decreasing in $k$, it must then exceed $\delta_0$ for all $ k < k_0$ as well.  

Applying Proposition \ref{thm:DG2} to each $\theta_k$, we conclude that 
\[ \abs{\{0 < \theta_k < 1\} \cap [-4,0]\times B_4(\Gamma)} \geq \mu. \]
In particular, this means that the quantity [cite] increases by atleast $\mu$ every time $k$ increases by 1. By choice of $k_0$ and the fact that quantity [cite] is bounded by $4|B_4|$, we obtain a contradiciton.  Therefore, the assumption [cite] must fail for $k = k_0-1$.  

Therefore $\theta_{k_0}$ must satisfy the assumptions of Proposition \ref{thm:DG1}.  In particular, we conclude that
\[ \theta_{k_0}(t,x) \leq 1 \qquad \forall (t,x) \in [-1,0]\times B_1(\Gamma). \]

For the original function $\theta$, this means that for $(t,x) \in [-1,0] \times B_1(\Gamma)$
\[ \theta(t,x) \leq 2 - 2^{-k_0}. \]
\end{proof}

That's the absolute gain.  Now let us consider how this gain can be shifted to our new reference frame.  But first, a quice technical lemma:

\begin{lemma} \label{thm:technical scaling of barrier}
There exist a constant $\bar{\lambda} > 0$ and $\alpha > 1$ such that, for any $0 < \eps \leq 1/2$ and any $z \geq 1$
\[ \paren{|\eps\n (z - 1) + 3|^{1/4} - 2^{1/4}}_+ - \alpha \paren{|z|^{1/4} - 2^{1/4}}_+ \geq \bar{\lambda}. \]
\end{lemma}

\begin{proof}
For $z$ fixed, this function is increasing as $\eps$ decreases, so it will suffice to show the lemma when $\eps = 1/2$.  Consider
\[ \paren{|2 z + 1|^{1/4} - 2^{1/4}}_+ - \alpha \paren{|z|^{1/4} - 2^{1/4}}_+. \]
When $\alpha = 1$, this quantity is clearly non-negative and in fact strictly positive when $z \geq 1$.  On any compact interval $[0,N]$, the quantity with $\alpha = 1$ is bounded below, and the quantity $\paren{|z|^{1/4} - 2^{1/4}}_+$ is bounded above, so if $\alpha-1$ is less than the ratio of those bounds then the total quantity will be bounded below.  

However, the range of acceptable $\alpha$ depends on $N$, and it is possible that no single $\alpha$ is acceptable for the whole of $z \in [1,\infty)$.  

For $z > 2$, the expression reduces to
\[ (2z+1)^{1/4} - \alpha z^{1/4} - (\alpha-1) 2^{1/4} = z^{1/4} \paren{(2 + 1/z)^{1/4} - \alpha} - (\alpha-1)2^{1/4}. \]
This quantity is increasing as $\alpha$ decreases, and for any $\alpha < 2^{1/4}$ it tends to $\infty$ as $z$ increases. 

This is sufficient to show that for some $\alpha > 1$, there exists a lower bound $\bar{\lambda}$ on the quantity [cite], and thus the lemma holds. 
\end{proof}

We are ready to prove the shifted version of the Harnack Inequality.  

\begin{lemma}[Oscillation Lemma, with shift] \label{thm:oscillation shifted}
Let $\theta$ and $u = \ulow + \uhigh$ be as desired.  Let $\Gamma$ and $\gamma$ be paths such that
\[ \dot{\Gamma} + \dot{\gamma} = \ulow(t,\Gamma+\gamma) \]
and $\norm{\gamma}_\Lip \leq C_\gamma$.  If $0 < \eps < 1/5$ is such that
\[ 5 C_\gamma \leq \eps\n - 3 \]
then the following holds:

Let $k_0$ be as in Lemma \ref{thm:harnack general} and assume that for $(t,x) \in [-5,0]\times \Omega$
\[ |\theta(t,x)| \leq 2 + 2^{-k_0} \paren{|x-\Gamma(t)|^{1/4}-2^{1/4}}_+ \]
and
\[ \abs{\{\theta \leq 0\} \cap [-4,0]\times B_4(\Gamma)} \geq \frac{4|B_4|}{2}. \]

Then there exist a $\lambda > 0$ small enough that for $(t,x) \in [-5,0]\times \eps\n \Omega$
\[ \abs{\frac{2}{2-\lambda} \bracket{\theta(\eps t, \eps x) + \lambda}} \leq 2 + 2^{-k_0} \paren{|x-\eps\n\Gamma(\eps t)-\eps\n\gamma(\eps t)|^{1/4}-2^{1/4}}_+. \]
\end{lemma}

If we only wish to show that by zooming horizontally by a large amount and zooming vertically by a small amount we stay under the barrier, this is obvious and merely requires being written down.  Even the shift itself is clearly not a problem when considered in the un-zoomed coordinates.  Since the velocity of $\gamma$ is bounded by $C_\gamma$, the shift $\gamma$ is arbitrarily small over very small time periods.  The difficulty comes from the fact that $k_0$ itself depends on $C_\gamma$, and as we will see in the next section $C_\gamma$ depends on $\eps$, so $\eps$ cannot depend on $k_0$.  In time, the co-dependence of $\eps$ and $C_\gamma$ is easy to untangle (so long as $\eps C_\gamma$ is less than some universal constant, the proof will go through).  In space, it is less clear that $\eps$ will not depend on $k_0$, and of course we need to zoom in time and space by the same factor so both issues are interconnected.  

\begin{proof}
Take $\lambda$ such that
\[ 2\lambda \leq 2^{-k_0}, \qquad \frac{2}{2-\lambda} \leq 1 + 2^{-k_0} \bar{\lambda} / 2, \qquad \frac{2}{2-\lambda} \leq \alpha. \]
for $\bar{\lambda}$ and $\alpha$ from Lemma \ref{thm:technical scaling of barrier}.  

Denote 
\[ \bar{\theta}(t,x) := \frac{2}{2-\lambda} \bracket{\theta(\eps t, \eps x) + \lambda} \]
and
\[ \phi(x) = \paren{|x|^{1/4} - 2^{1/4}}_+. \]

We already proved in Lemma \ref{thm:oscillation general} that $\theta \leq 2 - 2^{-k_0}$ on $[-1,0] \times B_1(\Gamma)$.  For $\bar{\theta}$, this means that $|\bar{\theta}(t,x)| \leq 2$ when $(t,x) \in [-1/\eps, 0] \times B_{1/\eps}(\eps\n \Gamma(\eps t))$.  

Similarly, the bound [cite] on $\theta$ becomes the equivalent bound on $\bar{\theta}$, for all $(t,x) \in [-5/\eps,0] \times \eps\n \Omega$
\[ \bar{\theta}(t,x) \leq \frac{2}{2-\lambda} \bracket{2 + \lambda + 2^{-k_0} \phi(|\eps x - \Gamma(\eps t)|)}, \]
\[ \bar{\theta}(t,x) \geq \frac{2}{2-\lambda} \bracket{\lambda - 2 - 2^{-k_0} \phi(|\eps x - \Gamma(\eps t)|)}. \]

Let $t \in [-5,0]$ and $x \in \eps\n \Omega$, and define $y = x - \eps\n \Gamma(\eps t)$.  If $|y| \leq \eps\n$ then
\[ \bar{\theta}(t,x) \leq 2 \leq 2 + 2^{-k_0} \phi(x - \eps\n \Gamma(\eps t) - \eps\n \gamma(\eps t)). \]
If $|y| \geq \eps\n$ then from Lemma \ref{thm:technical scaling of barrier}, 
\[ \bar{\lambda} + \alpha \phi(\eps |y|) \leq \phi(|y| - \eps\n + 3). \]
We assume that
\[ (2+\lambda)(\frac{2}{2-\lambda}) \leq 2 + 2^{-k_0} \bar{\lambda}, \qquad \frac{2}{2-\lambda} \leq \alpha. \]
Thus we rewrite the bound [cite] as
\[ \bar{\theta}(t,x) \leq \frac{2}{2-\lambda} \bracket{2 + \lambda + 2^{-k_0} \phi(\eps |y|)} \]
\[ \leq 2 + 2^{-k_0} \bar{\lambda} + 2^{-k_0} \alpha \phi(\eps |y|) \]
\[ = 2 + 2^{-k_0} \bracket{\bar{\lambda} + \alpha \phi(\eps |y|)} \]
\[ \leq 2 + 2^{-k_0} \phi(|y| - \eps\n + 3). \]
For $t \in [-5,0]$,
\[ |y| - 5 C_\gamma \leq |y - \eps\n\gamma(\eps t)|. \]
Thus, since by assumption $5 C_\gamma \leq \eps\n - 3$,
\[ |y| - \eps\n + 3 \leq |y-\eps\n\gamma(\eps t)|. \]

Therefore, for $|y| \geq \eps\n$,
\[ \bar{\theta}(t,x) \leq 2 + 2^{-k_0} \phi(|x - \eps\n\Gamma(\eps t) - \eps\n\gamma(\eps t)|). \]

On the other hand, 
\[ -\bar{\theta}(t,x) \leq \frac{2}{2-\lambda} \bracket{2 -\lambda + 2^{-k_0} \phi(\eps |y|)} \]
\[ \leq 2 + 2^{-k_0} \alpha \phi(\eps |y|) \]
\[ \leq 2 + 2^{-k_0} \bracket{\bar{\lambda} + \alpha \phi(\eps |y|)} \]
\[ \leq 2 + 2^{-k_0} \phi(|y| - \eps\n + 3) \]
\[ \leq 2 + 2^{-k_0} \phi(|y-\eps\n\gamma(\eps t)|). \]

This concludes the proof.  
\end{proof}

%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{H\"{o}lder Continuity} \label{sec:holder}

In this section we prove the main theorem.  

\begin{proof}
We'll show that if $\theta$ with $\norm{\theta}_{L^\infty([-5,0] \times \Omega)} \leq 2$ solves \eqref{eq:main nonlinear} on $[-5,0]\times \Omega$ then $\theta$ is H\"{o}lder continuous at the point $(0,0)$ (with possibly $0 \in \bar{\Omega}$).  Up to translation and scaling, this will be sufficient to show continuity at all points in the domain, with a constant depending on $\Omega$ and on the time we wait.  

From Section \ref{sec:littlewood paley}, we know that 
\[ \R^\perp \theta = \sum_{j=j_0}^\infty u_j \]
for a sequence $(u_j)_j$ calibrated with some constant $\kappa = \kappa(\Omega)$ and center 0.  

Choose a constant $0 < \eps < 1/5$ such that
\begin{equation}\label{eps is small enough for Cgamma} 
5 \max\paren{ - \kappa \ln_2(\eps) e^{10\eps\kappa}, (1-j_0) \kappa} \leq \eps\n - 3,
\end{equation}

%\[ 5 \max\paren{ - \kappa \ln_2(\eps) e^{10\eps\kappa}, (1-j_0) \kappa} \leq \eps^{-a k}/k \qquad \forall k\geq 0. \]
%critical point at $k = -1/(a \ln(\eps))$, at that point the bound is $\leq -a \ln(\eps) \eps^{1/\ln(\eps)} = - a \ln(\eps) e$

For notational convenience, denote
\[ \sum_k = \sum_{j > - k \ln(\eps)}, \qquad \sum^k = \sum_{j \leq -k \ln(\eps)}. \]

For integers $k \geq 0$ consider the domains
\[ \Omega_k := \{x \in \R^2: \eps^k x \in \Omega\} \]
and define the following functions on $[-5,0]\times \Omega_k$:
\begin{align*} 
\ulowth{k}(t,x) &:= \sum^k u_j(\eps^k t, \eps^k x), \\
\uhighth{k}(t,x) &:= \sum_k u_j(\eps^k t, \eps^k x).  
\end{align*}

For $t \in [-5,0]$ and $k \geq 0$ define $\Gamma_k, \gamma_k: [-5,0] \to \R^2$ by the following ODEs:
\begin{align*}
\Gamma_0(t) &:= 0, \\
\gamma_k(0) &:= 0, \\
\dot{\gamma}_k(t) &:= \ulowth{k}(t, \Gamma_k(t) + \gamma_k(t)) - \dot{\Gamma}_k(t) \\
\Gamma_k(t) &:= \eps\n \gamma_{k-1}(\eps t) + \eps^{-2} \gamma_{k-2}(\eps^2 t) + \cdots + \eps^{-k} \gamma_0(\eps^k t), \qquad k \geq 1.
\end{align*}
Use [citation] some lemma from Bahouri-Chemin-Danchin that's a generalization of Picard-Lindelof to prove that these $\gamma$ exist.  Each $\ulowth{k}$ is a Lipschitz-in-space vector field, and each $\Gamma_k + \gamma_k$ is a flow along that vector field which ends up at the origin at $t=0$.  In particular, since  $\ulowth{k}$ is tangential to the boundary of $\Omega_k$ and has unique flows, the flow $\Gamma_k + \gamma_k$ cannot exit the region $\Omega_k$ and so our expressions remain well-defined.  

By Lemmas \ref{thm:scaling} and \ref{thm:calibration is good}, we know the sequence $(u_j(\eps^k \cdot, \eps^k \cdot))_j$ is calibrated and hence that independently of $k$
\[ \norm{\Lambda^{-1/4} \uhighth{k}}_{L^\infty([-5,0]\times \Omega_k)} \leq C \kappa \]
etc.  
Particularly
\[ \norm{\grad \ulowth{k}}_{L^\infty([-5,0]\times \Omega_k)} \leq 2 \kappa. \]

%I want to claim that 
%\[ \dot{\Gamma}_k(t) = \sum^{k-1} (\eps^k t, \eps^k \Gamma_k(t)). \]

%Notice that $\dot{\gamma}_0(t) = \ulowth{0}(t,\Gamma_0(t) + \gamma_0(t))$.  
By construction, for $k \geq 0$ we have $\Gamma_{k+1}(t) = \eps\n \gamma_k(\eps t) + \eps\n \Gamma_k(\eps t)$.  Therefore
\begin{align*} 
\dot{\Gamma}_{k+1}(t) &= \del_t \bracket{\eps\n \gamma_k(\eps t) + \eps\n \Gamma_k(\eps t)}
\\ &= \dot{\gamma}_k(\eps t) + \dot{\Gamma}_k(\eps t)
\\ &= \ulowth{k}(\eps t, \gamma_k(\eps t) + \Gamma_k(\eps t))
\\ &= \ulowth{k}(\eps t, \eps \Gamma_{k+1}(t)).  
\end{align*}

%Well, $\dot{\gamma}_0(t) = \ulowth{0}(t,\gamma_0(t))$.  Moreover, 
%\[ \ulowth{k}(t,\Gamma_{k+1}(t)) = \ulowth{k}(\eps\n \eps t, \eps\n \bracket{\gamma_k(\eps t) + \Gamma_k(\eps t)}) \]
%or
%\begin{align*} 
%\sum^k u_j(\eps^{k+1} t, \eps^{k+1} \Gamma_{k+1}(t)) &= \sum^k u_j(\eps^k \eps t, \eps^k \bracket{\gamma_k(\eps t) + \Gamma_k(\eps t)})
%\\ &= \ulowth{k}(\eps t, \gamma_k(\eps t) + \Gamma_k(\eps t))
%\\ &= \dot{\gamma}_k(\eps t) + \dot{\Gamma}_k(\eps t)
%\\ &= \del_t \bracket{\eps\n \gamma_k(\eps t) + \eps\n \Gamma_k(\eps t)}
%\\ &= \dot{\Gamma}_{k+1}(t).
%\end{align*}
%
%In other words,
%\[ \dot{\Gamma}_k(t) = \sum^{k-1} u_j(\eps^k t, \eps^k \Gamma_k(t)) \qquad k \geq 2. \]

With this in hand, we can bound the size of $\gamma_k$.  Namely, for $k \geq 1$, 
\begin{align*}
\dot{\gamma}_k(t) &= \ulowth{k}(t, \Gamma_k(t) + \gamma_k(t)) - \dot{\Gamma}_k(t)
\\ &= \ulowth{k}(t, \Gamma_k(t) + \gamma_k(t)) - \ulowth{k-1}(\eps t, \eps \Gamma_k(t))
\\ &= \sum^k u_j(\eps^k t, \eps^k \Gamma_k(t) + \eps^k \gamma_k(t)) - \sum^{k-1} u_j(\eps^k t, \eps^k \Gamma_k(t))
\\ &= \sum^{k-1} \bracket{u_j(\eps^k t, \eps^k \Gamma_k(t)+\eps^k \gamma_k(t)) - u_j(\eps^k t, \eps^k \Gamma_k(t))} + \sum_{k-1}^k u_j(\eps^k t, \eps^k \ldots)
\\ &= \bracket{\ulowth{k-1}\big(\eps t, \eps \Gamma_k(t)+\eps \gamma_k(t)\big) - \ulowth{k-1}(\eps t, \eps \Gamma_k(t))} + \sum_{k-1}^k u_j(\eps^k t, \eps^k \ldots).
\end{align*}
The sum $\sum^{k-1} u_j(\eps^k \cdot, \eps^k \cdot) = \ulowth{k-1}(\eps \, \cdot, \eps \, \cdot)$ is Lipschitz in space, with Lipschitz constant less than $2 \eps \kappa$.  Moreover, each $u_j$ has $\norm{u_j}_\infty \leq \kappa$.  Thus both terms of $\dot{\gamma}_k(t)$ are bounded
\[ |\dot{\gamma}_k(t)| \leq 2 \eps \kappa |\gamma_k(t)| - \kappa \ln_2(\eps). \]
This, by Gronwall's inequality, tells us that for $t \in [-5,0]$,
\[ |\gamma_k(t)| \leq \frac{-\ln_2(\eps)}{2 \eps} \paren{ e^{10 \eps \kappa} - 1} \]
and hence
\[ |\dot{\gamma}_k(t)| \leq -\kappa \ln_2(\eps) e^{10\eps \kappa}. \]

To account for $\gamma_0$, define
\[ C_\gamma = \max\paren{ - \kappa \ln_2(\eps) e^{10\eps\kappa}, j_0 \kappa} \]
so that for all $k \geq 0$ and $t \in [-5,0]$
\[ |\dot{\gamma}_k(t)| \leq C_\gamma. \]

Let us now produce a sequence of solutions $\theta_k$.  Define
\[ \theta_0(t,x) := \theta(t,x) \]
and for each $k \geq 0$, if $|\{\theta_k \leq 0\} \cap [-5,0]\times B_4(\Gamma_k(t))| \geq 2|B_4|$ then set
\[ \theta_{k+1}(t,x) := \frac{2}{2-\lambda} \bracket{\theta_k(\eps t, \eps x) + \lambda}. \]
Otherwise, set
\[ \theta_{k+1}(t,x) := \frac{1}{1-\lambda} \bracket{\theta_k(\eps t, \eps x) - \lambda}. \]

From Lemma \ref{thm:scaling}, we know that $\theta_k$ and the calibrated sequence $(u_j(\eps^k \cdot, \eps^k \cdot))_j$ solve \eqref{eq:main linear}.  

We will now show that
\begin{equation}\label{thetak below the barrier}
|\theta_k| \leq 2 + 2^{-k_0} \paren{|x-\Gamma_k(t)|^{1/4} - 2^{1/4}}_+
\end{equation}
holds for all $k \geq 0$.  

Since $|\theta_0|\leq 2$ by assumption, we know in particular that \eqref{thetak below the barrier} holds at $k=0$.  

This is sufficient for us to apply Lemma \ref{thm:harnack shifted} to each $\theta_k$ (or to $-\theta_k$ as appropriate) in order.  We conclude that \eqref{thetak below the barrier} holds for all $k \geq 0$.  
%\[ \abs{\theta_{k+1}(t,x)} \leq 2 + 2^{-k_0} \paren{|x-\Gamma_{k+1}(t)|^{1/4} - 2^{1/4}}_+. \]

Each $\theta_k$ is between $-2$ and 2 on $[-5,0]\times B_2(\Gamma_k)$.  But recall that each $\Gamma_k$ is Lipschitz with constant $k C_\gamma$.  Thus $|\Gamma_k(t)|\leq 1$ for $t \in [-(k C_\gamma)\n, 0]$.  On that time interval, 
\[ \abs{\theta_k(t,x)} \leq 2 \qquad \forall x \in B_1(0). \]

We conclude that
\[ \abs{ \sup_{[-\eps^k (k C_\gamma)\n, 0] \times B_{\eps^k}(0)} \theta(t,x) - \inf_{[-\eps^k (k C_\gamma)\n, 0] \times B_{\eps^k}(0)} \theta(t,x) } \leq 4 \paren{\frac{2}{2-\lambda}}^{-k}. \]

In particular, for some positive constant $C$ such that
\[ \eps^{C k} \leq (k C_\gamma)\n \qquad \forall k \geq 0, \]
we can say that
\[ |t|^2 + |x|^2 \leq \eps^{(1+C)k} \]	
implies that $(t,x) \in [-\eps^k (k C_\gamma)\n, 0] \times B_{\eps^k}(0)$ which in turn implies that
\[ \abs{\theta(t,x) - \theta(0,0)} \leq  4 \paren{\frac{2}{2-\lambda}}^{-k}. \]

In other words,
\begin{align*} 
\abs{\theta(t,x) - \theta(0,0)} &\leq 4 \paren{\frac{2}{2-\lambda}}^{ -\frac{1}{1+C} \log_\eps(|t|^2 - |x|^2)  + 1} 
\\ &= 4 \paren{\frac{2}{2-\lambda}} \exp\bracket{\ln\paren{\frac{2}{2-\lambda}} \frac{\ln(|t|^2 + |x|^2)}{-(1+C)\ln(\eps)}}
\\ &= \frac{8}{2-\lambda} (|t|^2 + |x|^2)^{-\frac{\ln(2) - \ln(2-\lambda)}{(1+C)\ln(\eps)}}.
\end{align*}

\end{proof}

%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------%-------

\section{Waxing Philosophical}

Our equation is
\[ \del_t \theta + \ulow \cdot \grad \theta + \Lambda^{1/4} f \cdot \grad \theta + \Lambda \theta = 0. \]

\end{document}